{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6491,
     "status": "ok",
     "timestamp": 1675333348365,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "IawStAMhtY0q",
    "outputId": "1a5d6537-c37e-44de-8d0e-c74c98f9529a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5541,
     "status": "ok",
     "timestamp": 1675333353902,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "SctI2LsOt3dh",
    "outputId": "25af520c-97d8-4b01-a79a-b8ef3f36c49b"
   },
   "outputs": [],
   "source": [
    "!pip install easyfsl tensorflow sklearn numpy matplotlib scipy tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1675333353903,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "xi7TOrG8tO6X",
    "outputId": "0bd4ef5f-bdd0-40e6-b173-fbe1b7509466"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras import Sequential,layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import statistics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "import tensorflow_probability as tfp\n",
    "from operator import truediv\n",
    "from tensorflow.compat.v1.distributions import Bernoulli\n",
    "from plotly.offline import init_notebook_mode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from tensorflow.python.keras import backend as K\n",
    "# import spectral\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dVy7URxfN6tc"
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "im_width, im_height, im_depth, im_channel = 11,11,30, 1 # im -> image\n",
    "mc_loss_weight = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaFcFKyBN6tf"
   },
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lmFAiil_N6tf"
   },
   "outputs": [],
   "source": [
    "def calc_euclidian_dists(x, y):\n",
    "    n = x.shape[0]\n",
    "    m = y.shape[0]\n",
    "    x = tf.tile(tf.expand_dims(x, 1), [1, m, 1])\n",
    "    y = tf.tile(tf.expand_dims(y, 0), [n, 1, 1])\n",
    "    return tf.reduce_mean(tf.math.pow(x - y, 2), 2)    \n",
    "                                  #   ^^^^^^^^  ^^ -> axis \n",
    "                                  #      x-y -> subtracts each element of x from y\n",
    "                                  #     2 -> square of the difference ^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n",
      "(2, 3)\n",
      "(3, 3)\n",
      "tf.Tensor(\n",
      "[[[1 2 3]\n",
      "  [1 2 3]\n",
      "  [1 2 3]]\n",
      "\n",
      " [[4 5 6]\n",
      "  [4 5 6]\n",
      "  [4 5 6]]], shape=(2, 3, 3), dtype=int32)\n",
      "(2, 3, 3)\n",
      "tf.Tensor(\n",
      "[[[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]], shape=(2, 3, 3), dtype=int32)\n",
      "(2, 3, 3)\n",
      "tf.Tensor(\n",
      "[[[ 0  0  0]\n",
      "  [-3 -3 -3]\n",
      "  [-6 -6 -6]]\n",
      "\n",
      " [[ 3  3  3]\n",
      "  [ 0  0  0]\n",
      "  [-3 -3 -3]]], shape=(2, 3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0  0  0]\n",
      "  [ 9  9  9]\n",
      "  [36 36 36]]\n",
      "\n",
      " [[ 9  9  9]\n",
      "  [ 0  0  0]\n",
      "  [ 9  9  9]]], shape=(2, 3, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 0,  9, 36],\n",
       "       [ 9,  0,  9]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3],[4,5,6]]) 2 \n",
    "b = tf.constant([[1,2,3],[4,5,6],[7,8,9]]) 3 \n",
    "calc_euclidian_dists(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGfdaFk4KNE6"
   },
   "outputs": [],
   "source": [
    "def calc_euclidian_dists(x, y):\n",
    "    n = x.shape[0]\n",
    "    m = y.shape[0]\n",
    "    x = tf.tile(tf.expand_dims(x, 1), [1, m, 1])\n",
    "    y = tf.tile(tf.expand_dims(y, 0), [n, 1, 1])\n",
    "    return tf.reduce_mean(tf.math.pow(x - y, 2), 2)    \n",
    "\n",
    "def _bernoulli(shape, mean):\n",
    "    return tf.nn.relu(tf.sign(mean - tf.random.uniform(shape, minval=0, maxval=1, dtype=tf.float32)))\n",
    "\n",
    "class DropBlock3D(tf.keras.layers.Layer):\n",
    "    def __init__(self, keep_prob, block_size, scale=True, **kwargs):\n",
    "        super(DropBlock3D, self).__init__(**kwargs)\n",
    "        self.keep_prob = float(keep_prob) if isinstance(keep_prob, int) else keep_prob\n",
    "        self.block_size = int(block_size)\n",
    "        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 5\n",
    "        _, self.d, self.h, self.w, self.channel = input_shape.as_list()\n",
    "        # pad the mask\n",
    "        p0 = (self.block_size - 1) // 2\n",
    "        p1 = (self.block_size - 1) - p0\n",
    "        self.padding = [[0, 0], [p0, p1], [p0, p1], [p0, p1], [0, 0]]\n",
    "        self.set_keep_prob()\n",
    "        super(DropBlock3D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=True, **kwargs):\n",
    "        def drop():\n",
    "            mask = self._create_mask(tf.shape(inputs))\n",
    "            output = inputs * mask\n",
    "            output = tf.cond(self.scale,\n",
    "                             true_fn=lambda: output * tf.compat.v1.to_float(tf.size(mask)) / tf.reduce_sum(mask),\n",
    "                             false_fn=lambda: output)\n",
    "            return output\n",
    "\n",
    "        if training is None:\n",
    "            training = K.learning_phase()\n",
    "        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n",
    "                         true_fn=lambda: inputs,\n",
    "                         false_fn=drop)\n",
    "        return output\n",
    "\n",
    "    def set_keep_prob(self, keep_prob=None):\n",
    "        \"\"\"This method only supports Eager Execution\"\"\"\n",
    "        if keep_prob is not None:\n",
    "            self.keep_prob = keep_prob\n",
    "        d, w, h = tf.compat.v1.to_float(self.d), tf.compat.v1.to_float(self.w), tf.compat.v1.to_float(self.h)\n",
    "        self.gamma = ((1. - self.keep_prob) * (d * w * h) / (self.block_size ** 3) /\n",
    "                      ((d - self.block_size + 1) * (w - self.block_size + 1) * (h - self.block_size + 1)))\n",
    "\n",
    "    def _create_mask(self, input_shape):\n",
    "        sampling_mask_shape = tf.stack([input_shape[0],\n",
    "                                        self.d - self.block_size + 1,\n",
    "                                        self.h - self.block_size + 1,\n",
    "                                        self.w - self.block_size + 1,\n",
    "                                        self.channel])\n",
    "        mask = _bernoulli(sampling_mask_shape, self.gamma)\n",
    "        mask = tf.pad(mask, self.padding)\n",
    "        mask = tf.nn.max_pool3d(mask, [1, self.block_size, self.block_size, self.block_size, 1], [1, 1, 1, 1, 1], 'SAME')\n",
    "        mask = 1 - mask\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1451,
     "status": "ok",
     "timestamp": 1675333355346,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "215a8XhEN6ti",
    "outputId": "472f7931-f8c2-45a2-e708-a6f4d82c07bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 11, 11, 30, 1)]   0         \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 11, 11, 30, 8)     512       \n",
      "                                                                 \n",
      " drop_block3d (DropBlock3D)  (None, 11, 11, 30, 8)     0         \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 11, 11, 30, 16)    5776      \n",
      "                                                                 \n",
      " drop_block3d_1 (DropBlock3  (None, 11, 11, 30, 16)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 9, 9, 28, 32)      13856     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 9, 9, 896)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 7, 7, 64)          516160    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               803072    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1372272 (5.23 MB)\n",
      "Trainable params: 1372272 (5.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(shape = (im_height, im_width, im_depth, im_channel))\n",
    "out1 = layers.Conv3D(filters=8, kernel_size=(3,3,7), activation='relu',input_shape=(im_height, im_width, im_depth, im_channel),padding='same')(input_layer)\n",
    "out1 = DropBlock3D(0.7,3)(out1) \n",
    "out2 = layers.Conv3D(filters=16, kernel_size=(3,3,5), activation='relu',padding='same')(out1) # no of prams=16*(3*3*5*8 + 1)=2880\n",
    "out2 = DropBlock3D(0.7,3)(out2)\n",
    "out3 = layers.Conv3D(filters=32, kernel_size=(3,3,3), activation= 'relu')(out2)\n",
    "out3 = layers.Reshape((out3.shape[1], out3.shape[2], out3.shape[3]*out3.shape[4]))(out3)\n",
    "out3 = layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(out3)\n",
    "out4 = layers.Flatten()(out3)\n",
    "out4 = layers.Dropout(0.4)(out4, training=True)\n",
    "out4 = layers.Dense(256, activation='relu')(out4)  # output = activation(dot(input, kernel) + bias)\n",
    "out5 = layers.Dropout(0.4)(out4,training=True) \n",
    "out5 = layers.Dense(128, activation='relu')(out5)\n",
    "#out5 = layers.Dropout(0.4)(out5, training=True)\n",
    "#out6 = layers.Dense(16, activation='relu')(out5)\n",
    "model = Model(inputs=input_layer,outputs=out5) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wAOZ0z1rN6to"
   },
   "outputs": [],
   "source": [
    "class Prototypical(Model):\n",
    "    def __init__(self, model, w, h, d, c):\n",
    "        super(Prototypical, self).__init__()\n",
    "        self.w, self.h, self.d, self.c = w, h, d, c\n",
    "        self.encoder = model\n",
    "\n",
    "    def call(self, support, query, support_labels, query_labels, K, C, N,n_times,training=True):\n",
    "      # support : support images (25, 11, 11, 30, 1)\n",
    "      # query : query images (75, 11, 11, 30, 1)\n",
    "    \n",
    "      n_class = C                                                               #5\n",
    "      n_support = K                                                             #5\n",
    "      n_query = N                                                               #15 \n",
    "\n",
    "      if training == True : \n",
    "        loss = 0\n",
    "        mc_predictions = []                                                     # list of predictions for multiple passes\n",
    "        for i in range(n_times) :     \n",
    "          y = np.zeros((int(C*N),C))                                              #(75, 5)\n",
    "          \n",
    "          \n",
    "          for i in range(int(C*N)) :                                             # 75\n",
    "            x = support_labels.index(query_labels[i])                           # creation of 1-hot for true labels\n",
    "            y[i][x] = 1.                                               # n_times passing every query image for calculating variance \n",
    "            #  basically we are creating OMR sheet for each query image where each column represents the class and each row represents the query image, where the true class is 1 and rest are 0\n",
    "            \n",
    "          cat = tf.concat([support,query], axis=0)       \n",
    "          print('cat', cat.shape, cat)                                       # [100, 11, 11, 30, 1]\n",
    "          z = self.encoder(cat)    \n",
    "          print('z', z.shape, z)                                             # [100, 128]   # build a new computational graph from the provided inputs\n",
    "          # Divide embedding into support and query\n",
    "          z_prototypes = tf.reshape(z[:n_class * n_support],[n_class, n_support, z.shape[-1]])   #[5, 5, 128])\n",
    "          print('z_p', z_prototypes.shape, z_prototypes)   \n",
    "          # Prototypes are means of n_support examples\n",
    "          z_prototypes = tf.math.reduce_mean(z_prototypes, axis=1)              #[5, 128]\n",
    "          print('z_p', z_prototypes.shape, z_prototypes)   \n",
    "          z_query = z[n_class * n_support:]                                     #[75, 182]                         \n",
    "          print('z_q', z_query.shape, z_query)   \n",
    "          # Calculate distances between query and prototypes\n",
    "          dists = calc_euclidian_dists(z_query, z_prototypes)                   #[75, 5]\n",
    "          print('dist', dists)   \n",
    "          # log softmax of calculated distances\n",
    "          log_p_y = tf.nn.log_softmax(-dists, axis=-1)                          #[75, 5]     this activation function heavily penalizes wrong class prediction as compared to its Softmax counterpart    \n",
    "          print('log', log_p_y)   \n",
    "          loss1 = -tf.reduce_mean((tf.reduce_sum(tf.multiply(y, log_p_y), axis=-1)))   #loss for the current pass                     \n",
    "          print('loss1', loss1)                                                 # []\n",
    "          loss += loss1                                                         # adding loss for each pass                   \n",
    "          predictions = tf.nn.softmax(-dists, axis=-1)                         # [75, 5] prediction probability for the search-space classes per query image(for current pass)\n",
    "          print('pred', predictions)   \n",
    "          mc_predictions.append(predictions)                                          \n",
    "\n",
    "        y = np.zeros((int(C*N),C))\n",
    "        for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])                           # creation of 1-hot for true labels\n",
    "            y[i][x] = 1. \n",
    "        mc_predictions = tf.convert_to_tensor(np.reshape(np.asarray(mc_predictions),(n_times,int(C*N),C)))  #(n_times,75,5)\n",
    "        std_predictions = tf.math.reduce_std(mc_predictions,axis=0)                                         # (75,5)\n",
    "        std = tf.reduce_sum(tf.reduce_sum(tf.multiply(std_predictions,y),axis=1))\n",
    "        print('std', std)        \n",
    "        loss += mc_loss_weight*std\n",
    "        \n",
    "        # calculating mean accuracy\n",
    "        mean_predictions = tf.reduce_mean(mc_predictions,axis=0)                # mean prediction probability for each class (75,5)\n",
    "        mean_eq = tf.cast(tf.equal(                                             # accuracy for the current pass  c\n",
    "            tf.cast(tf.argmax(mean_predictions, axis=-1), tf.int32),            # check if the index of max probability is equal to the true class index\n",
    "            tf.cast(tf.argmax(y,axis=-1), tf.int32)), tf.float32)               # argmax returns the index of max probability\n",
    "        mean_accuracy = tf.reduce_mean(mean_eq)\n",
    "        mean_predictions = tf.reduce_mean(mc_predictions,axis=0)                # mean prediction probability for each class (5)\n",
    "        return loss, mean_accuracy, mean_predictions   \n",
    "      \n",
    "      if training == False :\n",
    "        loss = 0\n",
    "        mc_predictions = []                                                     # list of predictions for multiple passes  \n",
    "        for i in range(n_times) :                                               # n_times passing the query images for variance calculation\n",
    "          y = np.zeros((int(C*N),C))                                            # (150,10)\n",
    "          for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])                           # creation of 1-hot for the true labels\n",
    "            y[i][x] = 1.  \n",
    "          # merge support and query to forward through encoder\n",
    "          cat = tf.concat([support,query], axis=0)                              # [200,9,9,20,1]   \n",
    "          z = self.encoder(cat)                                                 # [200, 320]\n",
    "          # Divide embedding into support and query\n",
    "          z_prototypes = tf.reshape(z[:n_class * n_support],[n_class, n_support, z.shape[-1]])   #[10, 5, 320])\n",
    "          # Prototypes are means of n_support examples\n",
    "          z_prototypes = tf.math.reduce_mean(z_prototypes, axis=1)              #[10, 320]\n",
    "          z_query = z[n_class * n_support:]                                     #[150, 320]                         \n",
    "          # Calculate distances between query and prototypes\n",
    "          dists = calc_euclidian_dists(z_query, z_prototypes)                   #[150, 10]\n",
    "          # log softmax of calculated distances\n",
    "          log_p_y = tf.nn.log_softmax(-dists, axis=-1)                          #[150, 10]        \n",
    "          loss1 = -tf.reduce_mean((tf.reduce_sum(tf.multiply(y, log_p_y), axis=-1)))        \n",
    "          loss += loss1\n",
    "          predictions = tf.nn.softmax(-dists, axis=-1)                                 # prediction probabilities for the classes for current pass\n",
    "          mc_predictions.append(predictions)                                             \n",
    "        y = np.zeros((int(C*N),C))                                            # (150,10)\n",
    "        for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])                           # creation of 1-hot for the true labels\n",
    "            y[i][x] = 1.  \n",
    "        mean_predictions = tf.reduce_mean(mc_predictions,axis=0)                # mean prediction probability for each class (150,10)\n",
    "        mean_eq = tf.cast(tf.equal(                                             # accuracy for the current pass\n",
    "            tf.cast(tf.argmax(mean_predictions, axis=-1), tf.int32), \n",
    "            tf.cast(tf.argmax(y,axis=-1), tf.int32)), tf.float32)\n",
    "        mean_accuracy = tf.reduce_mean(mean_eq)\n",
    "        mean_pred_index = tf.argmax(mean_predictions,axis=1)\n",
    "        # mean class-wise accuracies\n",
    "        mean_correct_class = [[] for i in range(tC)]\n",
    "        mean_correct_pred = [[] for i in range(tC)]\n",
    "        classwise_mean_acc = [[] for i in range(tC)]\n",
    "        for i in range(int(C*N)):\n",
    "          x = support_labels.index(query_labels[i])\n",
    "          mean_correct_class[x].append('4')\n",
    "          if(mean_pred_index[i] == x) :\n",
    "            mean_correct_pred[x].append('4')\n",
    "        for i in range(tC) :\n",
    "           z = len(mean_correct_pred[i])/len(mean_correct_class[i])\n",
    "           classwise_mean_acc[i].append(z)  \n",
    "        #std calculation\n",
    "        std = 0\n",
    "        for i in range(int(C*N)) :\n",
    "           x = support_labels.index(query_labels[i])\n",
    "           p_i = np.array([p[i,:] for p in mc_predictions])\n",
    "           std_i = tf.math.reduce_std(p_i,axis=0) \n",
    "           std_i_true = std_i[x]\n",
    "           std += std_i_true                                                    # adding std of each class\n",
    "        print('std',std)\n",
    "        loss += mc_loss_weight*std \n",
    "        y = np.zeros((int(C*N),C))                                            # (150,10)\n",
    "        for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])                           # creation of 1-hot for the true labels\n",
    "            y[i][x] = 1.                                                                \n",
    "        return loss, mc_predictions, mean_accuracy, classwise_mean_acc, y\n",
    "\n",
    "\n",
    "      def save(self, model_path):\n",
    "        self.encoder.save(model_path)\n",
    "\n",
    "      def load(self, model_path):\n",
    "        self.encoder(tf.zeros([1, self.w, self.h, self.c]))\n",
    "        self.encoder.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX2P_sAOFevh"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m3ipb9FLtO6c"
   },
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data = sio.loadmat('E:\\Engginearing\\SAKEC\\SEM 6\\Major Project\\Data\\Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "    labels = sio.loadmat('E:\\Engginearing\\SAKEC\\SEM 6\\Major Project\\Data\\Indian_pines_gt.mat')['indian_pines_gt']\n",
    "    return data, labels\n",
    "# without reduction of 200 channels to 30 channels, memory error while creating cube \n",
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def padWithZeros(X, margin):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)  # X :(145, 145, 30) --> (155, 155, 30) with window =11\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))  # (21025, 25, 25, 30)   \n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))  # (21025,)\n",
    "    patchIndex = 0\n",
    "    \n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]  \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]            \n",
    "            patchIndex = patchIndex + 1\n",
    "  \n",
    "    patchesData = np.expand_dims(patchesData, axis=-1)\n",
    "    return patchesData,patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1675333355976,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "_iyX4iTQUOpT",
    "outputId": "71b63c48-8d0e-440c-c0e1-fd9acbdeb05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21025, 11, 11, 30, 1) (21025,)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = 'IP'                                         # 16 classes   \n",
    "ip_x1, ip_y = loadData(dataset1)                              #((512, 217, 204), (512, 217))\n",
    "ip_x2,pca = applyPCA(ip_x1,numComponents=30)                   # ((512, 217, 20), (512, 217))\n",
    "ip_X,ip_Y = createImageCubes(ip_x2, ip_y, windowSize=11)   #(111104, 9, 9, 20, 1) (111104,)\n",
    "print(ip_X.shape,ip_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BMY1DbyVZtV1"
   },
   "outputs": [],
   "source": [
    "def patches_class(X,Y,n) :\n",
    "  n_classes = n\n",
    "  patches_list = []\n",
    "  for i in range(1,n_classes+1):   # not considering class 0\n",
    "    patchesData_Ith_Label = X[Y==i,:,:,:,:]\n",
    "    patches_list.append(patchesData_Ith_Label)\n",
    "  return patches_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NBjLuxWvxMBG"
   },
   "outputs": [],
   "source": [
    "patches_class_ip = patches_class(ip_X,ip_Y,16) # class_wise list of patches #(16,) for class 0: (2009, 9, 9, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nzvKxHabyVJQ"
   },
   "outputs": [],
   "source": [
    "train_class_indices = [1,2,4,5,7,9,10,11,13,14]\n",
    "test_class_indices = [0,3,6,8,12,15]\n",
    "train_patches_class = [patches_class_ip[i] for i in train_class_indices]        #(10)\n",
    "test_patches_class = [patches_class_ip[i] for i in test_class_indices]        #(6) \n",
    "train_class_labels = [2,3,5,6,8,10,11,12,14,15]   \n",
    "test_class_labels = [1,4,7,9,13,16]     #[11...16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL367A6HF3qf"
   },
   "source": [
    "**Prepare Training and validation Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MEfZ0-xNEcM"
   },
   "source": [
    "**Create DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kNBNYdJX3STT"
   },
   "outputs": [],
   "source": [
    "C = 5    # n_class\n",
    "K1 = 5   # n_support\n",
    "N = 15   # n_query\n",
    "tC = 3   # classes in a test episode\n",
    "im_height,im_width,im_depth = 11,11,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vmBBYOcd7wdm"
   },
   "outputs": [],
   "source": [
    "def new_episode(patches_list,K,C,N,class_labels) :\n",
    "  selected_classes = np.random.choice(class_labels,C,replace=False)  # Randomly choice 5 Classes out of classes available # replace: False means no repetition\n",
    "  tsupport_patches = []\n",
    "  tquery_patches = []\n",
    "  query_labels = []\n",
    "  support_labels = list(selected_classes) \n",
    "  for x in selected_classes :\n",
    "    sran_indices = np.random.choice(len(patches_list[x-1]),K,replace=False)  # for class no X-1: select K samples \n",
    "    support_patches = patches_list[x-1][sran_indices,:,:,:,:]\n",
    "    qran_indices = np.random.choice(len(patches_list[x-1]),N,replace=False)  # N Samples for Query\n",
    "    query_patches = patches_list[x-1][qran_indices,:,:,:,:]\n",
    "  # Support and Query patches belong to same Class \n",
    "    for i in range(N) :\n",
    "      query_labels.append(x) #  [1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 7, 7, 7, 7, 7] [p1, p1, p1, p1, p1, p3, p3 ...]\n",
    "    tquery_patches.extend(query_patches)   # class 5, query 15 75  # extend: add all elements of a list to another list individually and not append the whole list as one element\n",
    "    tsupport_patches.extend(support_patches) # class 5, support 5 25\n",
    "  temp1 = list(zip(tquery_patches, query_labels))  \n",
    "  random.shuffle(temp1)        # By Doing Shuffling, Support, Query Same class combination got mismatched - mitigated by support index\n",
    "  tquery_patches, query_labels = zip(*temp1) # * is used to unzip\n",
    "  tquery_patches = tf.convert_to_tensor(np.reshape(np.asarray(tquery_patches),(C*N,im_height,im_width,im_depth,1)),dtype=tf.float32)\n",
    "  tsupport_patches = tf.convert_to_tensor(np.reshape(np.asarray(tsupport_patches),(C*K,im_height,im_width,im_depth,1)),dtype=tf.float32)\n",
    "  return tquery_patches, tsupport_patches, query_labels, support_labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mZSEL1Zo3KUh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 14, 6, 3, 10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tquery_patches, tsupport_patches, query_labels, support_labels = new_episode(patches_class_ip,K1,C,N,train_class_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SyQYRKpN6t4"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rtxObYGQN6t4"
   },
   "outputs": [],
   "source": [
    "ProtoModel = Prototypical(model,im_width, im_height, im_depth, im_channel)\n",
    "optimizer = tf.keras.optimizers.Adam(0.00001)          #Adam(0.001)\n",
    "n_times = 1  # 25\n",
    "#std_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8HvgsXRvN6t6"
   },
   "outputs": [],
   "source": [
    "# Metrics to gather\n",
    "train_loss = tf.metrics.Mean(name='train_loss')\n",
    "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "def train_step(support, query, support_labels, query_labels, K, C, N):\n",
    "    # Forward & update gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N,n_times,training=True)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    # A gradient simply measures the change in all weights with regard to the change in error. You can also think of a gradient as the slope of a function. The higher the gradient, the steeper the slope and the faster a model can learn. But if the slope is zero, the model stops learning\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Log loss and accuracy for step\n",
    "    train_loss(loss)\n",
    "    train_acc(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat (100, 11, 11, 30, 1) tf.Tensor(\n",
      "[[[[[-7.02419460e-01]\n",
      "    [-8.62633362e-02]\n",
      "    [ 7.11570919e-01]\n",
      "    ...\n",
      "    [-2.17975259e-01]\n",
      "    [ 5.82661815e-02]\n",
      "    [ 7.34669685e-01]]\n",
      "\n",
      "   [[-5.95469475e-01]\n",
      "    [ 4.47918087e-01]\n",
      "    [ 9.92179453e-01]\n",
      "    ...\n",
      "    [ 1.89423239e+00]\n",
      "    [-5.39725184e-01]\n",
      "    [ 1.49373615e+00]]\n",
      "\n",
      "   [[-6.12751722e-01]\n",
      "    [ 4.75553095e-01]\n",
      "    [ 6.42560303e-01]\n",
      "    ...\n",
      "    [ 1.25302404e-01]\n",
      "    [ 7.54794180e-02]\n",
      "    [ 1.43731260e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-1.10534084e+00]\n",
      "    [-3.44334662e-01]\n",
      "    [-5.63104391e-01]\n",
      "    ...\n",
      "    [ 1.56273091e+00]\n",
      "    [ 5.68705201e-01]\n",
      "    [-1.04426615e-01]]\n",
      "\n",
      "   [[-1.47406471e+00]\n",
      "    [ 1.85612291e-01]\n",
      "    [-1.39785886e-01]\n",
      "    ...\n",
      "    [ 1.50141490e+00]\n",
      "    [ 1.23116709e-01]\n",
      "    [ 4.95756149e-01]]\n",
      "\n",
      "   [[-1.29334521e+00]\n",
      "    [-8.56044609e-03]\n",
      "    [-6.50987148e-01]\n",
      "    ...\n",
      "    [-5.98869383e-01]\n",
      "    [-1.26528516e-01]\n",
      "    [-6.25001431e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 6.71693683e-01]\n",
      "    [-2.04244360e-01]\n",
      "    [ 2.35208303e-01]\n",
      "    ...\n",
      "    [-9.71571028e-01]\n",
      "    [ 4.03265983e-01]\n",
      "    [-4.44832504e-01]]\n",
      "\n",
      "   [[ 6.63328528e-01]\n",
      "    [-4.49621528e-02]\n",
      "    [ 4.58083838e-01]\n",
      "    ...\n",
      "    [-5.53637505e-01]\n",
      "    [ 2.34425902e-01]\n",
      "    [-4.37717110e-01]]\n",
      "\n",
      "   [[ 6.70965910e-01]\n",
      "    [ 2.78419554e-02]\n",
      "    [ 4.99765992e-01]\n",
      "    ...\n",
      "    [-1.33545315e-02]\n",
      "    [ 6.05380535e-02]\n",
      "    [-4.48149085e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-8.67254138e-01]\n",
      "    [-6.48323223e-02]\n",
      "    [-7.22565770e-01]\n",
      "    ...\n",
      "    [-2.82677226e-02]\n",
      "    [ 2.60054380e-01]\n",
      "    [-1.03910494e+00]]\n",
      "\n",
      "   [[-1.49396026e+00]\n",
      "    [-3.73427808e-01]\n",
      "    [-2.77112007e-01]\n",
      "    ...\n",
      "    [ 3.34433526e-01]\n",
      "    [-2.16512427e-01]\n",
      "    [-1.90644607e-01]]\n",
      "\n",
      "   [[-1.50237978e+00]\n",
      "    [-1.05467938e-01]\n",
      "    [-1.19883632e-02]\n",
      "    ...\n",
      "    [ 3.68161768e-01]\n",
      "    [-4.76487994e-01]\n",
      "    [-1.22857630e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 5.82479715e-01]\n",
      "    [-6.08368143e-02]\n",
      "    [-8.13632667e-01]\n",
      "    ...\n",
      "    [ 1.47727370e-01]\n",
      "    [ 3.44269574e-01]\n",
      "    [-4.94831115e-01]]\n",
      "\n",
      "   [[ 5.40253639e-01]\n",
      "    [ 1.11236326e-01]\n",
      "    [-7.64238715e-01]\n",
      "    ...\n",
      "    [ 4.77058440e-01]\n",
      "    [-2.25041223e+00]\n",
      "    [-5.01281917e-01]]\n",
      "\n",
      "   [[ 5.49782693e-01]\n",
      "    [-4.96215820e-02]\n",
      "    [-7.62723863e-01]\n",
      "    ...\n",
      "    [ 5.88133514e-01]\n",
      "    [-1.09258667e-01]\n",
      "    [-2.20936507e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-8.36721361e-01]\n",
      "    [ 4.18771565e-01]\n",
      "    [-4.66443211e-01]\n",
      "    ...\n",
      "    [-5.69071472e-01]\n",
      "    [ 4.27879125e-01]\n",
      "    [-8.62876534e-01]]\n",
      "\n",
      "   [[-1.35405481e+00]\n",
      "    [ 3.71676534e-01]\n",
      "    [-7.23910779e-02]\n",
      "    ...\n",
      "    [ 1.21234965e+00]\n",
      "    [-9.26715508e-02]\n",
      "    [-2.53621578e-01]]\n",
      "\n",
      "   [[-1.48000062e+00]\n",
      "    [ 3.79400738e-02]\n",
      "    [ 6.64223656e-02]\n",
      "    ...\n",
      "    [ 1.25508535e+00]\n",
      "    [ 2.63358682e-01]\n",
      "    [ 2.85528153e-01]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[-1.40899181e+00]\n",
      "    [-9.76069644e-02]\n",
      "    [ 3.82173955e-01]\n",
      "    ...\n",
      "    [-5.46737313e-01]\n",
      "    [-1.31409991e+00]\n",
      "    [-5.99881351e-01]]\n",
      "\n",
      "   [[-1.47419870e+00]\n",
      "    [-3.56477708e-01]\n",
      "    [ 4.98994499e-01]\n",
      "    ...\n",
      "    [ 3.70088816e-01]\n",
      "    [-1.23386478e+00]\n",
      "    [ 1.29130304e-01]]\n",
      "\n",
      "   [[-1.44750273e+00]\n",
      "    [-1.49485499e-01]\n",
      "    [ 5.21709919e-01]\n",
      "    ...\n",
      "    [-6.40084088e-01]\n",
      "    [-8.18420172e-01]\n",
      "    [-2.54677385e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-1.30673075e+00]\n",
      "    [-1.73606649e-02]\n",
      "    [ 3.44553620e-01]\n",
      "    ...\n",
      "    [-5.34958601e-01]\n",
      "    [-3.95606339e-01]\n",
      "    [ 1.08907223e+00]]\n",
      "\n",
      "   [[-8.83001685e-01]\n",
      "    [ 7.06547856e-01]\n",
      "    [ 9.00805593e-01]\n",
      "    ...\n",
      "    [-6.54866934e-01]\n",
      "    [-3.16330075e-01]\n",
      "    [ 6.90176129e-01]]\n",
      "\n",
      "   [[-3.74921635e-02]\n",
      "    [ 1.55027997e+00]\n",
      "    [ 1.04881108e-01]\n",
      "    ...\n",
      "    [-1.23291016e+00]\n",
      "    [ 1.99128926e-01]\n",
      "    [ 6.10010386e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]\n",
      "\n",
      "   [[ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    ...\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]\n",
      "    [ 0.00000000e+00]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 9.22139227e-01]\n",
      "    [-1.25124484e-01]\n",
      "    [-1.19283020e+00]\n",
      "    ...\n",
      "    [ 3.72018993e-01]\n",
      "    [-1.80016398e+00]\n",
      "    [-4.44465071e-01]]\n",
      "\n",
      "   [[ 9.50153291e-01]\n",
      "    [-9.29229185e-02]\n",
      "    [-1.24674106e+00]\n",
      "    ...\n",
      "    [ 8.00565302e-01]\n",
      "    [ 1.66902587e-01]\n",
      "    [-3.24434012e-01]]\n",
      "\n",
      "   [[ 9.15263355e-01]\n",
      "    [ 5.17252795e-02]\n",
      "    [-1.42381144e+00]\n",
      "    ...\n",
      "    [ 5.69787621e-01]\n",
      "    [ 1.18213698e-01]\n",
      "    [-1.73308998e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 8.84850621e-01]\n",
      "    [-1.33498877e-01]\n",
      "    [-1.29020572e+00]\n",
      "    ...\n",
      "    [ 8.18489790e-01]\n",
      "    [ 2.21367851e-01]\n",
      "    [-3.93745095e-01]]\n",
      "\n",
      "   [[ 8.60309303e-01]\n",
      "    [-3.16414833e-02]\n",
      "    [-1.35293984e+00]\n",
      "    ...\n",
      "    [ 9.54974771e-01]\n",
      "    [ 3.49284671e-02]\n",
      "    [-3.04859340e-01]]\n",
      "\n",
      "   [[ 8.73719633e-01]\n",
      "    [-1.02754585e-01]\n",
      "    [-1.14560866e+00]\n",
      "    ...\n",
      "    [ 5.07247508e-01]\n",
      "    [-1.78625774e+00]\n",
      "    [-7.09024370e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 3.18375111e-01]\n",
      "    [ 4.54747707e-01]\n",
      "    [-3.54985774e-01]\n",
      "    ...\n",
      "    [ 3.08178246e-01]\n",
      "    [-2.49777004e-01]\n",
      "    [-3.92826915e-01]]\n",
      "\n",
      "   [[ 2.43851334e-01]\n",
      "    [ 2.82752782e-01]\n",
      "    [-3.39954227e-01]\n",
      "    ...\n",
      "    [-4.16542590e-01]\n",
      "    [-1.23091780e-01]\n",
      "    [-6.82824910e-01]]\n",
      "\n",
      "   [[-5.97574376e-02]\n",
      "    [ 2.42141798e-01]\n",
      "    [-4.06492710e-01]\n",
      "    ...\n",
      "    [-2.44675875e+00]\n",
      "    [ 2.59484828e-01]\n",
      "    [ 1.68650460e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 4.84613180e-01]\n",
      "    [-1.41627327e-01]\n",
      "    [-4.97975320e-01]\n",
      "    ...\n",
      "    [ 4.08083886e-01]\n",
      "    [ 5.91272175e-01]\n",
      "    [-3.21952760e-01]]\n",
      "\n",
      "   [[ 4.81026590e-01]\n",
      "    [-7.60517940e-02]\n",
      "    [-6.97135031e-01]\n",
      "    ...\n",
      "    [-1.61107302e-01]\n",
      "    [ 4.67165321e-01]\n",
      "    [-2.60299623e-01]]\n",
      "\n",
      "   [[ 4.28392500e-01]\n",
      "    [ 2.22904682e-02]\n",
      "    [-6.46689713e-01]\n",
      "    ...\n",
      "    [ 2.04596236e-01]\n",
      "    [ 5.52960634e-01]\n",
      "    [-3.86807412e-01]]]\n",
      "\n",
      "\n",
      "  [[[-3.95788312e-01]\n",
      "    [ 3.24973643e-01]\n",
      "    [ 1.13579738e+00]\n",
      "    ...\n",
      "    [-8.72160971e-01]\n",
      "    [ 6.00153685e-01]\n",
      "    [ 5.96450448e-01]]\n",
      "\n",
      "   [[-4.85577941e-01]\n",
      "    [-3.95538002e-01]\n",
      "    [ 7.31006980e-01]\n",
      "    ...\n",
      "    [ 1.29879844e+00]\n",
      "    [ 5.71128428e-02]\n",
      "    [-1.01097679e+00]]\n",
      "\n",
      "   [[-6.78831816e-01]\n",
      "    [-9.52858984e-01]\n",
      "    [ 1.05686462e+00]\n",
      "    ...\n",
      "    [ 1.59563994e+00]\n",
      "    [ 2.71777320e+00]\n",
      "    [-1.20281696e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 1.92838505e-01]\n",
      "    [-2.05755800e-01]\n",
      "    [ 1.11009002e+00]\n",
      "    ...\n",
      "    [ 6.24742150e-01]\n",
      "    [-2.20335826e-01]\n",
      "    [ 7.52270669e-02]]\n",
      "\n",
      "   [[ 1.77497670e-01]\n",
      "    [-6.09201938e-02]\n",
      "    [ 1.04616654e+00]\n",
      "    ...\n",
      "    [ 7.06723511e-01]\n",
      "    [ 2.87230253e-01]\n",
      "    [-4.00067195e-02]]\n",
      "\n",
      "   [[ 2.58860528e-01]\n",
      "    [ 3.24542761e-01]\n",
      "    [ 1.11346817e+00]\n",
      "    ...\n",
      "    [-1.18627720e-01]\n",
      "    [ 9.99271423e-02]\n",
      "    [-3.15496773e-01]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[-1.59796858e+00]\n",
      "    [-9.06258881e-01]\n",
      "    [ 1.12260468e-01]\n",
      "    ...\n",
      "    [-1.14599526e+00]\n",
      "    [ 1.00228405e+00]\n",
      "    [ 8.89892951e-02]]\n",
      "\n",
      "   [[-1.49399912e+00]\n",
      "    [-6.95096076e-01]\n",
      "    [ 3.02131232e-02]\n",
      "    ...\n",
      "    [ 1.21246791e+00]\n",
      "    [-2.43482161e+00]\n",
      "    [ 1.50658572e+00]]\n",
      "\n",
      "   [[-1.34797728e+00]\n",
      "    [-5.39177716e-01]\n",
      "    [ 3.25298123e-02]\n",
      "    ...\n",
      "    [ 2.64545655e+00]\n",
      "    [-1.79414615e-01]\n",
      "    [-6.44868314e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 7.81459510e-01]\n",
      "    [-2.73101687e-01]\n",
      "    [-8.17689836e-01]\n",
      "    ...\n",
      "    [-1.77358896e-01]\n",
      "    [ 7.74656355e-01]\n",
      "    [-2.33597055e-01]]\n",
      "\n",
      "   [[ 7.60336518e-01]\n",
      "    [-2.45212749e-01]\n",
      "    [-9.81099129e-01]\n",
      "    ...\n",
      "    [ 2.47954950e-01]\n",
      "    [ 8.61487150e-01]\n",
      "    [ 1.30013362e-01]]\n",
      "\n",
      "   [[ 6.91991210e-01]\n",
      "    [-4.90332097e-01]\n",
      "    [-1.01870263e+00]\n",
      "    ...\n",
      "    [-6.69563830e-01]\n",
      "    [-1.78811395e+00]\n",
      "    [-1.99351266e-01]]]\n",
      "\n",
      "\n",
      "  [[[-1.53136754e+00]\n",
      "    [-6.34424865e-01]\n",
      "    [ 1.56528957e-03]\n",
      "    ...\n",
      "    [ 1.13980365e+00]\n",
      "    [-2.72934556e+00]\n",
      "    [ 1.06421739e-01]]\n",
      "\n",
      "   [[-1.37391734e+00]\n",
      "    [-5.06320059e-01]\n",
      "    [-1.84826091e-01]\n",
      "    ...\n",
      "    [ 8.16311777e-01]\n",
      "    [-2.23810625e+00]\n",
      "    [ 1.64807236e+00]]\n",
      "\n",
      "   [[-1.39831161e+00]\n",
      "    [-8.17478418e-01]\n",
      "    [-2.01897368e-01]\n",
      "    ...\n",
      "    [-1.77024376e+00]\n",
      "    [-6.10973954e-01]\n",
      "    [-2.33094740e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 9.09078777e-01]\n",
      "    [-1.51209638e-01]\n",
      "    [-7.63382852e-01]\n",
      "    ...\n",
      "    [ 6.55995846e-01]\n",
      "    [ 5.94178140e-01]\n",
      "    [-3.82772654e-01]]\n",
      "\n",
      "   [[ 6.01372242e-01]\n",
      "    [-2.50140548e-01]\n",
      "    [-1.13320863e+00]\n",
      "    ...\n",
      "    [ 2.88803518e-01]\n",
      "    [-1.54917359e-01]\n",
      "    [ 4.79851551e-02]]\n",
      "\n",
      "   [[-4.04699951e-01]\n",
      "    [-3.75608690e-02]\n",
      "    [-7.67774880e-01]\n",
      "    ...\n",
      "    [ 1.43123746e+00]\n",
      "    [ 7.94536591e-01]\n",
      "    [ 4.90072072e-01]]]\n",
      "\n",
      "\n",
      "  [[[-1.61999321e+00]\n",
      "    [-9.38299298e-01]\n",
      "    [ 1.79338139e-02]\n",
      "    ...\n",
      "    [ 2.91918933e-01]\n",
      "    [ 2.21525416e-01]\n",
      "    [-9.31403518e-01]]\n",
      "\n",
      "   [[-1.54119658e+00]\n",
      "    [-8.33791435e-01]\n",
      "    [ 1.24001339e-01]\n",
      "    ...\n",
      "    [-6.89906955e-01]\n",
      "    [ 1.39450097e+00]\n",
      "    [ 3.54135185e-01]]\n",
      "\n",
      "   [[-1.27570820e+00]\n",
      "    [-4.54058379e-01]\n",
      "    [-1.81855887e-01]\n",
      "    ...\n",
      "    [ 9.31337595e-01]\n",
      "    [ 1.05193757e-01]\n",
      "    [-1.59392238e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 8.40581357e-01]\n",
      "    [ 7.35883019e-04]\n",
      "    [-8.89890730e-01]\n",
      "    ...\n",
      "    [ 2.20261872e-01]\n",
      "    [-1.58633304e+00]\n",
      "    [-2.11681426e-01]]\n",
      "\n",
      "   [[ 5.68373859e-01]\n",
      "    [-1.54782727e-01]\n",
      "    [-1.00658417e+00]\n",
      "    ...\n",
      "    [ 1.23822028e-02]\n",
      "    [ 4.60964888e-01]\n",
      "    [ 3.72875214e-01]]\n",
      "\n",
      "   [[-5.55191576e-01]\n",
      "    [-3.95878822e-01]\n",
      "    [-1.14346409e+00]\n",
      "    ...\n",
      "    [ 7.57156134e-01]\n",
      "    [ 1.46916911e-01]\n",
      "    [ 8.54979098e-01]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 1.03274000e+00]\n",
      "    [ 1.25702894e+00]\n",
      "    [-2.24705085e-01]\n",
      "    ...\n",
      "    [ 5.10611355e-01]\n",
      "    [ 2.41469249e-01]\n",
      "    [-2.16219378e+00]]\n",
      "\n",
      "   [[ 1.05411482e+00]\n",
      "    [ 1.03165150e+00]\n",
      "    [-3.22778016e-01]\n",
      "    ...\n",
      "    [ 3.44203144e-01]\n",
      "    [ 3.08462620e-01]\n",
      "    [-2.65588313e-01]]\n",
      "\n",
      "   [[ 1.15772188e+00]\n",
      "    [ 3.27056348e-01]\n",
      "    [-4.17105287e-01]\n",
      "    ...\n",
      "    [ 1.39791858e+00]\n",
      "    [-9.90711674e-02]\n",
      "    [ 1.86174437e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 8.29426050e-01]\n",
      "    [ 7.92333305e-01]\n",
      "    [-3.48347664e-01]\n",
      "    ...\n",
      "    [ 1.46013498e+00]\n",
      "    [-5.12874365e-01]\n",
      "    [ 1.27313876e+00]]\n",
      "\n",
      "   [[-3.94591391e-01]\n",
      "    [ 8.15052912e-02]\n",
      "    [-2.54277676e-01]\n",
      "    ...\n",
      "    [ 9.86638665e-01]\n",
      "    [-3.03341448e-01]\n",
      "    [ 5.20530403e-01]]\n",
      "\n",
      "   [[-1.31532109e+00]\n",
      "    [-1.18937290e+00]\n",
      "    [ 6.23365343e-01]\n",
      "    ...\n",
      "    [-1.88729596e+00]\n",
      "    [ 2.16726065e+00]\n",
      "    [-5.09348392e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 1.05831039e+00]\n",
      "    [ 1.23492932e+00]\n",
      "    [-3.88257444e-01]\n",
      "    ...\n",
      "    [ 2.43680909e-01]\n",
      "    [-2.88203470e-02]\n",
      "    [-1.98347747e+00]]\n",
      "\n",
      "   [[ 1.05535483e+00]\n",
      "    [ 1.29888892e+00]\n",
      "    [-2.93804169e-01]\n",
      "    ...\n",
      "    [ 4.38181683e-02]\n",
      "    [ 1.26032665e-01]\n",
      "    [-2.10697365e+00]]\n",
      "\n",
      "   [[ 1.10370064e+00]\n",
      "    [ 6.26808465e-01]\n",
      "    [-2.93733150e-01]\n",
      "    ...\n",
      "    [ 1.27788812e-01]\n",
      "    [-4.09962773e-01]\n",
      "    [ 6.74508512e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 9.22309339e-01]\n",
      "    [ 1.22652566e+00]\n",
      "    [-2.00139523e-01]\n",
      "    ...\n",
      "    [ 3.49464715e-01]\n",
      "    [-7.47940168e-02]\n",
      "    [-8.64883065e-02]]\n",
      "\n",
      "   [[ 1.36991173e-01]\n",
      "    [ 1.22609937e+00]\n",
      "    [-2.12929919e-01]\n",
      "    ...\n",
      "    [ 1.23609412e+00]\n",
      "    [-8.22479188e-01]\n",
      "    [ 4.06710535e-01]]\n",
      "\n",
      "   [[-6.49030983e-01]\n",
      "    [ 6.33127451e-01]\n",
      "    [ 4.12911415e-01]\n",
      "    ...\n",
      "    [ 4.91965525e-02]\n",
      "    [-4.72936541e-01]\n",
      "    [ 1.39570391e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.08149385e+00]\n",
      "    [ 1.03905308e+00]\n",
      "    [-3.60813737e-01]\n",
      "    ...\n",
      "    [ 2.84932882e-01]\n",
      "    [ 3.20814371e-01]\n",
      "    [-3.17390621e-01]]\n",
      "\n",
      "   [[ 1.07082117e+00]\n",
      "    [ 1.39782357e+00]\n",
      "    [-3.11092019e-01]\n",
      "    ...\n",
      "    [ 6.15333974e-01]\n",
      "    [ 6.38754725e-01]\n",
      "    [-1.22457731e+00]]\n",
      "\n",
      "   [[ 1.09812975e+00]\n",
      "    [ 1.03617191e+00]\n",
      "    [-3.40177834e-01]\n",
      "    ...\n",
      "    [ 3.92158002e-01]\n",
      "    [ 3.14772367e-01]\n",
      "    [-5.94200790e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 1.01364589e+00]\n",
      "    [ 1.37039888e+00]\n",
      "    [-2.75612567e-02]\n",
      "    ...\n",
      "    [ 9.49641526e-01]\n",
      "    [ 1.81098759e-01]\n",
      "    [-5.22186220e-01]]\n",
      "\n",
      "   [[ 2.35378534e-01]\n",
      "    [ 1.02219665e+00]\n",
      "    [-4.83664691e-01]\n",
      "    ...\n",
      "    [ 9.93148625e-01]\n",
      "    [-2.49994144e-01]\n",
      "    [-1.15057290e+00]]\n",
      "\n",
      "   [[-7.29499280e-01]\n",
      "    [ 3.16390514e-01]\n",
      "    [ 9.98207852e-02]\n",
      "    ...\n",
      "    [ 2.16886476e-01]\n",
      "    [-1.73162311e-01]\n",
      "    [ 1.86855912e+00]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[ 1.14308274e+00]\n",
      "    [ 7.30698168e-01]\n",
      "    [-7.19144881e-01]\n",
      "    ...\n",
      "    [-1.60799939e-02]\n",
      "    [ 1.17504053e-01]\n",
      "    [ 7.54178762e-01]]\n",
      "\n",
      "   [[ 1.23191428e+00]\n",
      "    [ 1.34115189e-01]\n",
      "    [-4.17563111e-01]\n",
      "    ...\n",
      "    [-9.04428899e-01]\n",
      "    [ 2.30198398e-01]\n",
      "    [-1.66640446e-01]]\n",
      "\n",
      "   [[ 1.32393086e+00]\n",
      "    [-3.71676773e-01]\n",
      "    [-4.14485205e-03]\n",
      "    ...\n",
      "    [-4.36704308e-02]\n",
      "    [ 3.33684593e-01]\n",
      "    [-1.60769731e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 1.18497503e+00]\n",
      "    [ 2.59085596e-01]\n",
      "    [ 1.45937219e-01]\n",
      "    ...\n",
      "    [-1.57968330e+00]\n",
      "    [ 1.79815501e-01]\n",
      "    [-4.33153898e-01]]\n",
      "\n",
      "   [[ 1.10960793e+00]\n",
      "    [ 1.05617535e+00]\n",
      "    [ 1.43507287e-01]\n",
      "    ...\n",
      "    [ 2.79050708e-01]\n",
      "    [ 2.15283275e-01]\n",
      "    [ 1.65247470e-01]]\n",
      "\n",
      "   [[ 8.26517344e-01]\n",
      "    [ 8.24435472e-01]\n",
      "    [-9.96411592e-02]\n",
      "    ...\n",
      "    [-1.54769659e+00]\n",
      "    [ 1.80901334e-01]\n",
      "    [ 3.67973208e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 1.13712132e+00]\n",
      "    [ 7.82991767e-01]\n",
      "    [-6.16975546e-01]\n",
      "    ...\n",
      "    [ 2.57631421e-01]\n",
      "    [-4.01913255e-01]\n",
      "    [ 8.52653027e-01]]\n",
      "\n",
      "   [[ 1.26296127e+00]\n",
      "    [ 1.22123308e-01]\n",
      "    [-5.82456529e-01]\n",
      "    ...\n",
      "    [ 1.68023825e+00]\n",
      "    [-3.12589318e-01]\n",
      "    [ 2.35387072e-01]]\n",
      "\n",
      "   [[ 1.36130261e+00]\n",
      "    [-6.56420708e-01]\n",
      "    [-9.83310714e-02]\n",
      "    ...\n",
      "    [ 2.15582266e-01]\n",
      "    [ 6.49422705e-01]\n",
      "    [-1.80400610e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 1.05115974e+00]\n",
      "    [ 8.89896810e-01]\n",
      "    [ 2.24863412e-03]\n",
      "    ...\n",
      "    [ 3.16994011e-01]\n",
      "    [ 3.46281946e-01]\n",
      "    [-3.20490450e-01]]\n",
      "\n",
      "   [[ 9.20915067e-01]\n",
      "    [ 1.25196767e+00]\n",
      "    [ 2.14737326e-01]\n",
      "    ...\n",
      "    [ 8.75745654e-01]\n",
      "    [ 6.38395607e-01]\n",
      "    [ 1.43388295e+00]]\n",
      "\n",
      "   [[ 8.21592033e-01]\n",
      "    [ 1.18597937e+00]\n",
      "    [-8.49861428e-02]\n",
      "    ...\n",
      "    [ 1.15819538e+00]\n",
      "    [-3.41913283e-01]\n",
      "    [-3.25175226e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 1.13176489e+00]\n",
      "    [ 7.76088536e-01]\n",
      "    [-6.78383231e-01]\n",
      "    ...\n",
      "    [ 2.09890351e-01]\n",
      "    [-5.50416410e-02]\n",
      "    [ 4.95056450e-01]]\n",
      "\n",
      "   [[ 1.20140624e+00]\n",
      "    [ 3.74927521e-01]\n",
      "    [-6.32893920e-01]\n",
      "    ...\n",
      "    [ 1.54916048e+00]\n",
      "    [-2.27315918e-01]\n",
      "    [ 3.25693697e-01]]\n",
      "\n",
      "   [[ 1.29541910e+00]\n",
      "    [-3.24829072e-01]\n",
      "    [-1.88297063e-01]\n",
      "    ...\n",
      "    [ 4.19548154e-02]\n",
      "    [ 1.61672339e-01]\n",
      "    [-1.98244855e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 1.19567156e+00]\n",
      "    [-5.24535850e-02]\n",
      "    [-2.47474775e-01]\n",
      "    ...\n",
      "    [-7.94370532e-01]\n",
      "    [ 3.19536895e-01]\n",
      "    [-1.58558354e-01]]\n",
      "\n",
      "   [[ 1.16429520e+00]\n",
      "    [-9.26507264e-02]\n",
      "    [-1.89161003e-01]\n",
      "    ...\n",
      "    [-6.30113304e-01]\n",
      "    [ 4.23044302e-02]\n",
      "    [ 7.21033290e-02]]\n",
      "\n",
      "   [[ 9.14017379e-01]\n",
      "    [ 5.20114064e-01]\n",
      "    [-5.78694046e-01]\n",
      "    ...\n",
      "    [-3.80204409e-01]\n",
      "    [ 2.05745213e-02]\n",
      "    [ 3.73479664e-01]]]]\n",
      "\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 1.75851077e-01]\n",
      "    [ 2.44408980e-01]\n",
      "    [-2.37099504e+00]\n",
      "    ...\n",
      "    [-2.17086643e-01]\n",
      "    [-1.81608582e+00]\n",
      "    [ 1.61797631e+00]]\n",
      "\n",
      "   [[ 1.67257190e-01]\n",
      "    [ 1.94693521e-01]\n",
      "    [-2.37027860e+00]\n",
      "    ...\n",
      "    [-2.47660086e-01]\n",
      "    [-1.74889886e+00]\n",
      "    [ 1.93138254e+00]]\n",
      "\n",
      "   [[ 1.77729592e-01]\n",
      "    [ 1.84063286e-01]\n",
      "    [-2.26370049e+00]\n",
      "    ...\n",
      "    [ 4.48474139e-01]\n",
      "    [ 4.85543311e-01]\n",
      "    [ 2.03248048e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 1.00929484e-01]\n",
      "    [-3.11970115e-02]\n",
      "    [-2.32055211e+00]\n",
      "    ...\n",
      "    [-1.00754142e+00]\n",
      "    [-1.14635706e+00]\n",
      "    [ 2.03951907e+00]]\n",
      "\n",
      "   [[ 6.00073598e-02]\n",
      "    [-9.37659368e-02]\n",
      "    [-2.28108978e+00]\n",
      "    ...\n",
      "    [ 6.58320487e-02]\n",
      "    [ 4.55218822e-01]\n",
      "    [ 2.03903699e+00]]\n",
      "\n",
      "   [[ 1.27994949e-02]\n",
      "    [-2.02015385e-01]\n",
      "    [-1.96935773e+00]\n",
      "    ...\n",
      "    [ 2.90267318e-01]\n",
      "    [ 6.31615967e-02]\n",
      "    [ 2.02846169e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.80927902e-01]\n",
      "    [ 2.53378630e-01]\n",
      "    [-2.38560820e+00]\n",
      "    ...\n",
      "    [-2.80708402e-01]\n",
      "    [-2.11052513e+00]\n",
      "    [ 1.71957958e+00]]\n",
      "\n",
      "   [[ 1.71582222e-01]\n",
      "    [ 8.47694501e-02]\n",
      "    [-2.20677590e+00]\n",
      "    ...\n",
      "    [-2.13976189e-01]\n",
      "    [-1.73162973e+00]\n",
      "    [ 1.85538065e+00]]\n",
      "\n",
      "   [[ 1.46578968e-01]\n",
      "    [ 3.73315029e-02]\n",
      "    [-2.11636734e+00]\n",
      "    ...\n",
      "    [-6.31503582e-01]\n",
      "    [-1.62783527e+00]\n",
      "    [ 1.71634924e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 2.59247478e-02]\n",
      "    [-1.45155445e-01]\n",
      "    [-2.22863460e+00]\n",
      "    ...\n",
      "    [-3.23420405e-01]\n",
      "    [-1.68295562e+00]\n",
      "    [ 1.77076364e+00]]\n",
      "\n",
      "   [[ 2.57183611e-02]\n",
      "    [-1.44530609e-01]\n",
      "    [-2.25090122e+00]\n",
      "    ...\n",
      "    [ 1.18458748e-01]\n",
      "    [ 2.34646249e+00]\n",
      "    [ 1.95738614e+00]]\n",
      "\n",
      "   [[-9.07962117e-03]\n",
      "    [-2.50837892e-01]\n",
      "    [-2.03529239e+00]\n",
      "    ...\n",
      "    [-3.06693047e-01]\n",
      "    [ 1.91054058e+00]\n",
      "    [ 2.34306741e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.32226169e-01]\n",
      "    [ 2.98545450e-01]\n",
      "    [-2.53673291e+00]\n",
      "    ...\n",
      "    [ 1.17015541e+00]\n",
      "    [-1.76615119e+00]\n",
      "    [-6.16236448e-01]]\n",
      "\n",
      "   [[ 1.60273463e-01]\n",
      "    [ 6.22453019e-02]\n",
      "    [-2.38236856e+00]\n",
      "    ...\n",
      "    [-3.95751953e-01]\n",
      "    [-1.32126331e+00]\n",
      "    [ 1.59747422e+00]]\n",
      "\n",
      "   [[ 8.46583247e-02]\n",
      "    [ 7.31599377e-03]\n",
      "    [-2.39120269e+00]\n",
      "    ...\n",
      "    [ 2.27686137e-01]\n",
      "    [ 1.88461140e-01]\n",
      "    [ 2.25581551e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 5.99686205e-02]\n",
      "    [-6.73302412e-02]\n",
      "    [-1.98053861e+00]\n",
      "    ...\n",
      "    [-2.75303870e-01]\n",
      "    [ 7.36217797e-01]\n",
      "    [ 2.04652715e+00]]\n",
      "\n",
      "   [[ 2.99620964e-02]\n",
      "    [-1.69444874e-01]\n",
      "    [-1.99409497e+00]\n",
      "    ...\n",
      "    [-1.21310301e-01]\n",
      "    [ 1.13980579e+00]\n",
      "    [ 1.93918347e+00]]\n",
      "\n",
      "   [[-1.93110742e-02]\n",
      "    [-2.95109957e-01]\n",
      "    [-1.53012288e+00]\n",
      "    ...\n",
      "    [-2.76636153e-01]\n",
      "    [-1.65760982e+00]\n",
      "    [ 1.42560899e+00]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[ 1.39242679e-01]\n",
      "    [-3.93779844e-01]\n",
      "    [-1.50135148e+00]\n",
      "    ...\n",
      "    [ 3.79510343e-01]\n",
      "    [ 3.08525383e-01]\n",
      "    [-4.13397014e-01]]\n",
      "\n",
      "   [[ 1.59666032e-01]\n",
      "    [-4.07715231e-01]\n",
      "    [-1.44593751e+00]\n",
      "    ...\n",
      "    [ 6.21791124e-01]\n",
      "    [-7.06042767e-01]\n",
      "    [-3.73894721e-01]]\n",
      "\n",
      "   [[ 1.63871929e-01]\n",
      "    [-3.94329578e-01]\n",
      "    [-1.55936325e+00]\n",
      "    ...\n",
      "    [ 5.30623317e-01]\n",
      "    [-9.50044572e-01]\n",
      "    [-8.47638607e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 2.08522826e-01]\n",
      "    [-3.98290634e-01]\n",
      "    [-1.56635785e+00]\n",
      "    ...\n",
      "    [ 2.73920715e-01]\n",
      "    [ 1.47924379e-01]\n",
      "    [-5.35607994e-01]]\n",
      "\n",
      "   [[ 1.73951074e-01]\n",
      "    [-3.98142427e-01]\n",
      "    [-1.70134115e+00]\n",
      "    ...\n",
      "    [ 2.46691659e-01]\n",
      "    [ 4.95059103e-01]\n",
      "    [-2.44757965e-01]]\n",
      "\n",
      "   [[ 1.30093157e-01]\n",
      "    [-3.80660295e-01]\n",
      "    [-1.82161772e+00]\n",
      "    ...\n",
      "    [ 5.07852137e-01]\n",
      "    [ 2.33180213e+00]\n",
      "    [-7.23028034e-02]]]\n",
      "\n",
      "\n",
      "  [[[ 1.74121372e-02]\n",
      "    [-2.94632047e-01]\n",
      "    [-1.83034444e+00]\n",
      "    ...\n",
      "    [-8.15937161e-01]\n",
      "    [-3.59963357e-01]\n",
      "    [ 1.73311317e+00]]\n",
      "\n",
      "   [[ 5.70227504e-02]\n",
      "    [-2.53785193e-01]\n",
      "    [-1.80393589e+00]\n",
      "    ...\n",
      "    [ 1.00829855e-01]\n",
      "    [ 2.38202676e-01]\n",
      "    [ 1.32294297e+00]]\n",
      "\n",
      "   [[ 8.31905976e-02]\n",
      "    [-3.84235114e-01]\n",
      "    [-1.62085414e+00]\n",
      "    ...\n",
      "    [ 8.32048357e-01]\n",
      "    [-8.87997806e-01]\n",
      "    [ 7.11180925e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 7.24987835e-02]\n",
      "    [-6.25919104e-01]\n",
      "    [-1.30647647e+00]\n",
      "    ...\n",
      "    [ 3.73244315e-01]\n",
      "    [-1.88933444e+00]\n",
      "    [-8.06961656e-01]]\n",
      "\n",
      "   [[ 3.34075317e-02]\n",
      "    [-5.92603981e-01]\n",
      "    [-1.33403862e+00]\n",
      "    ...\n",
      "    [ 7.19351828e-01]\n",
      "    [-2.24328518e+00]\n",
      "    [ 3.19637693e-02]]\n",
      "\n",
      "   [[ 8.21156427e-02]\n",
      "    [-6.79186404e-01]\n",
      "    [-1.04821253e+00]\n",
      "    ...\n",
      "    [ 6.20106399e-01]\n",
      "    [-2.02847815e+00]\n",
      "    [-7.37875462e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 1.44243553e-01]\n",
      "    [-1.25260890e-01]\n",
      "    [-2.19245124e+00]\n",
      "    ...\n",
      "    [-1.59321070e-01]\n",
      "    [ 2.64822984e+00]\n",
      "    [ 1.14882517e+00]]\n",
      "\n",
      "   [[ 1.80987611e-01]\n",
      "    [-2.75789380e-01]\n",
      "    [-1.87993431e+00]\n",
      "    ...\n",
      "    [ 9.56673384e-01]\n",
      "    [ 5.59060240e+00]\n",
      "    [-4.34049636e-01]]\n",
      "\n",
      "   [[ 1.67537436e-01]\n",
      "    [-4.17777121e-01]\n",
      "    [-1.60030437e+00]\n",
      "    ...\n",
      "    [ 4.72697109e-01]\n",
      "    [ 4.41410840e-01]\n",
      "    [-5.38037241e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 1.29322231e-01]\n",
      "    [-5.48947573e-01]\n",
      "    [-1.21979892e+00]\n",
      "    ...\n",
      "    [ 5.30570924e-01]\n",
      "    [-1.58048081e+00]\n",
      "    [-8.39033127e-01]]\n",
      "\n",
      "   [[ 1.25186354e-01]\n",
      "    [-4.88013536e-01]\n",
      "    [-1.26516378e+00]\n",
      "    ...\n",
      "    [ 6.32843971e-01]\n",
      "    [-8.04357767e-01]\n",
      "    [-5.33704400e-01]]\n",
      "\n",
      "   [[ 9.62595120e-02]\n",
      "    [-4.96934414e-01]\n",
      "    [-1.42773616e+00]\n",
      "    ...\n",
      "    [ 5.66211820e-01]\n",
      "    [ 7.59743154e-01]\n",
      "    [-4.24793184e-01]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 8.90599668e-01]\n",
      "    [-8.90478268e-02]\n",
      "    [-1.14636838e+00]\n",
      "    ...\n",
      "    [ 1.08762181e+00]\n",
      "    [ 3.45884025e-01]\n",
      "    [-4.55084056e-01]]\n",
      "\n",
      "   [[ 8.52306604e-01]\n",
      "    [-1.53753713e-01]\n",
      "    [-1.12703609e+00]\n",
      "    ...\n",
      "    [ 4.58419137e-02]\n",
      "    [ 4.36494112e-01]\n",
      "    [-4.18442190e-01]]\n",
      "\n",
      "   [[ 8.24455619e-01]\n",
      "    [ 1.33706667e-02]\n",
      "    [-1.27668417e+00]\n",
      "    ...\n",
      "    [ 5.13246953e-01]\n",
      "    [ 3.52870435e-01]\n",
      "    [-4.86947358e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 7.98879206e-01]\n",
      "    [-5.58666140e-02]\n",
      "    [-1.22978592e+00]\n",
      "    ...\n",
      "    [ 5.77514648e-01]\n",
      "    [ 6.01665015e-05]\n",
      "    [-1.85643598e-01]]\n",
      "\n",
      "   [[ 7.68324137e-01]\n",
      "    [-2.62630612e-01]\n",
      "    [-8.75699937e-01]\n",
      "    ...\n",
      "    [ 2.63110906e-01]\n",
      "    [ 3.67370188e-01]\n",
      "    [-2.57432938e-01]]\n",
      "\n",
      "   [[ 6.99324369e-01]\n",
      "    [-3.09867829e-01]\n",
      "    [ 2.26882204e-01]\n",
      "    ...\n",
      "    [-4.06167746e-01]\n",
      "    [ 2.93653756e-01]\n",
      "    [ 6.08404279e-02]]]\n",
      "\n",
      "\n",
      "  [[[ 5.99353850e-01]\n",
      "    [-3.34527902e-02]\n",
      "    [-6.55363321e-01]\n",
      "    ...\n",
      "    [ 1.10126875e-01]\n",
      "    [ 6.42247558e-01]\n",
      "    [-4.65715319e-01]]\n",
      "\n",
      "   [[ 6.86487675e-01]\n",
      "    [ 5.18110655e-02]\n",
      "    [-7.36738861e-01]\n",
      "    ...\n",
      "    [ 9.38301146e-01]\n",
      "    [ 4.43982393e-01]\n",
      "    [-1.23987861e-01]]\n",
      "\n",
      "   [[ 6.42318726e-01]\n",
      "    [ 1.37580618e-01]\n",
      "    [-8.95462871e-01]\n",
      "    ...\n",
      "    [ 5.76555848e-01]\n",
      "    [ 9.02017117e-01]\n",
      "    [-1.96275860e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 5.79474628e-01]\n",
      "    [ 6.06440566e-02]\n",
      "    [-1.04067683e+00]\n",
      "    ...\n",
      "    [-2.83441693e-01]\n",
      "    [ 1.00806987e+00]\n",
      "    [-2.40117088e-01]]\n",
      "\n",
      "   [[ 5.99545538e-01]\n",
      "    [-1.00454360e-01]\n",
      "    [-8.21239948e-01]\n",
      "    ...\n",
      "    [ 1.90613028e-02]\n",
      "    [ 7.82339871e-01]\n",
      "    [-2.21105441e-01]]\n",
      "\n",
      "   [[ 6.18284583e-01]\n",
      "    [-3.08884025e-01]\n",
      "    [ 1.38086304e-01]\n",
      "    ...\n",
      "    [-2.52439409e-01]\n",
      "    [ 6.37737989e-01]\n",
      "    [-9.70053151e-02]]]\n",
      "\n",
      "\n",
      "  [[[-3.44326496e-02]\n",
      "    [ 1.06929374e+00]\n",
      "    [ 9.60370719e-01]\n",
      "    ...\n",
      "    [ 9.87282753e-01]\n",
      "    [-5.90652972e-02]\n",
      "    [ 5.53119779e-01]]\n",
      "\n",
      "   [[-8.16143155e-02]\n",
      "    [ 7.79749930e-01]\n",
      "    [ 1.16626215e+00]\n",
      "    ...\n",
      "    [ 2.59238094e-01]\n",
      "    [-1.83391109e-01]\n",
      "    [-4.10566568e-01]]\n",
      "\n",
      "   [[-1.78016454e-01]\n",
      "    [ 5.93896568e-01]\n",
      "    [ 1.08570957e+00]\n",
      "    ...\n",
      "    [ 1.24140525e+00]\n",
      "    [-4.50735867e-01]\n",
      "    [ 6.24141514e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-2.89407551e-01]\n",
      "    [ 6.26703739e-01]\n",
      "    [-4.13358480e-01]\n",
      "    ...\n",
      "    [ 1.12796381e-01]\n",
      "    [ 5.63727200e-01]\n",
      "    [-3.36215407e-01]]\n",
      "\n",
      "   [[-6.55654743e-02]\n",
      "    [ 5.34796059e-01]\n",
      "    [-7.05506921e-01]\n",
      "    ...\n",
      "    [-5.78136921e-01]\n",
      "    [ 5.26109815e-01]\n",
      "    [-1.40660143e+00]]\n",
      "\n",
      "   [[ 1.57406047e-01]\n",
      "    [-3.60724777e-02]\n",
      "    [ 6.43837810e-01]\n",
      "    ...\n",
      "    [ 1.60383005e-02]\n",
      "    [ 7.32154548e-02]\n",
      "    [-5.05206846e-02]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[ 5.85321546e-01]\n",
      "    [ 4.34649065e-02]\n",
      "    [-1.17096233e+00]\n",
      "    ...\n",
      "    [-7.80365989e-02]\n",
      "    [ 4.93473470e-01]\n",
      "    [-6.31790310e-02]]\n",
      "\n",
      "   [[ 5.30480742e-01]\n",
      "    [-4.97822762e-02]\n",
      "    [-1.18110132e+00]\n",
      "    ...\n",
      "    [ 1.32208705e-01]\n",
      "    [ 7.79367447e-01]\n",
      "    [-1.81210533e-01]]\n",
      "\n",
      "   [[ 4.78599310e-01]\n",
      "    [ 3.22190046e-01]\n",
      "    [-1.20538473e+00]\n",
      "    ...\n",
      "    [ 1.04100943e+00]\n",
      "    [ 1.00394860e-01]\n",
      "    [-1.29952759e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 3.47893894e-01]\n",
      "    [ 9.90498722e-01]\n",
      "    [-5.37928402e-01]\n",
      "    ...\n",
      "    [-6.66134655e-01]\n",
      "    [ 1.70005903e-01]\n",
      "    [ 5.30462444e-01]]\n",
      "\n",
      "   [[ 1.28661573e-01]\n",
      "    [ 1.00653040e+00]\n",
      "    [-5.20564497e-01]\n",
      "    ...\n",
      "    [-5.15083313e-01]\n",
      "    [ 8.71243477e-02]\n",
      "    [-9.55510557e-01]]\n",
      "\n",
      "   [[-2.07535744e-01]\n",
      "    [ 3.01214367e-01]\n",
      "    [ 1.64347276e-01]\n",
      "    ...\n",
      "    [-4.67521220e-01]\n",
      "    [ 1.11599145e-02]\n",
      "    [-4.56128299e-01]]]\n",
      "\n",
      "\n",
      "  [[[-1.03736591e+00]\n",
      "    [ 7.56797373e-01]\n",
      "    [ 1.02723861e+00]\n",
      "    ...\n",
      "    [-5.77648401e-01]\n",
      "    [ 6.78210035e-02]\n",
      "    [-6.31581008e-01]]\n",
      "\n",
      "   [[-1.14822638e+00]\n",
      "    [ 3.25472385e-01]\n",
      "    [ 8.64318788e-01]\n",
      "    ...\n",
      "    [ 9.10957992e-01]\n",
      "    [ 3.79490480e-02]\n",
      "    [-3.75279970e-02]]\n",
      "\n",
      "   [[-1.23184609e+00]\n",
      "    [ 3.57468277e-01]\n",
      "    [ 6.92965984e-01]\n",
      "    ...\n",
      "    [ 4.68539074e-02]\n",
      "    [-5.34262061e-01]\n",
      "    [-1.00984728e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-1.34002340e+00]\n",
      "    [ 1.71578765e-01]\n",
      "    [ 4.07824904e-01]\n",
      "    ...\n",
      "    [-3.96423489e-01]\n",
      "    [-5.18646371e-03]\n",
      "    [-6.98799133e-01]]\n",
      "\n",
      "   [[-1.16024768e+00]\n",
      "    [ 6.64882839e-01]\n",
      "    [ 9.65726614e-01]\n",
      "    ...\n",
      "    [ 4.87897426e-01]\n",
      "    [ 1.07860409e-01]\n",
      "    [-1.22658658e+00]]\n",
      "\n",
      "   [[-8.88666570e-01]\n",
      "    [ 7.83823431e-02]\n",
      "    [ 1.03103578e+00]\n",
      "    ...\n",
      "    [ 2.04817459e-01]\n",
      "    [-2.13682622e-01]\n",
      "    [ 2.15274978e+00]]]\n",
      "\n",
      "\n",
      "  [[[-1.39965010e+00]\n",
      "    [ 3.60037908e-02]\n",
      "    [ 5.90819061e-01]\n",
      "    ...\n",
      "    [-2.18797565e-01]\n",
      "    [-4.07131255e-01]\n",
      "    [-7.44157284e-02]]\n",
      "\n",
      "   [[-1.44030952e+00]\n",
      "    [ 8.48779306e-02]\n",
      "    [ 4.50448871e-01]\n",
      "    ...\n",
      "    [ 8.83737385e-01]\n",
      "    [-2.23123714e-01]\n",
      "    [-7.70114005e-01]]\n",
      "\n",
      "   [[-1.49575746e+00]\n",
      "    [-4.45484877e-01]\n",
      "    [ 4.09988537e-02]\n",
      "    ...\n",
      "    [ 5.53431988e-01]\n",
      "    [-2.90419912e+00]\n",
      "    [ 2.75849164e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-1.40045786e+00]\n",
      "    [-2.59936601e-01]\n",
      "    [ 3.56241137e-01]\n",
      "    ...\n",
      "    [ 1.87326387e-01]\n",
      "    [-8.77588153e-01]\n",
      "    [ 7.56189004e-02]]\n",
      "\n",
      "   [[-1.28826427e+00]\n",
      "    [-6.65668696e-02]\n",
      "    [ 8.83802593e-01]\n",
      "    ...\n",
      "    [ 2.42507756e-01]\n",
      "    [-4.40846652e-01]\n",
      "    [ 1.37910983e-02]]\n",
      "\n",
      "   [[-7.80960441e-01]\n",
      "    [ 7.13284910e-02]\n",
      "    [ 8.42428863e-01]\n",
      "    ...\n",
      "    [-1.13824749e+00]\n",
      "    [-4.57034707e-01]\n",
      "    [ 6.64631426e-01]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 8.92755806e-01]\n",
      "    [-5.30001342e-01]\n",
      "    [ 2.14105844e+00]\n",
      "    ...\n",
      "    [-6.43521488e-01]\n",
      "    [ 4.43842769e-01]\n",
      "    [-4.46539879e-01]]\n",
      "\n",
      "   [[ 1.10991180e+00]\n",
      "    [-2.65036851e-01]\n",
      "    [ 2.67801571e+00]\n",
      "    ...\n",
      "    [-6.02517501e-02]\n",
      "    [ 5.75278580e-01]\n",
      "    [-2.91761398e-01]]\n",
      "\n",
      "   [[ 7.39282370e-01]\n",
      "    [ 1.79562662e-02]\n",
      "    [ 2.99968791e+00]\n",
      "    ...\n",
      "    [ 3.25698033e-02]\n",
      "    [-6.70303777e-02]\n",
      "    [-1.79062560e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-1.61549032e-01]\n",
      "    [ 1.80121019e-01]\n",
      "    [ 1.48288214e+00]\n",
      "    ...\n",
      "    [-3.74665767e-01]\n",
      "    [-1.71077132e-01]\n",
      "    [ 1.92970157e-01]]\n",
      "\n",
      "   [[ 5.87046385e-01]\n",
      "    [ 9.10133839e-01]\n",
      "    [ 2.80087280e+00]\n",
      "    ...\n",
      "    [-8.77680182e-02]\n",
      "    [ 3.84138525e-01]\n",
      "    [ 1.10231590e+00]]\n",
      "\n",
      "   [[ 2.99481988e-01]\n",
      "    [ 1.19852281e+00]\n",
      "    [ 1.25218689e+00]\n",
      "    ...\n",
      "    [-1.39212859e+00]\n",
      "    [-5.60904562e-01]\n",
      "    [ 1.85127771e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 5.39945029e-02]\n",
      "    [-5.26509667e-03]\n",
      "    [ 1.55376399e+00]\n",
      "    ...\n",
      "    [ 8.94428790e-02]\n",
      "    [-9.74187851e-02]\n",
      "    [ 2.18716717e+00]]\n",
      "\n",
      "   [[ 3.50639708e-02]\n",
      "    [ 2.55988538e-01]\n",
      "    [ 1.27877581e+00]\n",
      "    ...\n",
      "    [-2.72287399e-01]\n",
      "    [-3.80676568e-01]\n",
      "    [ 1.19888067e+00]]\n",
      "\n",
      "   [[-3.70104760e-01]\n",
      "    [-4.24094917e-03]\n",
      "    [ 5.76461077e-01]\n",
      "    ...\n",
      "    [ 1.28509021e+00]\n",
      "    [-4.26223397e-01]\n",
      "    [ 5.59345126e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-7.86240220e-01]\n",
      "    [-4.08532411e-01]\n",
      "    [-2.79826164e-01]\n",
      "    ...\n",
      "    [ 1.92873311e+00]\n",
      "    [ 1.75682917e-01]\n",
      "    [-6.78805351e-01]]\n",
      "\n",
      "   [[-2.25711912e-01]\n",
      "    [ 1.61186457e-01]\n",
      "    [ 5.28979242e-01]\n",
      "    ...\n",
      "    [-2.81400025e-01]\n",
      "    [ 2.08304584e-01]\n",
      "    [-6.28857434e-01]]\n",
      "\n",
      "   [[ 3.06295455e-01]\n",
      "    [ 2.67459214e-01]\n",
      "    [ 1.04519081e+00]\n",
      "    ...\n",
      "    [-3.80652815e-01]\n",
      "    [-9.88775790e-02]\n",
      "    [ 3.62254977e-01]]]\n",
      "\n",
      "\n",
      "  [[[-5.05865037e-01]\n",
      "    [-3.66547853e-01]\n",
      "    [-1.10095906e+00]\n",
      "    ...\n",
      "    [ 1.01245654e+00]\n",
      "    [ 1.49231240e-01]\n",
      "    [ 2.82153296e+00]]\n",
      "\n",
      "   [[-7.30613053e-01]\n",
      "    [-3.62812072e-01]\n",
      "    [-3.72958541e-01]\n",
      "    ...\n",
      "    [ 8.78860474e-01]\n",
      "    [ 2.48019740e-01]\n",
      "    [ 1.53945848e-01]]\n",
      "\n",
      "   [[-5.55367529e-01]\n",
      "    [-2.79278588e-02]\n",
      "    [ 7.21540034e-01]\n",
      "    ...\n",
      "    [-1.09515905e+00]\n",
      "    [-4.59393747e-02]\n",
      "    [-1.75536990e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-5.97006619e-01]\n",
      "    [-8.58093798e-01]\n",
      "    [-7.16461420e-01]\n",
      "    ...\n",
      "    [ 1.47483814e+00]\n",
      "    [ 2.32198358e-01]\n",
      "    [-1.61472404e+00]]\n",
      "\n",
      "   [[-4.31686282e-01]\n",
      "    [-5.81235409e-01]\n",
      "    [-4.29379761e-01]\n",
      "    ...\n",
      "    [ 3.92848670e-01]\n",
      "    [ 9.10296440e-01]\n",
      "    [-7.12343335e-01]]\n",
      "\n",
      "   [[-2.72934020e-01]\n",
      "    [-3.74258190e-01]\n",
      "    [-6.33923650e-01]\n",
      "    ...\n",
      "    [-1.62000861e-02]\n",
      "    [-2.04935765e+00]\n",
      "    [-1.26116920e+00]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[ 2.34237403e-01]\n",
      "    [-1.30747879e+00]\n",
      "    [-1.54248714e+00]\n",
      "    ...\n",
      "    [-1.93564117e+00]\n",
      "    [ 1.16186786e+00]\n",
      "    [-4.61156964e-01]]\n",
      "\n",
      "   [[ 2.26738647e-01]\n",
      "    [-1.52628076e+00]\n",
      "    [-1.53855944e+00]\n",
      "    ...\n",
      "    [-2.43736529e+00]\n",
      "    [-3.10497165e+00]\n",
      "    [ 2.60476163e-03]]\n",
      "\n",
      "   [[ 2.32785881e-01]\n",
      "    [-1.56200421e+00]\n",
      "    [-1.74273658e+00]\n",
      "    ...\n",
      "    [-2.97675180e+00]\n",
      "    [-3.00091100e+00]\n",
      "    [ 7.28478253e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 3.85090034e-03]\n",
      "    [-8.07828128e-01]\n",
      "    [-1.54401302e+00]\n",
      "    ...\n",
      "    [ 3.30058604e-01]\n",
      "    [-1.81150448e+00]\n",
      "    [-8.45396161e-01]]\n",
      "\n",
      "   [[-4.48853642e-01]\n",
      "    [ 1.25447482e-01]\n",
      "    [-9.16809916e-01]\n",
      "    ...\n",
      "    [-9.03386176e-01]\n",
      "    [-1.68440390e+00]\n",
      "    [-8.67911398e-01]]\n",
      "\n",
      "   [[-3.48397195e-02]\n",
      "    [ 1.57202256e+00]\n",
      "    [ 4.54645544e-01]\n",
      "    ...\n",
      "    [-7.21804082e-01]\n",
      "    [ 1.78816363e-01]\n",
      "    [ 1.44252145e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.60935253e-01]\n",
      "    [-1.29451585e+00]\n",
      "    [-1.84092402e+00]\n",
      "    ...\n",
      "    [-2.39002752e+00]\n",
      "    [-9.20811653e-01]\n",
      "    [-7.72682607e-01]]\n",
      "\n",
      "   [[ 1.45662799e-01]\n",
      "    [-1.47265828e+00]\n",
      "    [-2.06470060e+00]\n",
      "    ...\n",
      "    [-2.85374904e+00]\n",
      "    [-2.27418041e+00]\n",
      "    [-3.81880790e-01]]\n",
      "\n",
      "   [[ 1.06090814e-01]\n",
      "    [-1.51688910e+00]\n",
      "    [-1.77699602e+00]\n",
      "    ...\n",
      "    [-2.84311843e+00]\n",
      "    [-2.53804684e+00]\n",
      "    [ 1.10052860e+00]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-1.12720586e-01]\n",
      "    [-6.87476158e-01]\n",
      "    [-1.57418060e+00]\n",
      "    ...\n",
      "    [ 6.60465658e-01]\n",
      "    [ 1.65098056e-01]\n",
      "    [ 1.12457669e+00]]\n",
      "\n",
      "   [[-1.80273339e-01]\n",
      "    [ 2.65930921e-01]\n",
      "    [-3.07719111e-01]\n",
      "    ...\n",
      "    [ 1.92227328e+00]\n",
      "    [ 1.55199885e-01]\n",
      "    [ 7.62153491e-02]]\n",
      "\n",
      "   [[ 4.31803584e-01]\n",
      "    [ 6.48462415e-01]\n",
      "    [ 5.71954131e-01]\n",
      "    ...\n",
      "    [ 2.77817160e-01]\n",
      "    [-6.33484066e-01]\n",
      "    [-3.07062954e-01]]]\n",
      "\n",
      "\n",
      "  [[[ 9.94842574e-02]\n",
      "    [-9.42007780e-01]\n",
      "    [-1.53298569e+00]\n",
      "    ...\n",
      "    [-1.49212527e+00]\n",
      "    [ 2.24276924e+00]\n",
      "    [-1.82386780e+00]]\n",
      "\n",
      "   [[ 1.88220441e-01]\n",
      "    [-1.10883570e+00]\n",
      "    [-1.62587357e+00]\n",
      "    ...\n",
      "    [-1.17152286e+00]\n",
      "    [ 2.15650058e+00]\n",
      "    [-1.91517723e+00]]\n",
      "\n",
      "   [[ 1.69286028e-01]\n",
      "    [-1.32631445e+00]\n",
      "    [-1.64042771e+00]\n",
      "    ...\n",
      "    [-2.32562423e+00]\n",
      "    [-2.24417701e-01]\n",
      "    [-9.58795309e-01]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-1.08551785e-01]\n",
      "    [-7.23358393e-01]\n",
      "    [-1.67131114e+00]\n",
      "    ...\n",
      "    [ 4.46044475e-01]\n",
      "    [ 9.49450552e-01]\n",
      "    [ 9.11583543e-01]]\n",
      "\n",
      "   [[-3.09356093e-01]\n",
      "    [-3.15070778e-01]\n",
      "    [-6.85032487e-01]\n",
      "    ...\n",
      "    [ 1.36795864e-01]\n",
      "    [ 6.26226783e-01]\n",
      "    [-7.48361170e-01]]\n",
      "\n",
      "   [[-1.67023212e-01]\n",
      "    [ 3.72588634e-01]\n",
      "    [-1.64284911e-02]\n",
      "    ...\n",
      "    [ 8.56267333e-01]\n",
      "    [-5.15269578e-01]\n",
      "    [-1.01605676e-01]]]]], shape=(100, 11, 11, 30, 1), dtype=float32)\n",
      "z (100, 128) tf.Tensor(\n",
      "[[0.         0.06841395 0.02838409 ... 0.05753114 0.03350375 0.        ]\n",
      " [0.03864493 0.00070483 0.03492289 ... 0.19947027 0.01098043 0.        ]\n",
      " [0.         0.         0.         ... 0.4348658  0.2275653  0.        ]\n",
      " ...\n",
      " [0.         0.4318821  0.6760919  ... 0.34680697 0.19671696 0.        ]\n",
      " [0.         0.05848605 0.16968898 ... 0.12190428 0.00973464 0.        ]\n",
      " [0.14336136 0.19533126 0.058667   ... 0.         0.01989387 0.        ]], shape=(100, 128), dtype=float32)\n",
      "z_p (5, 5, 128) tf.Tensor(\n",
      "[[[0.         0.06841395 0.02838409 ... 0.05753114 0.03350375 0.        ]\n",
      "  [0.03864493 0.00070483 0.03492289 ... 0.19947027 0.01098043 0.        ]\n",
      "  [0.         0.         0.         ... 0.4348658  0.2275653  0.        ]\n",
      "  [0.         0.29506275 0.0017895  ... 0.35242778 0.05724714 0.        ]\n",
      "  [0.         0.         0.         ... 0.1572455  0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.2401505  ... 0.05447333 0.3189154  0.26291442]\n",
      "  [0.16087925 0.0966856  0.         ... 0.         0.20437723 0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.42038357 0.        ]\n",
      "  [0.         0.2761072  0.         ... 0.33119607 0.03758838 0.        ]\n",
      "  [0.         0.14582554 0.2125484  ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.20367509 ... 0.         0.07691225 0.        ]\n",
      "  [0.11265989 0.3943748  0.37963906 ... 0.5391861  0.         0.        ]\n",
      "  [0.         0.         0.06947783 ... 0.         0.00183252 0.        ]\n",
      "  [0.3965791  0.36078832 0.03443246 ... 0.32914555 0.1773819  0.        ]\n",
      "  [0.         0.01824004 0.         ... 0.         0.         0.01116783]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.04010932 0.02442034]\n",
      "  [0.         0.07505985 0.         ... 0.03254259 0.10334706 0.        ]\n",
      "  [0.         0.25503182 0.         ... 0.6156299  0.         0.        ]\n",
      "  [0.15135282 0.19930735 0.28919476 ... 0.02481586 0.         0.        ]\n",
      "  [0.         0.07647406 0.15151626 ... 0.23971272 0.11086276 0.        ]]\n",
      "\n",
      " [[0.         0.         0.08311865 ... 0.         0.17320508 0.        ]\n",
      "  [0.07047865 0.         0.2265922  ... 0.         0.11928743 0.09737989]\n",
      "  [0.13323866 0.20436062 0.02396451 ... 0.20271318 0.11434947 0.        ]\n",
      "  [0.         0.         0.11777289 ... 0.         0.32013574 0.        ]\n",
      "  [0.         0.20745437 0.27524477 ... 0.5660948  0.         0.1689017 ]]], shape=(5, 5, 128), dtype=float32)\n",
      "z_p (5, 128) tf.Tensor(\n",
      "[[0.00772899 0.0728363  0.01301929 0.07191138 0.01993422 0.05102418\n",
      "  0.03774704 0.00841653 0.121874   0.         0.10929856 0.\n",
      "  0.13071463 0.22945006 0.05836121 0.12554768 0.07959659 0.01451012\n",
      "  0.         0.20368238 0.04326583 0.06908217 0.05836963 0.14731526\n",
      "  0.20378642 0.03422578 0.0496998  0.19171175 0.03987476 0.00824269\n",
      "  0.         0.0110683  0.05432866 0.04836069 0.00921626 0.03391882\n",
      "  0.05745613 0.         0.04631852 0.         0.         0.00907637\n",
      "  0.03038799 0.07552217 0.3125113  0.09815117 0.08063748 0.01149589\n",
      "  0.         0.01932038 0.04880045 0.01229882 0.02759943 0.0075768\n",
      "  0.04387327 0.01631659 0.09527158 0.06454635 0.06676892 0.05139504\n",
      "  0.         0.         0.15143654 0.15244663 0.19524136 0.06687296\n",
      "  0.18683429 0.         0.07067563 0.06462108 0.11408697 0.1365186\n",
      "  0.07644608 0.00520707 0.06724373 0.03061846 0.07241292 0.09603075\n",
      "  0.21228877 0.04519547 0.04936731 0.11456549 0.00902747 0.01192927\n",
      "  0.12288865 0.01759943 0.08834897 0.03279165 0.0417537  0.23124425\n",
      "  0.03061604 0.09188017 0.05065949 0.00889259 0.01751024 0.00220231\n",
      "  0.09959257 0.04965533 0.03492669 0.11517988 0.19062111 0.\n",
      "  0.24259667 0.08905586 0.         0.04395296 0.19801418 0.09906247\n",
      "  0.19685379 0.03910401 0.15402265 0.01118199 0.15317853 0.02005882\n",
      "  0.         0.03853714 0.         0.03744785 0.04066652 0.03641962\n",
      "  0.08314864 0.03680981 0.3124345  0.13809094 0.01313203 0.24030812\n",
      "  0.06585933 0.        ]\n",
      " [0.03217585 0.10372367 0.09053978 0.05681299 0.00703671 0.15697984\n",
      "  0.06944548 0.05675056 0.20404752 0.10327484 0.06008674 0.03424325\n",
      "  0.0695752  0.11932856 0.12680908 0.19206806 0.1343148  0.04228106\n",
      "  0.071338   0.15855041 0.01385473 0.02383718 0.         0.1395838\n",
      "  0.11990337 0.0924126  0.03456464 0.21585989 0.03037512 0.06073546\n",
      "  0.01345457 0.         0.         0.09306265 0.03021159 0.12407656\n",
      "  0.08481297 0.03501021 0.05837426 0.         0.         0.05284693\n",
      "  0.0882685  0.04794484 0.2588079  0.10070235 0.01783788 0.\n",
      "  0.04127273 0.03649946 0.02329174 0.         0.05465907 0.03719786\n",
      "  0.02892877 0.04952193 0.08822726 0.06199584 0.2504576  0.\n",
      "  0.01482891 0.01493417 0.17290965 0.12847278 0.19397567 0.12017319\n",
      "  0.23928699 0.00259903 0.06971155 0.02663153 0.24027503 0.09887252\n",
      "  0.1284101  0.0512103  0.05397117 0.17501965 0.12384611 0.17436369\n",
      "  0.2178032  0.01603745 0.00227201 0.19499457 0.09053875 0.01453733\n",
      "  0.17119914 0.08146062 0.08844928 0.1934536  0.04085247 0.2762006\n",
      "  0.01229951 0.10409237 0.15213455 0.01132946 0.01607976 0.03539781\n",
      "  0.1053036  0.06068776 0.05311955 0.1167894  0.11236686 0.\n",
      "  0.24951668 0.07190312 0.06388251 0.         0.20791225 0.09431609\n",
      "  0.18456149 0.02396708 0.19707295 0.06243578 0.12494985 0.08137508\n",
      "  0.         0.06512366 0.         0.         0.08577012 0.02613293\n",
      "  0.04886204 0.00747247 0.12706766 0.15558212 0.02808091 0.07713388\n",
      "  0.19625291 0.05258288]\n",
      " [0.10184779 0.15468062 0.13744488 0.00639023 0.18950835 0.09565233\n",
      "  0.03531717 0.04571211 0.36674294 0.04175717 0.19343153 0.05632625\n",
      "  0.28287292 0.24643707 0.18127799 0.12466472 0.13966009 0.00700442\n",
      "  0.03172997 0.16123733 0.29960972 0.05320465 0.19906029 0.3778406\n",
      "  0.11014948 0.18472734 0.         0.4006547  0.04487068 0.22095919\n",
      "  0.15395358 0.         0.         0.0980168  0.12766889 0.10920835\n",
      "  0.12187614 0.         0.03538603 0.         0.         0.24199355\n",
      "  0.13362846 0.07384501 0.25780872 0.15103403 0.07606087 0.\n",
      "  0.01063738 0.12241857 0.11629958 0.00191602 0.11799143 0.08399318\n",
      "  0.         0.04810941 0.06452031 0.12510762 0.07893805 0.04022708\n",
      "  0.04174194 0.03952492 0.17498574 0.21129975 0.26249093 0.06065812\n",
      "  0.18324451 0.         0.         0.         0.3959952  0.07361702\n",
      "  0.23361902 0.03948154 0.10248735 0.11761465 0.16065785 0.30710036\n",
      "  0.14967592 0.05768269 0.10979459 0.17791887 0.17342834 0.01179731\n",
      "  0.21958025 0.19524935 0.10565199 0.25929683 0.19514371 0.340872\n",
      "  0.05516993 0.20611815 0.1987956  0.         0.03311735 0.11986007\n",
      "  0.15043147 0.         0.08906587 0.28604406 0.14267726 0.\n",
      "  0.48122555 0.20005159 0.12017872 0.         0.03935462 0.2785299\n",
      "  0.30968446 0.05742409 0.10904984 0.1300491  0.13927957 0.02359646\n",
      "  0.         0.13864712 0.         0.2062413  0.01167339 0.\n",
      "  0.0791081  0.00696716 0.40336266 0.32618916 0.0234012  0.17366633\n",
      "  0.05122533 0.00223357]\n",
      " [0.03027057 0.12117462 0.0881422  0.00541299 0.0467316  0.04545944\n",
      "  0.03658953 0.01308879 0.11785147 0.1235657  0.11823175 0.\n",
      "  0.02683524 0.14207071 0.17220512 0.10585346 0.04852732 0.01977681\n",
      "  0.02174931 0.11508169 0.08145159 0.08236498 0.06147889 0.06063358\n",
      "  0.17401692 0.09573772 0.10728998 0.22865114 0.07322677 0.04699339\n",
      "  0.01373323 0.015638   0.         0.02307431 0.07826161 0.11322795\n",
      "  0.07073764 0.         0.02252572 0.00901381 0.         0.01123901\n",
      "  0.01381516 0.0510639  0.32608873 0.11615918 0.11994882 0.\n",
      "  0.         0.         0.206183   0.         0.10871291 0.02595962\n",
      "  0.03719957 0.04182505 0.07386275 0.1048248  0.10125478 0.05453371\n",
      "  0.15416867 0.         0.05273325 0.18655339 0.11259899 0.07673151\n",
      "  0.12819031 0.         0.00276015 0.08741038 0.06052197 0.11909342\n",
      "  0.10883345 0.         0.06815822 0.22793937 0.08062954 0.266542\n",
      "  0.11953435 0.03771015 0.02463827 0.12860985 0.05911164 0.04204669\n",
      "  0.11119473 0.04223606 0.01945063 0.08821668 0.06573246 0.28707197\n",
      "  0.05027524 0.11267666 0.04190077 0.09663828 0.         0.07135211\n",
      "  0.20596941 0.00161216 0.07140376 0.09379206 0.08926977 0.\n",
      "  0.27350312 0.06520607 0.12495831 0.01502181 0.10098916 0.02117508\n",
      "  0.23174258 0.05100258 0.09140614 0.03601073 0.03578504 0.00384818\n",
      "  0.         0.         0.05152575 0.07228791 0.0341517  0.05828897\n",
      "  0.07499041 0.00209538 0.34740835 0.10884289 0.04893808 0.18254021\n",
      "  0.05086382 0.00488407]\n",
      " [0.04074346 0.08236299 0.14533861 0.06744517 0.06883393 0.25537834\n",
      "  0.08000939 0.04146658 0.20945969 0.11154475 0.15758625 0.\n",
      "  0.08234739 0.15857132 0.06081929 0.16200534 0.29638886 0.04338086\n",
      "  0.07134517 0.21937637 0.07534038 0.04894846 0.14672738 0.17501107\n",
      "  0.05805178 0.18500277 0.07378343 0.27377954 0.         0.1545982\n",
      "  0.03453853 0.         0.05355745 0.18360522 0.0828467  0.12658004\n",
      "  0.02497754 0.         0.05678624 0.         0.         0.06867201\n",
      "  0.09325907 0.04142818 0.32861435 0.11889212 0.16098207 0.02785257\n",
      "  0.05922247 0.04201474 0.12402707 0.         0.13488014 0.\n",
      "  0.02455236 0.00912673 0.10495901 0.12181518 0.07961969 0.02255415\n",
      "  0.         0.06383979 0.08696686 0.08737325 0.15105735 0.01118114\n",
      "  0.15856655 0.0172083  0.02497652 0.13936667 0.18616854 0.10066649\n",
      "  0.0854729  0.02527757 0.03650532 0.14904693 0.20188121 0.0776839\n",
      "  0.1676876  0.02159075 0.03052014 0.19815175 0.00339111 0.07739025\n",
      "  0.15885338 0.01353742 0.09213401 0.06077219 0.01957999 0.25402185\n",
      "  0.0521438  0.2273037  0.08792794 0.01647368 0.01353208 0.12088387\n",
      "  0.07886092 0.0249583  0.04065522 0.17757288 0.04366968 0.\n",
      "  0.31942096 0.08599835 0.07141691 0.         0.16318615 0.23490572\n",
      "  0.20702338 0.06520195 0.03780406 0.04363912 0.03944912 0.20042174\n",
      "  0.         0.02512325 0.         0.17281136 0.         0.09409746\n",
      "  0.0371481  0.00903746 0.25752345 0.15167864 0.         0.1537616\n",
      "  0.14539555 0.05325632]], shape=(5, 128), dtype=float32)\n",
      "z_q (75, 128) tf.Tensor(\n",
      "[[0.         0.25614223 0.         ... 0.1540243  0.0563221  0.        ]\n",
      " [0.         0.40307808 0.10010499 ... 0.         0.07791063 0.02557717]\n",
      " [0.         0.         0.4535071  ... 0.23925501 0.05746596 0.        ]\n",
      " ...\n",
      " [0.         0.4318821  0.6760919  ... 0.34680697 0.19671696 0.        ]\n",
      " [0.         0.05848605 0.16968898 ... 0.12190428 0.00973464 0.        ]\n",
      " [0.14336136 0.19533126 0.058667   ... 0.         0.01989387 0.        ]], shape=(75, 128), dtype=float32)\n",
      "75 5\n",
      "(75, 128)\n",
      "(5, 128)\n",
      "tf.Tensor(\n",
      "[[[0.         0.25614223 0.         ... 0.1540243  0.0563221  0.        ]\n",
      "  [0.         0.25614223 0.         ... 0.1540243  0.0563221  0.        ]\n",
      "  [0.         0.25614223 0.         ... 0.1540243  0.0563221  0.        ]\n",
      "  [0.         0.25614223 0.         ... 0.1540243  0.0563221  0.        ]\n",
      "  [0.         0.25614223 0.         ... 0.1540243  0.0563221  0.        ]]\n",
      "\n",
      " [[0.         0.40307808 0.10010499 ... 0.         0.07791063 0.02557717]\n",
      "  [0.         0.40307808 0.10010499 ... 0.         0.07791063 0.02557717]\n",
      "  [0.         0.40307808 0.10010499 ... 0.         0.07791063 0.02557717]\n",
      "  [0.         0.40307808 0.10010499 ... 0.         0.07791063 0.02557717]\n",
      "  [0.         0.40307808 0.10010499 ... 0.         0.07791063 0.02557717]]\n",
      "\n",
      " [[0.         0.         0.4535071  ... 0.23925501 0.05746596 0.        ]\n",
      "  [0.         0.         0.4535071  ... 0.23925501 0.05746596 0.        ]\n",
      "  [0.         0.         0.4535071  ... 0.23925501 0.05746596 0.        ]\n",
      "  [0.         0.         0.4535071  ... 0.23925501 0.05746596 0.        ]\n",
      "  [0.         0.         0.4535071  ... 0.23925501 0.05746596 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.4318821  0.6760919  ... 0.34680697 0.19671696 0.        ]\n",
      "  [0.         0.4318821  0.6760919  ... 0.34680697 0.19671696 0.        ]\n",
      "  [0.         0.4318821  0.6760919  ... 0.34680697 0.19671696 0.        ]\n",
      "  [0.         0.4318821  0.6760919  ... 0.34680697 0.19671696 0.        ]\n",
      "  [0.         0.4318821  0.6760919  ... 0.34680697 0.19671696 0.        ]]\n",
      "\n",
      " [[0.         0.05848605 0.16968898 ... 0.12190428 0.00973464 0.        ]\n",
      "  [0.         0.05848605 0.16968898 ... 0.12190428 0.00973464 0.        ]\n",
      "  [0.         0.05848605 0.16968898 ... 0.12190428 0.00973464 0.        ]\n",
      "  [0.         0.05848605 0.16968898 ... 0.12190428 0.00973464 0.        ]\n",
      "  [0.         0.05848605 0.16968898 ... 0.12190428 0.00973464 0.        ]]\n",
      "\n",
      " [[0.14336136 0.19533126 0.058667   ... 0.         0.01989387 0.        ]\n",
      "  [0.14336136 0.19533126 0.058667   ... 0.         0.01989387 0.        ]\n",
      "  [0.14336136 0.19533126 0.058667   ... 0.         0.01989387 0.        ]\n",
      "  [0.14336136 0.19533126 0.058667   ... 0.         0.01989387 0.        ]\n",
      "  [0.14336136 0.19533126 0.058667   ... 0.         0.01989387 0.        ]]], shape=(75, 5, 128), dtype=float32)\n",
      "(75, 5, 128)\n",
      "tf.Tensor(\n",
      "[[[0.00772899 0.0728363  0.01301929 ... 0.24030812 0.06585933 0.        ]\n",
      "  [0.03217585 0.10372367 0.09053978 ... 0.07713388 0.19625291 0.05258288]\n",
      "  [0.10184779 0.15468062 0.13744488 ... 0.17366633 0.05122533 0.00223357]\n",
      "  [0.03027057 0.12117462 0.0881422  ... 0.18254021 0.05086382 0.00488407]\n",
      "  [0.04074346 0.08236299 0.14533861 ... 0.1537616  0.14539555 0.05325632]]\n",
      "\n",
      " [[0.00772899 0.0728363  0.01301929 ... 0.24030812 0.06585933 0.        ]\n",
      "  [0.03217585 0.10372367 0.09053978 ... 0.07713388 0.19625291 0.05258288]\n",
      "  [0.10184779 0.15468062 0.13744488 ... 0.17366633 0.05122533 0.00223357]\n",
      "  [0.03027057 0.12117462 0.0881422  ... 0.18254021 0.05086382 0.00488407]\n",
      "  [0.04074346 0.08236299 0.14533861 ... 0.1537616  0.14539555 0.05325632]]\n",
      "\n",
      " [[0.00772899 0.0728363  0.01301929 ... 0.24030812 0.06585933 0.        ]\n",
      "  [0.03217585 0.10372367 0.09053978 ... 0.07713388 0.19625291 0.05258288]\n",
      "  [0.10184779 0.15468062 0.13744488 ... 0.17366633 0.05122533 0.00223357]\n",
      "  [0.03027057 0.12117462 0.0881422  ... 0.18254021 0.05086382 0.00488407]\n",
      "  [0.04074346 0.08236299 0.14533861 ... 0.1537616  0.14539555 0.05325632]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00772899 0.0728363  0.01301929 ... 0.24030812 0.06585933 0.        ]\n",
      "  [0.03217585 0.10372367 0.09053978 ... 0.07713388 0.19625291 0.05258288]\n",
      "  [0.10184779 0.15468062 0.13744488 ... 0.17366633 0.05122533 0.00223357]\n",
      "  [0.03027057 0.12117462 0.0881422  ... 0.18254021 0.05086382 0.00488407]\n",
      "  [0.04074346 0.08236299 0.14533861 ... 0.1537616  0.14539555 0.05325632]]\n",
      "\n",
      " [[0.00772899 0.0728363  0.01301929 ... 0.24030812 0.06585933 0.        ]\n",
      "  [0.03217585 0.10372367 0.09053978 ... 0.07713388 0.19625291 0.05258288]\n",
      "  [0.10184779 0.15468062 0.13744488 ... 0.17366633 0.05122533 0.00223357]\n",
      "  [0.03027057 0.12117462 0.0881422  ... 0.18254021 0.05086382 0.00488407]\n",
      "  [0.04074346 0.08236299 0.14533861 ... 0.1537616  0.14539555 0.05325632]]\n",
      "\n",
      " [[0.00772899 0.0728363  0.01301929 ... 0.24030812 0.06585933 0.        ]\n",
      "  [0.03217585 0.10372367 0.09053978 ... 0.07713388 0.19625291 0.05258288]\n",
      "  [0.10184779 0.15468062 0.13744488 ... 0.17366633 0.05122533 0.00223357]\n",
      "  [0.03027057 0.12117462 0.0881422  ... 0.18254021 0.05086382 0.00488407]\n",
      "  [0.04074346 0.08236299 0.14533861 ... 0.1537616  0.14539555 0.05325632]]], shape=(75, 5, 128), dtype=float32)\n",
      "(75, 5, 128)\n",
      "tf.Tensor(\n",
      "[[[-7.72898551e-03  1.83305919e-01 -1.30192935e-02 ... -8.62838179e-02\n",
      "   -9.53722745e-03  0.00000000e+00]\n",
      "  [-3.21758501e-02  1.52418554e-01 -9.05397758e-02 ...  7.68904239e-02\n",
      "   -1.39930815e-01 -5.25828823e-02]\n",
      "  [-1.01847790e-01  1.01461604e-01 -1.37444884e-01 ... -1.96420252e-02\n",
      "    5.09676337e-03 -2.23356578e-03]\n",
      "  [-3.02705653e-02  1.34967610e-01 -8.81422013e-02 ... -2.85159051e-02\n",
      "    5.45827299e-03 -4.88406746e-03]\n",
      "  [-4.07434627e-02  1.73779234e-01 -1.45338610e-01 ...  2.62707472e-04\n",
      "   -8.90734494e-02 -5.32563217e-02]]\n",
      "\n",
      " [[-7.72898551e-03  3.30241770e-01  8.70856941e-02 ... -2.40308121e-01\n",
      "    1.20513067e-02  2.55771652e-02]\n",
      "  [-3.21758501e-02  2.99354404e-01  9.56521183e-03 ... -7.71338791e-02\n",
      "   -1.18342280e-01 -2.70057172e-02]\n",
      "  [-1.01847790e-01  2.48397455e-01 -3.73398960e-02 ... -1.73666328e-01\n",
      "    2.66852975e-02  2.33436003e-02]\n",
      "  [-3.02705653e-02  2.81903446e-01  1.19627863e-02 ... -1.82540208e-01\n",
      "    2.70468071e-02  2.06930973e-02]\n",
      "  [-4.07434627e-02  3.20715070e-01 -4.52336222e-02 ... -1.53761595e-01\n",
      "   -6.74849153e-02 -2.76791565e-02]]\n",
      "\n",
      " [[-7.72898551e-03 -7.28363022e-02  4.40487802e-01 ... -1.05310977e-03\n",
      "   -8.39336589e-03  0.00000000e+00]\n",
      "  [-3.21758501e-02 -1.03723668e-01  3.62967312e-01 ...  1.62121132e-01\n",
      "   -1.38786957e-01 -5.25828823e-02]\n",
      "  [-1.01847790e-01 -1.54680625e-01  3.16062212e-01 ...  6.55886829e-02\n",
      "    6.24062493e-03 -2.23356578e-03]\n",
      "  [-3.02705653e-02 -1.21174619e-01  3.65364909e-01 ...  5.67148030e-02\n",
      "    6.60213456e-03 -4.88406746e-03]\n",
      "  [-4.07434627e-02 -8.23629946e-02  3.08168471e-01 ...  8.54934156e-02\n",
      "   -8.79295915e-02 -5.32563217e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-7.72898551e-03  3.59045804e-01  6.63072586e-01 ...  1.06498852e-01\n",
      "    1.30857646e-01  0.00000000e+00]\n",
      "  [-3.21758501e-02  3.28158438e-01  5.85552156e-01 ...  2.69673109e-01\n",
      "    4.64051962e-04 -5.25828823e-02]\n",
      "  [-1.01847790e-01  2.77201474e-01  5.38647056e-01 ...  1.73140645e-01\n",
      "    1.45491630e-01 -2.23356578e-03]\n",
      "  [-3.02705653e-02  3.10707510e-01  5.87949693e-01 ...  1.64266765e-01\n",
      "    1.45853132e-01 -4.88406746e-03]\n",
      "  [-4.07434627e-02  3.49519134e-01  5.30753314e-01 ...  1.93045378e-01\n",
      "    5.13214171e-02 -5.32563217e-02]]\n",
      "\n",
      " [[-7.72898551e-03 -1.43502504e-02  1.56669691e-01 ... -1.18403845e-01\n",
      "   -5.61246909e-02  0.00000000e+00]\n",
      "  [-3.21758501e-02 -4.52376157e-02  7.91492090e-02 ...  4.47703972e-02\n",
      "   -1.86518282e-01 -5.25828823e-02]\n",
      "  [-1.01847790e-01 -9.61945727e-02  3.22441012e-02 ... -5.17620519e-02\n",
      "   -4.14907001e-02 -2.23356578e-03]\n",
      "  [-3.02705653e-02 -6.26885667e-02  8.15467834e-02 ... -6.06359318e-02\n",
      "   -4.11291905e-02 -4.88406746e-03]\n",
      "  [-4.07434627e-02 -2.38769427e-02  2.43503749e-02 ... -3.18573192e-02\n",
      "   -1.35660917e-01 -5.32563217e-02]]\n",
      "\n",
      " [[ 1.35632381e-01  1.22494958e-01  4.56477031e-02 ... -2.40308121e-01\n",
      "   -4.59654555e-02  0.00000000e+00]\n",
      "  [ 1.11185506e-01  9.16075930e-02 -3.18727791e-02 ... -7.71338791e-02\n",
      "   -1.76359043e-01 -5.25828823e-02]\n",
      "  [ 4.15135697e-02  4.06506360e-02 -7.87778869e-02 ... -1.73666328e-01\n",
      "   -3.13314646e-02 -2.23356578e-03]\n",
      "  [ 1.13090798e-01  7.41566420e-02 -2.94752046e-02 ... -1.82540208e-01\n",
      "   -3.09699550e-02 -4.88406746e-03]\n",
      "  [ 1.02617897e-01  1.12968266e-01 -8.66716132e-02 ... -1.53761595e-01\n",
      "   -1.25501677e-01 -5.32563217e-02]]], shape=(75, 5, 128), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[5.97372164e-05 3.36010605e-02 1.69502004e-04 ... 7.44489720e-03\n",
      "   9.09587106e-05 0.00000000e+00]\n",
      "  [1.03528530e-03 2.32314151e-02 8.19745101e-03 ... 5.91213722e-03\n",
      "   1.95806324e-02 2.76495959e-03]\n",
      "  [1.03729721e-02 1.02944570e-02 1.88910961e-02 ... 3.85809166e-04\n",
      "   2.59769968e-05 4.98881627e-06]\n",
      "  [9.16307152e-04 1.82162561e-02 7.76904775e-03 ... 8.13156832e-04\n",
      "   2.97927436e-05 2.38541143e-05]\n",
      "  [1.66002975e-03 3.01992223e-02 2.11233124e-02 ... 6.90152149e-08\n",
      "   7.93407951e-03 2.83623580e-03]]\n",
      "\n",
      " [[5.97372164e-05 1.09059624e-01 7.58391805e-03 ... 5.77479936e-02\n",
      "   1.45233993e-04 6.54191361e-04]\n",
      "  [1.03528530e-03 8.96130577e-02 9.14932752e-05 ... 5.94963552e-03\n",
      "   1.40048955e-02 7.29308755e-04]\n",
      "  [1.03729721e-02 6.17012940e-02 1.39426778e-03 ... 3.01599931e-02\n",
      "   7.12105073e-04 5.44923649e-04]\n",
      "  [9.16307152e-04 7.94695541e-02 1.43108264e-04 ... 3.33209261e-02\n",
      "   7.31529784e-04 4.28204279e-04]\n",
      "  [1.66002975e-03 1.02858156e-01 2.04608054e-03 ... 2.36426275e-02\n",
      "   4.55421396e-03 7.66135694e-04]]\n",
      "\n",
      " [[5.97372164e-05 5.30512678e-03 1.94029510e-01 ... 1.10904023e-06\n",
      "   7.04485938e-05 0.00000000e+00]\n",
      "  [1.03528530e-03 1.07585993e-02 1.31745264e-01 ... 2.62832623e-02\n",
      "   1.92618202e-02 2.76495959e-03]\n",
      "  [1.03729721e-02 2.39260960e-02 9.98953208e-02 ... 4.30187536e-03\n",
      "   3.89453999e-05 4.98881627e-06]\n",
      "  [9.16307152e-04 1.46832885e-02 1.33491516e-01 ... 3.21656885e-03\n",
      "   4.35881811e-05 2.38541143e-05]\n",
      "  [1.66002975e-03 6.78366283e-03 9.49678048e-02 ... 7.30912434e-03\n",
      "   7.73161324e-03 2.83623580e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5.97372164e-05 1.28913894e-01 4.39665258e-01 ... 1.13420058e-02\n",
      "   1.71237234e-02 0.00000000e+00]\n",
      "  [1.03528530e-03 1.07687958e-01 3.42871338e-01 ... 7.27235824e-02\n",
      "   2.15344230e-07 2.76495959e-03]\n",
      "  [1.03729721e-02 7.68406540e-02 2.90140659e-01 ... 2.99776830e-02\n",
      "   2.11678147e-02 4.98881627e-06]\n",
      "  [9.16307152e-04 9.65391546e-02 3.45684856e-01 ... 2.69835703e-02\n",
      "   2.12731361e-02 2.38541143e-05]\n",
      "  [1.66002975e-03 1.22163624e-01 2.81699091e-01 ... 3.72665189e-02\n",
      "   2.63388781e-03 2.83623580e-03]]\n",
      "\n",
      " [[5.97372164e-05 2.05929682e-04 2.45453920e-02 ... 1.40194707e-02\n",
      "   3.14998091e-03 0.00000000e+00]\n",
      "  [1.03528530e-03 2.04644189e-03 6.26459718e-03 ... 2.00438849e-03\n",
      "   3.47890705e-02 2.76495959e-03]\n",
      "  [1.03729721e-02 9.25339572e-03 1.03968207e-03 ... 2.67931004e-03\n",
      "   1.72147818e-03 4.98881627e-06]\n",
      "  [9.16307152e-04 3.92985623e-03 6.64987788e-03 ... 3.67671624e-03\n",
      "   1.69161032e-03 2.38541143e-05]\n",
      "  [1.66002975e-03 5.70108416e-04 5.92940778e-04 ... 1.01488875e-03\n",
      "   1.84038840e-02 2.83623580e-03]]\n",
      "\n",
      " [[1.83961429e-02 1.50050148e-02 2.08371272e-03 ... 5.77479936e-02\n",
      "   2.11282307e-03 0.00000000e+00]\n",
      "  [1.23622166e-02 8.39195121e-03 1.01587409e-03 ... 5.94963552e-03\n",
      "   3.11025120e-02 2.76495959e-03]\n",
      "  [1.72337645e-03 1.65247417e-03 6.20595552e-03 ... 3.01599931e-02\n",
      "   9.81660676e-04 4.98881627e-06]\n",
      "  [1.27895288e-02 5.49920741e-03 8.68787698e-04 ... 3.33209261e-02\n",
      "   9.59138095e-04 2.38541143e-05]\n",
      "  [1.05304327e-02 1.27618294e-02 7.51196872e-03 ... 2.36426275e-02\n",
      "   1.57506708e-02 2.83623580e-03]]], shape=(75, 5, 128), dtype=float32)\n",
      "dist tf.Tensor(\n",
      "[[0.00961203 0.01069723 0.01459939 0.00764833 0.01019546]\n",
      " [0.01221824 0.01149551 0.01974718 0.01214935 0.01364491]\n",
      " [0.01663778 0.01624897 0.02112733 0.01850787 0.01668877]\n",
      " [0.01625427 0.01596047 0.02285241 0.01599142 0.01432169]\n",
      " [0.01429026 0.01527501 0.01599294 0.01432613 0.01403025]\n",
      " [0.00902497 0.00972198 0.01805615 0.01028819 0.01148794]\n",
      " [0.01951521 0.01751365 0.01866416 0.01819233 0.01742686]\n",
      " [0.00937049 0.01208447 0.01722073 0.00922867 0.01176676]\n",
      " [0.01712531 0.01641855 0.01817568 0.01457923 0.01805581]\n",
      " [0.00859218 0.01013741 0.01760316 0.00890018 0.00975517]\n",
      " [0.02082369 0.01916914 0.02206965 0.02080408 0.01849731]\n",
      " [0.03601236 0.03499062 0.03313008 0.04073001 0.03269519]\n",
      " [0.03078534 0.03285293 0.03224039 0.02931035 0.02987447]\n",
      " [0.02512265 0.0235239  0.03042676 0.02397139 0.02472529]\n",
      " [0.02131578 0.01987693 0.02231287 0.02337001 0.01890418]\n",
      " [0.00997879 0.00958187 0.01806158 0.01001445 0.01175517]\n",
      " [0.01095794 0.01271535 0.01768555 0.01285025 0.01335518]\n",
      " [0.02876241 0.02936951 0.02928197 0.03206376 0.02872278]\n",
      " [0.00929381 0.00972069 0.0192038  0.01020853 0.01293605]\n",
      " [0.01452639 0.01507421 0.02005419 0.01172915 0.01598159]\n",
      " [0.01847987 0.01654252 0.02057174 0.02160449 0.01780719]\n",
      " [0.03951286 0.03839675 0.03716541 0.03967657 0.03594918]\n",
      " [0.00861409 0.00888871 0.02001114 0.00930172 0.00924035]\n",
      " [0.01687087 0.01690793 0.01946211 0.01781707 0.01818071]\n",
      " [0.01008003 0.00862208 0.01694265 0.01057023 0.01215606]\n",
      " [0.01710778 0.01503669 0.01919649 0.01645662 0.01342748]\n",
      " [0.01873274 0.01832954 0.01883255 0.01866291 0.01820961]\n",
      " [0.01247113 0.01231595 0.01846924 0.01537583 0.01463341]\n",
      " [0.01251322 0.00994814 0.01840988 0.01291523 0.01285626]\n",
      " [0.0323649  0.03235287 0.03002341 0.03252241 0.03435778]\n",
      " [0.01218802 0.01206854 0.01784188 0.01170146 0.01130946]\n",
      " [0.01333496 0.01194013 0.02043064 0.01089838 0.01207253]\n",
      " [0.00760972 0.00888478 0.01795811 0.00816734 0.0104148 ]\n",
      " [0.01474804 0.01737424 0.0241254  0.01724457 0.01838945]\n",
      " [0.02318359 0.02272852 0.02422795 0.02683697 0.02369318]\n",
      " [0.02206244 0.02190014 0.02212768 0.01930591 0.02316443]\n",
      " [0.01435029 0.01275041 0.0202394  0.01455524 0.01699335]\n",
      " [0.03653771 0.03320048 0.0304365  0.03865718 0.03159343]\n",
      " [0.01800954 0.01761436 0.02245079 0.01621022 0.01635709]\n",
      " [0.01840219 0.01758726 0.02685947 0.01852917 0.01816026]\n",
      " [0.01333608 0.01317669 0.01852018 0.01430512 0.01389575]\n",
      " [0.01133931 0.00983096 0.01784546 0.01002543 0.00954585]\n",
      " [0.01573605 0.01480645 0.02437668 0.015725   0.0153668 ]\n",
      " [0.00870779 0.00961168 0.0199516  0.00970043 0.01152328]\n",
      " [0.01647828 0.01504667 0.01635658 0.01885931 0.01390874]\n",
      " [0.01225228 0.01213695 0.01679484 0.01217714 0.01197901]\n",
      " [0.02207442 0.02002243 0.0263378  0.02048193 0.02373845]\n",
      " [0.01788857 0.01943772 0.021651   0.01955573 0.01927907]\n",
      " [0.02541413 0.02290179 0.02424747 0.02641535 0.02265266]\n",
      " [0.0120446  0.01172619 0.01997149 0.01207866 0.0132838 ]\n",
      " [0.02625236 0.02655732 0.02600764 0.0258469  0.02482333]\n",
      " [0.01234472 0.01133633 0.01905435 0.01140453 0.01336493]\n",
      " [0.01076623 0.01221544 0.0173974  0.01111072 0.01065523]\n",
      " [0.01013626 0.01113977 0.01571414 0.00979278 0.01212388]\n",
      " [0.05139358 0.05014452 0.041639   0.05599333 0.04596932]\n",
      " [0.01753759 0.01548587 0.02135799 0.01738064 0.01697642]\n",
      " [0.01142343 0.01254846 0.01597134 0.01186267 0.01242853]\n",
      " [0.0337612  0.03190514 0.03879569 0.02952835 0.03524511]\n",
      " [0.0213594  0.02360384 0.0296694  0.0217761  0.02334995]\n",
      " [0.01311457 0.01509821 0.01902663 0.0115419  0.01517976]\n",
      " [0.01234689 0.0128691  0.01628611 0.01402802 0.01513521]\n",
      " [0.04141054 0.03759472 0.0410826  0.04091139 0.03569093]\n",
      " [0.01487476 0.01498969 0.02123997 0.01450937 0.01605728]\n",
      " [0.0213982  0.0212628  0.02748393 0.02396997 0.01987643]\n",
      " [0.01194423 0.01084115 0.01846312 0.01198525 0.01153571]\n",
      " [0.01077725 0.01103558 0.01422613 0.0129372  0.01109605]\n",
      " [0.00965378 0.0100399  0.01932992 0.00948612 0.01049891]\n",
      " [0.01674044 0.01935676 0.0230537  0.01647835 0.01833851]\n",
      " [0.009833   0.0095601  0.01413058 0.0103393  0.00870465]\n",
      " [0.01562862 0.01489141 0.01921586 0.01484063 0.01443504]\n",
      " [0.02154986 0.01979067 0.02949922 0.02125823 0.02233649]\n",
      " [0.02080701 0.02067108 0.02039658 0.02250851 0.01863121]\n",
      " [0.04582138 0.0442249  0.0401761  0.04514751 0.04372169]\n",
      " [0.00826785 0.00837519 0.01683505 0.0085203  0.01087493]\n",
      " [0.02479945 0.02312381 0.02114389 0.02225413 0.02277171]], shape=(75, 5), dtype=float32)\n",
      "log tf.Tensor(\n",
      "[[-1.608502  -1.6095872 -1.6134894 -1.6065383 -1.6090854]\n",
      " [-1.6078097 -1.6070869 -1.6153386 -1.6077408 -1.6092364]\n",
      " [-1.6082352 -1.6078464 -1.6127248 -1.6101053 -1.6082861]\n",
      " [-1.6086205 -1.6083267 -1.6152186 -1.6083577 -1.6066879]\n",
      " [-1.6089455 -1.6099303 -1.6106482 -1.6089814 -1.6086855]\n",
      " [-1.6067524 -1.6074494 -1.6157836 -1.6080157 -1.6092154]\n",
      " [-1.610691  -1.6086894 -1.6098399 -1.6093681 -1.6086026]\n",
      " [-1.6068784 -1.6095923 -1.6147286 -1.6067365 -1.6092746]\n",
      " [-1.609693  -1.6089863 -1.6107434 -1.607147  -1.6106236]\n",
      " [-1.607038  -1.6085832 -1.616049  -1.607346  -1.608201 ]\n",
      " [-1.6099896 -1.6083351 -1.6112356 -1.6099701 -1.6076633]\n",
      " [-1.6099427 -1.6089209 -1.6070604 -1.6146604 -1.6066256]\n",
      " [-1.6092114 -1.611279  -1.6106665 -1.6077365 -1.6083006]\n",
      " [-1.6090096 -1.6074109 -1.6143137 -1.6078584 -1.6086123]\n",
      " [-1.6095991 -1.6081603 -1.6105962 -1.6116533 -1.6071875]\n",
      " [-1.6075435 -1.6071465 -1.6156262 -1.6075791 -1.6093198]\n",
      " [-1.6068854 -1.6086428 -1.613613  -1.6087778 -1.6092826]\n",
      " [-1.608561  -1.6091682 -1.6090807 -1.6118624 -1.6085215]\n",
      " [-1.6064659 -1.6068928 -1.6163759 -1.6073806 -1.6101081]\n",
      " [-1.6084949 -1.6090426 -1.6140227 -1.6056976 -1.6099501]\n",
      " [-1.6089183 -1.6069809 -1.6110102 -1.6120429 -1.6082456]\n",
      " [-1.6108116 -1.6096956 -1.6084642 -1.6109754 -1.607248 ]\n",
      " [-1.6068505 -1.6071252 -1.6182475 -1.6075381 -1.6074767]\n",
      " [-1.6084615 -1.6084986 -1.6110528 -1.6094077 -1.6097714]\n",
      " [-1.6078478 -1.6063899 -1.6147105 -1.608338  -1.6099238]\n",
      " [-1.6103027 -1.6082315 -1.6123914 -1.6096514 -1.6066223]\n",
      " [-1.6096171 -1.609214  -1.609717  -1.6095474 -1.609094 ]\n",
      " [-1.6072586 -1.6071033 -1.6132567 -1.6101632 -1.6094208]\n",
      " [-1.6086264 -1.6060613 -1.614523  -1.6090285 -1.6089694]\n",
      " [-1.6094794 -1.6094674 -1.6071379 -1.6096369 -1.6114722]\n",
      " [-1.608607  -1.6084876 -1.6142609 -1.6081204 -1.6077285]\n",
      " [-1.6090435 -1.6076486 -1.616139  -1.6066068 -1.6077809]\n",
      " [-1.6064479 -1.607723  -1.6167964 -1.6070056 -1.609253 ]\n",
      " [-1.6058145 -1.6084406 -1.6151918 -1.6083109 -1.6094558]\n",
      " [-1.6084884 -1.6080334 -1.6095328 -1.6121418 -1.6089981]\n",
      " [-1.609789  -1.6096268 -1.6098543 -1.6070325 -1.6108911]\n",
      " [-1.6080139 -1.606414  -1.6139029 -1.6082188 -1.6106569]\n",
      " [-1.6118953 -1.608558  -1.6057941 -1.6140147 -1.606951 ]\n",
      " [-1.6093217 -1.6089265 -1.613763  -1.6075224 -1.6076692]\n",
      " [-1.6079385 -1.6071236 -1.6163958 -1.6080655 -1.6076967]\n",
      " [-1.6081291 -1.6079698 -1.6133132 -1.6090982 -1.6086888]\n",
      " [-1.6090648 -1.6075565 -1.6155709 -1.6077509 -1.6072713]\n",
      " [-1.6079783 -1.6070487 -1.616619  -1.6079673 -1.6076092]\n",
      " [-1.6062552 -1.607159  -1.617499  -1.6072478 -1.6090707]\n",
      " [-1.6097877 -1.6083561 -1.609666  -1.6121687 -1.6072181]\n",
      " [-1.6086239 -1.6085086 -1.6131665 -1.6085488 -1.6083506]\n",
      " [-1.6089839 -1.6069319 -1.6132473 -1.6073915 -1.6106479]\n",
      " [-1.6077648 -1.609314  -1.6115273 -1.609432  -1.6091553]\n",
      " [-1.6105268 -1.6080145 -1.6093601 -1.611528  -1.6077653]\n",
      " [-1.6076665 -1.6073481 -1.6155934 -1.6077006 -1.6089057]\n",
      " [-1.609793  -1.6100979 -1.6095482 -1.6093874 -1.6083639]\n",
      " [-1.6082858 -1.6072774 -1.6149955 -1.6073456 -1.609306 ]\n",
      " [-1.6077783 -1.6092275 -1.6144094 -1.6081228 -1.6076673]\n",
      " [-1.607795  -1.6087985 -1.6133729 -1.6074516 -1.6097827]\n",
      " [-1.6118155 -1.6105664 -1.6020609 -1.6164153 -1.6063912]\n",
      " [-1.6092297 -1.607178  -1.6130501 -1.6090727 -1.6086686]\n",
      " [-1.6080158 -1.6091408 -1.6125637 -1.6084551 -1.6090208]\n",
      " [-1.6093569 -1.6075008 -1.6143913 -1.605124  -1.6108408]\n",
      " [-1.60685   -1.6090945 -1.61516   -1.6072668 -1.6088406]\n",
      " [-1.6077634 -1.6097469 -1.6136754 -1.6061907 -1.6098286]\n",
      " [-1.6076528 -1.608175  -1.611592  -1.6093339 -1.6104411]\n",
      " [-1.611513  -1.6076971 -1.6111851 -1.6110138 -1.6057934]\n",
      " [-1.6079816 -1.6080965 -1.6143467 -1.6076162 -1.6091641]\n",
      " [-1.6080414 -1.6079061 -1.6141272 -1.6106132 -1.6065197]\n",
      " [-1.608432  -1.607329  -1.614951  -1.6084731 -1.6080235]\n",
      " [-1.6082015 -1.6084598 -1.6116503 -1.6103615 -1.6085203]\n",
      " [-1.6072971 -1.6076832 -1.6169733 -1.6071295 -1.6081423]\n",
      " [-1.6073877 -1.610004  -1.6137009 -1.6071255 -1.6089857]\n",
      " [-1.608759  -1.6084862 -1.6130567 -1.6092653 -1.6076307]\n",
      " [-1.6092656 -1.6085284 -1.6128528 -1.6084776 -1.608072 ]\n",
      " [-1.6081067 -1.6063476 -1.6160561 -1.6078151 -1.6088934]\n",
      " [-1.6096427 -1.6095068 -1.6092323 -1.6113442 -1.6074669]\n",
      " [-1.6114429 -1.6098465 -1.6057976 -1.610769  -1.6093433]\n",
      " [-1.6071365 -1.6072438 -1.6157037 -1.607389  -1.6097436]\n",
      " [-1.6114196 -1.609744  -1.607764  -1.6088742 -1.6093918]], shape=(75, 5), dtype=float32)\n",
      "loss1 tf.Tensor(1.6085321, shape=(), dtype=float32)\n",
      "pred tf.Tensor(\n",
      "[[0.20018725 0.19997013 0.19919132 0.20058075 0.20007049]\n",
      " [0.2003259  0.20047075 0.19882333 0.20033972 0.20004033]\n",
      " [0.20024069 0.20031856 0.19934371 0.19986658 0.20023048]\n",
      " [0.20016354 0.20022237 0.19884719 0.20021616 0.20055075]\n",
      " [0.2000985  0.19990154 0.19975807 0.20009132 0.20015052]\n",
      " [0.20053783 0.2003981  0.1987349  0.20028466 0.20004451]\n",
      " [0.19974956 0.20014976 0.19991963 0.20001397 0.20016713]\n",
      " [0.20051257 0.19996911 0.19894466 0.200541   0.20003267]\n",
      " [0.19994897 0.20009033 0.19973905 0.2004587  0.199763  ]\n",
      " [0.20048055 0.200171   0.19868214 0.20041882 0.20024753]\n",
      " [0.19988969 0.20022069 0.19964078 0.19989361 0.20035525]\n",
      " [0.19989905 0.2001034  0.20047605 0.19895822 0.20056325]\n",
      " [0.2000453  0.19963212 0.19975443 0.20034058 0.2002276 ]\n",
      " [0.20008565 0.2004058  0.1990272  0.20031615 0.20016518]\n",
      " [0.19996777 0.2002557  0.19976848 0.19955742 0.2004506 ]\n",
      " [0.20037925 0.20045881 0.19876616 0.20037213 0.20002364]\n",
      " [0.20051114 0.20015907 0.19916672 0.20013207 0.20003104]\n",
      " [0.20017546 0.20005397 0.20007148 0.19951572 0.20018339]\n",
      " [0.20059527 0.20050967 0.19861719 0.20041187 0.19986598]\n",
      " [0.20018871 0.20007907 0.19908516 0.20074947 0.1998976 ]\n",
      " [0.20010395 0.20049201 0.19968581 0.19947968 0.2002386 ]\n",
      " [0.19972543 0.19994847 0.20019484 0.19969274 0.20043847]\n",
      " [0.20051816 0.20046312 0.19824581 0.20038033 0.20039262]\n",
      " [0.20019537 0.20018795 0.19967729 0.20000605 0.19993332]\n",
      " [0.20031828 0.20061053 0.19894826 0.2002201  0.19990283]\n",
      " [0.19982712 0.20024142 0.19941019 0.1999573  0.20056391]\n",
      " [0.19996415 0.2000448  0.1999442  0.19997813 0.20006879]\n",
      " [0.20043635 0.20046745 0.1992377  0.19985498 0.20000342]\n",
      " [0.20016237 0.20067646 0.19898555 0.20008191 0.20009372]\n",
      " [0.19999169 0.19999409 0.20046052 0.1999602  0.19959353]\n",
      " [0.20016626 0.20019019 0.19903773 0.20026366 0.2003422 ]\n",
      " [0.20007892 0.20035818 0.19866425 0.20056702 0.20033167]\n",
      " [0.2005989  0.20034328 0.19853373 0.20048708 0.20003699]\n",
      " [0.200726   0.20019956 0.19885251 0.2002255  0.1999964 ]\n",
      " [0.20018998 0.2002811  0.19998102 0.19945994 0.200088  ]\n",
      " [0.19992979 0.19996223 0.19991674 0.20048165 0.1997096 ]\n",
      " [0.20028499 0.20060569 0.19910897 0.20024395 0.19975634]\n",
      " [0.19950914 0.20017605 0.2007301  0.19908673 0.200498  ]\n",
      " [0.20002325 0.20010231 0.19913687 0.20038348 0.20035405]\n",
      " [0.20030011 0.2004634  0.19861326 0.20027468 0.20034857]\n",
      " [0.20026192 0.20029384 0.19922642 0.20006795 0.20014986]\n",
      " [0.20007464 0.20037666 0.19877715 0.2003377  0.20043379]\n",
      " [0.20029214 0.20047842 0.19856894 0.20029435 0.20036612]\n",
      " [0.20063755 0.20045628 0.19839425 0.20043848 0.20007345]\n",
      " [0.19993004 0.20021649 0.19995439 0.19945458 0.20044445]\n",
      " [0.20016287 0.20018595 0.19925568 0.20017791 0.20021757]\n",
      " [0.2000908  0.20050181 0.19923957 0.20040971 0.19975813]\n",
      " [0.20033489 0.20002478 0.19958256 0.20000118 0.20005651]\n",
      " [0.19978234 0.2002849  0.20001556 0.19958243 0.2003348 ]\n",
      " [0.2003546  0.20041841 0.1987727  0.20034778 0.20010649]\n",
      " [0.19992901 0.19986804 0.19997795 0.20001009 0.20021492]\n",
      " [0.20023057 0.20043257 0.19889158 0.2004189  0.20002638]\n",
      " [0.2003322  0.20004207 0.19900814 0.20026319 0.20035443]\n",
      " [0.20032883 0.2001279  0.19921453 0.20039766 0.19993106]\n",
      " [0.19952506 0.19977443 0.20148087 0.1986094  0.20061027]\n",
      " [0.20004164 0.20045249 0.19927886 0.20007303 0.20015393]\n",
      " [0.20028464 0.20005944 0.19937584 0.2001967  0.20008343]\n",
      " [0.20001622 0.20038779 0.19901176 0.20086464 0.19971964]\n",
      " [0.20051825 0.20006871 0.19885884 0.20043471 0.2001195 ]\n",
      " [0.20033519 0.1999382  0.19915429 0.2006505  0.19992189]\n",
      " [0.20035735 0.20025274 0.19956966 0.2000208  0.19979946]\n",
      " [0.19958542 0.20034845 0.19965087 0.19968505 0.20073023]\n",
      " [0.20029148 0.20026846 0.19902062 0.20036468 0.20005476]\n",
      " [0.20027947 0.2003066  0.19906433 0.19976506 0.20058449]\n",
      " [0.20020126 0.20042223 0.19890043 0.20019305 0.20028307]\n",
      " [0.2002474  0.20019569 0.19955796 0.19981535 0.20018359]\n",
      " [0.2004286  0.20035124 0.19849859 0.20046222 0.2002593 ]\n",
      " [0.20041049 0.19988681 0.19914922 0.20046301 0.20009047]\n",
      " [0.20013581 0.20019042 0.19927756 0.2000345  0.20036176]\n",
      " [0.20003445 0.20018198 0.19931816 0.20019212 0.20027335]\n",
      " [0.20026642 0.20061903 0.19868073 0.20032482 0.20010893]\n",
      " [0.19995902 0.19998622 0.20004112 0.19961908 0.20039457]\n",
      " [0.1995994  0.1999183  0.20072939 0.19973396 0.20001894]\n",
      " [0.20046082 0.2004393  0.19875076 0.20041023 0.1999389 ]\n",
      " [0.19960408 0.19993882 0.20033507 0.20011277 0.20000923]], shape=(75, 5), dtype=float32)\n",
      "std tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tquery_patches, tsupport_patches, query_labels, support_labels = new_episode(patches_class_ip,K1,C,N,train_class_labels)     \n",
    "train_step(tsupport_patches, tquery_patches,support_labels, query_labels, K1, C, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6kykozUCMjn"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'E:\\Engginearing\\SAKEC\\SEM 6\\Major Project\\Research\\SAMPLE_CODE_TF2_Keras\\Inprogress\\Hyperspectral_Classification\\Training checkpoints\\IP\\5_shot_ckpts\\\\New_train_5_way_ip_25_128'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, ProtoModel = ProtoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 166476,
     "status": "error",
     "timestamp": 1675333632398,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "N4DqXA2lN6t8",
    "outputId": "64dccfb2-f4e5-4242-ad83-d30a9643f285"
   },
   "outputs": [],
   "source": [
    "n_episodes = 100\n",
    "temp_list = []\n",
    "for epoch in range(50): # n_epochs-140\n",
    "    train_loss.reset_states()  \n",
    "    train_acc.reset_states()\n",
    "    \n",
    "    for epi in range(n_episodes): \n",
    "        tquery_patches, tsupport_patches, query_labels, support_labels = new_episode(patches_class_ip,K1,C,N,train_class_labels)     \n",
    "        train_step(tsupport_patches, tquery_patches,support_labels, query_labels, K1, C, N)    \n",
    "        template = 'Epoch {}, Episode {}, Train Loss: {:.2f}, Train Accuracy: {:.2f}'\n",
    "        print(template.format(epoch+1, epi+1,train_loss.result(),train_acc.result()*100))\n",
    "    if epoch % 5 == 0 and epoch != 0 :\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9p9sGw0yAon"
   },
   "source": [
    "**Tuning_5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f64ExXqB_J_F"
   },
   "outputs": [],
   "source": [
    "tune_set_5 = [[] for i in range(6)]\n",
    "for j in range(6) :\n",
    "  tune_set_5[j] = test_patches_class[j][:5,:,:,:,:]   # for each class first 5 samples taken\n",
    "std_tune_5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQHAAuML_BF8"
   },
   "outputs": [],
   "source": [
    "def tune_episode(tune_set,tC,tK,tN,test_class_labels) :\n",
    "  selected_classes = np.random.choice(test_class_labels,tC,replace=False)\n",
    "  support_labels  = list(selected_classes)\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    np.random.shuffle(tune_set[y])    \n",
    "    support_imgs = tune_set[y][:tK,:,:,:,:]    #Support 1, Query 4\n",
    "    query_imgs = tune_set[y][tK:5,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(tN) :\n",
    "      query_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  query_patches = tf.convert_to_tensor(np.reshape(np.asarray(query_patches),(tC*tN,im_height,im_width,im_depth,1)),dtype=tf.float32)\n",
    "  support_patches = tf.convert_to_tensor(np.reshape(np.asarray(support_patches),(tC*tK,im_height,im_width,im_depth,1)),dtype=tf.float32)\n",
    "  return query_patches, support_patches, query_labels, support_labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78mUqPSj3DA6"
   },
   "outputs": [],
   "source": [
    "query_patches, support_patches, query_labels, support_labels = tune_episode(tune_set_5,4,1,4,test_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KznikxjCElAR"
   },
   "outputs": [],
   "source": [
    "# Metrics to gather\n",
    "tune_loss = tf.metrics.Mean(name='tune_loss')\n",
    "tune_acc = tf.metrics.Mean(name='tune_accuracy')\n",
    "\n",
    "def tune_step(support, query, support_labels, query_labels, K, C, N):\n",
    "    # Forward & update gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N,n_times,training=True)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Log loss and accuracy for step\n",
    "    tune_loss(loss)\n",
    "    tune_acc(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlIrGMXBKN8Y"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir1 = '/content/drive/My Drive/Research/SAMPLE_CODE_TF2_Keras/Inprogress/Hyperspectral_Classification/Training checkpoints/IP/5_shot_ckpts/New_train_5_way_ip_25_128/Tune'\n",
    "checkpoint_prefix1 = os.path.join(checkpoint_dir1, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 ProtoModel = ProtoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 478694,
     "status": "error",
     "timestamp": 1664643887678,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "abc2CqQdBRFB",
    "outputId": "d51f7923-cafb-4f5e-b0d8-f63446e3fd53"
   },
   "outputs": [],
   "source": [
    "n_episodes = 100\n",
    "temp_list = []\n",
    "std_tune_5 = []\n",
    "for epoch in range(41): \n",
    "    tune_loss.reset_states()  \n",
    "    tune_acc.reset_states()    \n",
    "    for epi in range(n_episodes+1): \n",
    "        tquery_patches, tsupport_patches, query_labels, support_labels = tune_episode(tune_set_5,3,1,4,test_class_labels)    \n",
    "        tune_step(tsupport_patches, tquery_patches,support_labels, query_labels, 1, 3, 4)      \n",
    "        \n",
    "    template = 'Epoch {}, Tune Loss: {:.2f}, Tune Accuracy: {:.2f}'\n",
    "    print(template.format(epoch+1,tune_loss.result(),tune_acc.result()*100))\n",
    "    if (epoch+1)%5 == 0 :\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPjwIpM_tPz0"
   },
   "outputs": [],
   "source": [
    "def test_episode(test_patches_class,test_class_labels,test_C,test_K,i,f) :\n",
    "  selected_classes = test_class_labels[i:f]   # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  support_labels = list(selected_classes)\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    support_imgs = test_patches_class[y][:test_K,:,:,:,:]\n",
    "    query_imgs = test_patches_class[y][test_K:,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(query_imgs.shape[0]) :\n",
    "      query_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  x = len(query_labels)\n",
    "  query_patches = tf.convert_to_tensor(np.reshape(np.asarray(query_patches),(x,im_height,im_width,im_depth,1)),dtype=tf.float32)\n",
    "  support_patches = tf.convert_to_tensor(np.reshape(np.asarray(support_patches),(test_C*test_K,im_height,im_width,im_depth,1)),dtype=tf.float32)\n",
    "  return query_patches, support_patches, query_labels, support_labels,x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wO2QtQRf3ZpL"
   },
   "outputs": [],
   "source": [
    "query_patches, support_patches, query_labels, support_labels,x = test_episode(test_patches_class,test_class_labels,3,5,0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SP2cSUDD1H2n"
   },
   "outputs": [],
   "source": [
    "# Metrics to gather\n",
    "test_loss = tf.metrics.Mean(name='test_loss')\n",
    "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
    "def test_step(support, query, support_labels, query_labels, K, C, y):\n",
    "    loss, mc_predictions, mean_accuracy, classwise_mean_acc, y = ProtoModel(support, query, support_labels, query_labels, K, C, y,n_times,training=False)\n",
    "    return loss, mc_predictions, mean_accuracy, classwise_mean_acc, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5625,
     "status": "ok",
     "timestamp": 1664643907115,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "XsWfzZo5e242",
    "outputId": "6803e128-3d80-44d5-e75b-e6c25e3657dc"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1): #1000\n",
    "    test_loss.reset_states()  \n",
    "    test_acc.reset_states()        \n",
    "    tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1 = test_episode(test_patches_class,test_class_labels,3,5,0,3)    \n",
    "    loss1, mc_predictions1, mean_accuracy1, classwise_mean_acc1, y1 = test_step(tsupport_patches1, tquery_patches1,support_labels1, query_labels1, 5, 3, x1/3)      \n",
    "    print('OA1',mean_accuracy1)\n",
    "# Class-wise Accuracy\n",
    "    for i in range(tC) :\n",
    "      print('class',i+1,classwise_mean_acc1[i])\n",
    "    print('loss',loss1)\n",
    "    tquery_patches2, tsupport_patches2, query_labels2, support_labels2, x2 = test_episode(test_patches_class,test_class_labels,3,5,3,6)    \n",
    "    loss2, mc_predictions2, mean_accuracy2, classwise_mean_acc2, y2 = test_step(tsupport_patches2, tquery_patches2,support_labels2, query_labels2, 5, 3, x2/3)\n",
    "    print('OA2',mean_accuracy2) \n",
    "# Class-wise Accuracy\n",
    "    for i in range(tC) :\n",
    "      print('class',i+4,classwise_mean_acc2[i])\n",
    "    print('loss',loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRXITw9htGuw"
   },
   "source": [
    "**Overall Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1664643908863,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "oGeG6aLFtFvM",
    "outputId": "d03c0ed0-0266-42c9-b9e6-14eb0f4bdec0"
   },
   "outputs": [],
   "source": [
    "mean_predictions1 =  tf.reduce_mean(mc_predictions1,axis=0)\n",
    "mean_predictions2 =  tf.reduce_mean(mc_predictions2,axis=0)\n",
    "overall_predictions = tf.concat([mean_predictions1,mean_predictions2],axis=0)\n",
    "overall_true_labels = tf.concat([y1,y2],axis=0)\n",
    "correct_pred = tf.cast(tf.equal(                                             # accuracy for the current pass\n",
    "            tf.cast(tf.argmax(overall_predictions, axis=-1), tf.int32), \n",
    "            tf.cast(tf.argmax(overall_true_labels,axis=-1), tf.int32)), tf.float32)\n",
    "o_acc = tf.reduce_mean(correct_pred) \n",
    "print(\"Overall accuracy:\",o_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxDxvPzisig0"
   },
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1664643926157,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "CoyQLsRUshg7",
    "outputId": "5c3a5027-cded-4d2b-951b-a91c322c6793"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "mean_predictions1 =  tf.reduce_mean(mc_predictions1,axis=0)\n",
    "cm_pred1 = tf.argmax(mean_predictions1, axis=-1)\n",
    "mean_predictions2 =  tf.reduce_mean(mc_predictions2,axis=0)\n",
    "cm_pred2 = tf.argmax(mean_predictions2, axis=-1) + 3\n",
    "overall_predictions = tf.concat([cm_pred1,cm_pred2],axis=0)\n",
    "cm_true1 = tf.argmax(y1,axis=-1)\n",
    "cm_true2 = tf.argmax(y2,axis=-1) + 3\n",
    "overall_true_labels = tf.concat([cm_true1,cm_true2],axis=0)\n",
    "results = confusion_matrix(overall_true_labels,overall_predictions) \n",
    "print ('Confusion Matrix :')\n",
    "print(results) \n",
    "print ('Report : ')\n",
    "print (classification_report(overall_true_labels, overall_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOP-rcMX-4jl"
   },
   "source": [
    "**Kappa Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1664643932041,
     "user": {
      "displayName": "Mayank Kantharia",
      "userId": "02386211270688916554"
     },
     "user_tz": -330
    },
    "id": "bkUfTXWg-3xd",
    "outputId": "6a7750ff-dc87-49aa-ce54-de0b649e17c6"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.cohen_kappa_score(overall_true_labels, overall_predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
