{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aditya Sawant's Version of SPN_IP_5Shot.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Used\n",
    "\n",
    "- tensorflow\n",
    "- sklearn\n",
    "- numpy\n",
    "- matplotlib\n",
    "- pandas\n",
    "- scipy\n",
    "- tensorflow_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn numpy matplotlib scipy tensorflow_probability pandas plotly \n",
    "# tensorflow[and-cuda]==2.10 [cuDNN 8.1.1 CUDA 11.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def timeIt(func):\n",
    "    \"\"\"\n",
    "    timeIt is a decorator function to time the execution of a function.\n",
    "    \n",
    "    :param func: function to be timed\n",
    "    :return: wrapper function\n",
    "    \"\"\"\n",
    "    def wrap_func(*args, **kwargs):\n",
    "        t1 = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        t2 = time()\n",
    "        print(f'Function {func.__name__!r} executed in {(t2-t1):.4f}s')\n",
    "        return result\n",
    "    return wrap_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingData = pd.DataFrame(columns=['Loss', 'Accuracy'])\n",
    "def plotData(data, testing=False):\n",
    "    \n",
    "    if testing:\n",
    "        accuracy1_values = [item[0] for item in data]\n",
    "        accuracy2_values = [item[1] for item in data]\n",
    "        loss1_values = [item[2] for item in data]\n",
    "        loss2_values = [item[3] for item in data]\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss1_values, color='red', label='Loss')\n",
    "        plt.plot(accuracy1_values, color='blue', label='Accuracy')\n",
    "        plt.xlabel('Epoch/Episode')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Loss and Overall Accuracy 1')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss2_values, color='red', label='Loss')\n",
    "        plt.plot(accuracy2_values, color='blue', label='Accuracy')\n",
    "        plt.xlabel('Epoch/Episode')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Loss and Overall Accuracy 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        loss_values = [item[0] for item in data]\n",
    "        accuracy_values = [item[1] for item in data]\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_values, color='red', label='Loss')\n",
    "        plt.plot(accuracy_values, color='blue', label='Accuracy')\n",
    "        plt.xlabel('Epoch/Episode')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Loss and Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.10.0-rc3-6-g359c3cdfc5f 2.10.0\n",
      "True\n",
      "Number of GPUs Available:  1\n",
      "Number of Devices Available:  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import statistics\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "  \n",
    "from operator import truediv\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version.GIT_VERSION, tf.version.VERSION)\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(\"Number of GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Number of Devices Available: \", len(tf.config.experimental.list_physical_devices()))\n",
    "# import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.compat.v1.distributions import Bernoulli\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "from datetime import date, datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.Data import Data\n",
    "from lib.Stats import Stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test each code block individually\n",
    "TEST_BLOCKS: bool = False\n",
    "CWD: str = os.getcwd()\n",
    "VERBOSE: bool = False\n",
    "\n",
    "SAVE_REPORT: bool = True\n",
    "SAVE_MODEL: bool = False\n",
    "# Data Loading and Preprocessing\n",
    "\n",
    "\n",
    "# Dataset Used : Indian Pines\n",
    "DATASET: str = 'IP' # IP (indian_pines) PU (pavia_university) SA (salinas) HU (houston) \n",
    "PATH_TO_DATASET: str = CWD + '\\\\Datasets\\\\'\n",
    "\n",
    "# PCA\n",
    "PCA_COMPONENTS: int = 30 # Number of components to keep after PCA reduction\n",
    "\n",
    "# Window size for forming image cubes\n",
    "WINDOW_SIZE: int = 11\n",
    "\n",
    "# Image dimensions after forming image cubes\n",
    "IMAGE_WIDTH: int\n",
    "IMAGE_HEIGHT: int\n",
    "IMAGE_DEPTH: int\n",
    "IMAGE_CHANNEL: int \n",
    "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH, IMAGE_CHANNEL = 11, 11, 30, 1\n",
    "\n",
    "# Model Parameters\n",
    "\n",
    "N_TIMES = 1 # Number of times to run the model. Internally, the model is runs each episode N_TIMES times\n",
    "\n",
    "# Learning Rate\n",
    "LEARNING_RATE: float = 0.00001\n",
    "\n",
    "# Temprature Scaling\n",
    "TAU: float = 1.8\n",
    "\n",
    "# C (No. of Classes) K (No. of Samples per Class) N (No. of Patches per Class)\n",
    "TRAIN_C: int = 5 # Number of classes to be used for training\n",
    "TRAIN_K: int = 5 # Number of patches per class to be used for support during training\n",
    "TRAIN_N: int = 15 # Number of patches per class to be used for query during training\n",
    "\n",
    "TUNE_C: int = 3 # Number of classes to be used for testing\n",
    "TUNE_K: int = 1 # Number of patches per class to be used for support during testing\n",
    "TUNE_N: int = 4 # Number of patches per class to be used for query during testing\n",
    "\n",
    "TEST_C: int = 3 # Number of classes to be used for testing\n",
    "TEST_K: int = 5 # Number of patches per class to be used for support during testing\n",
    "TEST_N: int = 5 # Number of patches per class to be used for query during testing\n",
    "\n",
    "# ===================================\n",
    "# DO NOT REMOVE THIS.\n",
    "tC = 3   # classes in a test episode \n",
    "# Don't know this yet, probably used in the model to calculate loss\n",
    "MC_LOSS_WEIGHT: int = 5 \n",
    "# DIRECTLY USED IN PROTOTYPICAL NETWORK CLASS IN TESTING CASE\n",
    "# ===================================\n",
    "\n",
    "# Training Epochs\n",
    "TRAINING_EPOCH: int = 1  # 50\n",
    "\n",
    "# Training Episode\n",
    "TRAINING_EPISODE: int = 1 # 100\n",
    "\n",
    "# Tunning Epochs\n",
    "TUNNING_EPOCH: int = 41\n",
    "\n",
    "# Tunning Episode\n",
    "TUNNING_EPISODE: int = 100\n",
    "\n",
    "# Testing Epochs\n",
    "TESTING_EPOCH: int = 1000\n",
    "\n",
    "# Metrics to be used for evaluation\n",
    "train_loss = tf.metrics.Mean(name='train_loss')\n",
    "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
    "tune_loss = tf.metrics.Mean(name='tune_loss')\n",
    "tune_acc = tf.metrics.Mean(name='tune_accuracy')\n",
    "test_loss = tf.metrics.Mean(name='test_loss')\n",
    "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
    "\n",
    "trainingData = []\n",
    "tunningData = []\n",
    "testingData = []\n",
    "\n",
    "run_folder =  f'{date.today()}' + '-' + f'{datetime.now().hour}_5_1' + '\\\\' \n",
    "\n",
    "checkpoint_dir = CWD + '\\\\saves\\\\' + run_folder + DATASET + '\\\\' + f'{TRAIN_K}_shot_way' + '\\\\Train'\n",
    "checkpoint_prefix_train = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint_dir1 = CWD + '\\\\saves\\\\' + run_folder + DATASET + '\\\\' + f'{TRAIN_K}_shot_way' + '\\\\Train\\\\Tune'\n",
    "checkpoint_prefix_tune = os.path.join(checkpoint_dir1, \"ckpt\")\n",
    "\n",
    "report_path = CWD + f'\\\\Reports\\\\Report_{date.today()}_{str(datetime.now()).split(\".\")[0].split()[1].replace(\":\", \"-\")}.txt'\n",
    "model_save_path = CWD + '\\\\saves\\\\' + run_folder + DATASET + '\\\\' + f'{TRAIN_K}_shot_way' + '\\\\Train\\\\encoder.h5'\n",
    "\n",
    "\n",
    "checkpoint = None  # To be used for loading checkpoints. Declared in the Main Block\n",
    "ProtoModel = None  # Prototypical Network Object. Declared in the Main Block\n",
    "model = None  # Model Object. Declared in the Main Block\n",
    "optimizer = None  # Optimizer Object. Declared in the Main Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    \"\"\"\n",
    "    createModel() function creates the model architecture for the 3D CNN model.\n",
    "    :return: model \n",
    "    \n",
    "    The model architecture is as follows:\n",
    "    1. Input layer\n",
    "    2. 3D Convolution layer with 8 filters, kernel size (3,3,7), activation function 'relu' and padding 'same'\n",
    "    3. Spatial Dropout layer with dropout rate 0.3\n",
    "    4. 3D Convolution layer with 16 filters, kernel size (3,3,5), activation function 'relu' and padding 'same'\n",
    "    5. Spatial Dropout layer with dropout rate 0.3\n",
    "    6. 3D Convolution layer with 32 filters, kernel size (3,3,3), activation function 'relu'\n",
    "    7. Reshape layer to reshape the output of 3D Convolution layer to 2D\n",
    "    8. 2D Convolution layer with 64 filters, kernel size (3,3), activation function 'relu'\n",
    "    9. Flatten layer to flatten the output of 2D Convolution layer\n",
    "    10. Dropout layer with dropout rate 0.4\n",
    "    11. Dense layer with 256 neurons and activation function 'relu'\n",
    "    12. Dropout layer with dropout rate 0.4\n",
    "    13. Dense layer with 128 neurons and activation function 'relu'\n",
    "    14. Output layer with 128 neurons and activation function 'relu'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # input_layer = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL))\n",
    "    \n",
    "    # output_layer_1_conv = layers.Conv3D(filters=8, kernel_size=(3,3,7), activation='relu',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL),padding='same')(input_layer)\n",
    "    \n",
    "    # output_layer_1_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_1_conv,training=True)\n",
    "    \n",
    "    # output_layer_2_conv = layers.Conv3D(filters=16, kernel_size=(3,3,5), activation='relu',padding='same')(output_layer_1_drop3d)\n",
    "    \n",
    "    # output_layer_2_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_2_conv,training=True)\n",
    "    \n",
    "    # output_layer_3_conv = layers.Conv3D(filters=32, kernel_size=(3,3,3), activation= 'relu')(output_layer_2_drop3d)\n",
    "    \n",
    "    # output_layer_3_reshaped = layers.Reshape((output_layer_3_conv.shape[1], output_layer_3_conv.shape[2], output_layer_3_conv.shape[3]*output_layer_3_conv.shape[4]))(output_layer_3_conv)\n",
    "    \n",
    "    # output_layer_4_conv = layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(output_layer_3_reshaped)\n",
    "    \n",
    "    # output_layer_4_flatten = layers.Flatten()(output_layer_4_conv)\n",
    "    \n",
    "    # output_layer_4_drop = layers.Dropout(rate=0.4)(output_layer_4_flatten,training=True)\n",
    "    \n",
    "    # output_layer_4_dense = layers.Dense(256, activation='relu')(output_layer_4_drop)\n",
    "    \n",
    "    # output_layer_5_conv = layers.Dropout(0.4)(output_layer_4_dense,training=True)\n",
    "    \n",
    "    # output_layer_5_dense = layers.Dense(128, activation='relu')(output_layer_5_conv)\n",
    "    \n",
    "    # model = Model(inputs=input_layer, outputs=output_layer_5_dense)\n",
    "\n",
    "    \n",
    "    input_layer = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL))\n",
    "\n",
    "    output_layer_1_conv = layers.Conv3D(filters=8, kernel_size=(3,3,7), activation='relu',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL),padding='same')(input_layer)\n",
    "\n",
    "    output_layer_1_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_1_conv,training=True)\n",
    "\n",
    "    output_layer_2_conv = layers.Conv3D(filters=16, kernel_size=(3,3,5), activation='relu',padding='same')(output_layer_1_drop3d)\n",
    "\n",
    "    output_layer_2_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_2_conv,training=True)\n",
    "\n",
    "    output_layer_3_conv = layers.Conv3D(filters=32, kernel_size=(3,3,3), activation= 'relu')(output_layer_2_drop3d)\n",
    "\n",
    "    output_layer_3_reshaped = layers.Reshape((output_layer_3_conv.shape[1], output_layer_3_conv.shape[2], output_layer_3_conv.shape[3]*output_layer_3_conv.shape[4]))(output_layer_3_conv)\n",
    "\n",
    "    output_layer_4_conv = layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(output_layer_3_reshaped)\n",
    "\n",
    "    output_layer_5_SA_dot = layers.Attention()([output_layer_4_conv, output_layer_4_conv])\n",
    "\n",
    "    output_layer_5_softmax = layers.Softmax()(output_layer_5_SA_dot)\n",
    "\n",
    "    output_layer_5_SA_concat = layers.Attention(score_mode='concat')([output_layer_5_softmax, output_layer_4_conv])\n",
    "\n",
    "    output_layer_5_normalization = layers.LayerNormalization()(output_layer_5_SA_concat)\n",
    "\n",
    "    output_layer_6_flatten = layers.Flatten()(output_layer_5_normalization)\n",
    "\n",
    "    output_layer_6_drop = layers.Dropout(rate=0.4)(output_layer_6_flatten,training=True)\n",
    "\n",
    "    output_layer_6_dense = layers.Dense(256, activation='relu')(output_layer_6_drop)\n",
    "\n",
    "    output_layer_7_conv = layers.Dropout(0.4)(output_layer_6_dense,training=True)\n",
    "\n",
    "    output_layer_7_dense = layers.Dense(128, activation='relu')(output_layer_7_conv)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer_7_dense)\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model\n",
    "    \n",
    "    \n",
    "if(TEST_BLOCKS):\n",
    "    model = createModel()\n",
    "    print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_euclidian_dists(x, y):\n",
    "    \"\"\"\n",
    "    calc_euclidian_dists: Calculates the euclidian distance between two tensors\n",
    "    :param x: Tensor of shape (n, d)\n",
    "    :param y: Tensor of shape (m, d)\n",
    "    :return: Tensor of shape (n, m) with euclidian distances\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    m = y.shape[0]\n",
    "    x = tf.tile(tf.expand_dims(x, 1), [1, m, 1])\n",
    "    y = tf.tile(tf.expand_dims(y, 0), [n, 1, 1])\n",
    "    return tf.reduce_mean(tf.math.pow(x - y, 2), 2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prototypical(Model):\n",
    "    def __init__(self, model, w, h, d, c):\n",
    "        super(Prototypical, self).__init__()\n",
    "        self.w, self.h, self.d, self.c = w, h, d, c\n",
    "        self.encoder = model\n",
    "\n",
    "    def call(self, support, query, support_labels, query_labels, K, C, N,n_times,training=True):\n",
    "        # support : support images (25, 11, 11, 30, 1)\n",
    "        # query : query images (75, 11, 11, 30, 1)\n",
    "        \n",
    "        n_class = C                                                               #5\n",
    "        n_support = K                                                             #5\n",
    "        n_query = N\n",
    "        # print('supp',support.shape)                                                               #15 \n",
    "        # print('que',query.shape)      \n",
    "        # print('C K N')                                                         #15 \n",
    "        # print(C, K, N)\n",
    "        if type(n_times) != int:\n",
    "            n_times = 0\n",
    "        if training == True : \n",
    "            loss = 0\n",
    "        mc_predictions = []                                                     # list of predictions for multiple passes\n",
    "        y = np.zeros((int(C*N),C))\n",
    "        for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])\n",
    "            y[i][x] = 1\n",
    "            #  basically we are creating OMR sheet for each query image where each column represents the class and each row represents the query image, where the true class is 1 and rest are 0\n",
    "        for i in range(n_times) :      # n_times passing every query image for calculating variance\n",
    "            \n",
    "            cat = tf.concat([support,query], axis=0)       \n",
    "            # print('cat', cat.shape)                                       # [100, 11, 11, 30, 1]\n",
    "            z = self.encoder(cat)    \n",
    "            # print('z', z.shape)                                             # [100, 128]   # build a new computational graph from the provided inputs\n",
    "            # Divide embedding into support and query\n",
    "            z_prototypes = tf.reshape(z[:n_class * n_support],[n_class, n_support, z.shape[-1]])   #[5, 5, 128])\n",
    "            # print('z_p', z_prototypes.shape)   \n",
    "            # Prototypes are means of n_support examples\n",
    "            z_prototypes = tf.math.reduce_mean(z_prototypes, axis=1)              #[5, 128]\n",
    "            # print('z_p mean', z_prototypes.shape)   \n",
    "            z_query = z[n_class * n_support:]                                     #[75, 128]                         \n",
    "            # print('z_q', z_query.shape)   \n",
    "            # Calculate distances between query and prototypes\n",
    "            dists = calc_euclidian_dists(z_query, z_prototypes)                   #[75, 5]\n",
    "            # print('dist', dists.shape )   \n",
    "            # log softmax of calculated distances\n",
    "            log_p_y = tf.nn.log_softmax(-dists, axis=-1)                          #[75, 5]     this activation function heavily penalizes wrong class prediction as compared to its Softmax counterpart    \n",
    "            # print('log softmax', log_p_y.shape)   \n",
    "            loss1 = -tf.reduce_mean((tf.reduce_sum(tf.multiply(y, log_p_y), axis=-1)))   #loss for the current pass                     \n",
    "            #   print('loss1', loss1)                                                 # []\n",
    "            loss += loss1                                                         # adding loss for each pass                   \n",
    "            predictions = tf.nn.softmax(-dists, axis=-1)                         # [75, 5] prediction probability for the search-space classes per query image(for current pass)\n",
    "            # print('pred softmax', predictions.shape)   \n",
    "            mc_predictions.append(predictions)           \n",
    "            # Loop Over (n_times)                                  \n",
    "\n",
    "        mc_predictions = tf.convert_to_tensor(np.reshape(np.asarray(mc_predictions),(n_times,int(C*N),C)))  #(n_times,75,5)\n",
    "        # print('all pred', mc_predictions.shape)\n",
    "        std_predictions = tf.math.reduce_std(mc_predictions,axis=0)                                         # (75,5)\n",
    "        # print('all std pred', std_predictions.shape)\n",
    "        std = tf.reduce_sum(tf.reduce_sum(tf.multiply(std_predictions,y),axis=1))\n",
    "        # print('std', std.shape,std)\n",
    "        # print('std', std)        \n",
    "        loss += MC_LOSS_WEIGHT*std\n",
    "        \n",
    "        # calculating mean accuracy\n",
    "        mean_predictions = tf.reduce_mean(mc_predictions,axis=0)                # mean prediction probability for each class (75,5)\n",
    "        # print('MEAN', mean_predictions.shape)\n",
    "        mean_eq = tf.cast(tf.equal(                                             # accuracy for the current pass  c\n",
    "            tf.cast(tf.argmax(mean_predictions, axis=-1), tf.int32),            # check if the index of max probability is equal to the true class index\n",
    "            tf.cast(tf.argmax(y,axis=-1), tf.int32)), tf.float32)               # argmax returns the index of max probability\n",
    "        # print('MEAN eq', mean_eq.shape, mean_eq)\n",
    "        mean_accuracy = tf.reduce_mean(mean_eq)\n",
    "        # print('MEAN acc', mean_accuracy.shape, mean_accuracy)\n",
    "        mean_predictions = tf.reduce_mean(mc_predictions,axis=0)                # mean prediction probability for each class (5)\n",
    "        # print('MEAN preds', mean_predictions.shape, mean_predictions)\n",
    "        return loss, mean_accuracy, mean_predictions   \n",
    "      \n",
    "        if training == False :\n",
    "            loss = 0\n",
    "            mc_predictions = []                                                     # list of predictions for multiple passes  \n",
    "            for i in range(n_times) :                                               # n_times passing the query images for variance calculation\n",
    "                y = np.zeros((int(C*N),C))                                            # (150,10)\n",
    "            for i in range(int(C*N)) :\n",
    "                x = support_labels.index(query_labels[i])                           # creation of 1-hot for the true labels\n",
    "                y[i][x] = 1  \n",
    "            # merge support and query to forward through encoder\n",
    "            cat = tf.concat([support,query], axis=0)                              # [200,9,9,20,1]   \n",
    "            z = self.encoder(cat)                                                 # [200, 320]\n",
    "            # Divide embedding into support and query\n",
    "            z_prototypes = tf.reshape(z[:n_class * n_support],[n_class, n_support, z.shape[-1]])   #[10, 5, 320])\n",
    "            # Prototypes are means of n_support examples\n",
    "            z_prototypes = tf.math.reduce_mean(z_prototypes, axis=1)              #[10, 320]\n",
    "            z_query = z[n_class * n_support:]                                     #[150, 320]                         \n",
    "            # Calculate distances between query and prototypes\n",
    "            dists = calc_euclidian_dists(z_query, z_prototypes)                   #[150, 10]\n",
    "            # log softmax of calculated distances\n",
    "            log_p_y = tf.nn.log_softmax(-dists, axis=-1)                          #[150, 10]        \n",
    "            loss1 = -tf.reduce_mean((tf.reduce_sum(tf.multiply(y, log_p_y), axis=-1)))        \n",
    "            loss += loss1\n",
    "            predictions = tf.nn.softmax(-dists, axis=-1)                                 # prediction probabilities for the classes for current pass\n",
    "            mc_predictions.append(predictions)               \n",
    "          \n",
    "                                        \n",
    "        y = np.zeros((int(C*N),C))                                            # (150,10)\n",
    "        for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])                           # creation of 1-hot for the true labels\n",
    "            y[i][x] = 1  \n",
    "        mean_predictions = tf.reduce_mean(mc_predictions,axis=0)                # mean prediction probability for each class (150,10)\n",
    "        mean_eq = tf.cast(tf.equal(                                             # accuracy for the current pass\n",
    "            tf.cast(tf.argmax(mean_predictions, axis=-1), tf.int32), \n",
    "            tf.cast(tf.argmax(y,axis=-1), tf.int32)), tf.float32)\n",
    "        mean_accuracy = tf.reduce_mean(mean_eq)\n",
    "        mean_pred_index = tf.argmax(mean_predictions,axis=1)\n",
    "        # mean class-wise accuracies\n",
    "        mean_correct_class = [[] for i in range(tC)]\n",
    "        mean_correct_pred = [[] for i in range(tC)]\n",
    "        classwise_mean_acc = [[] for i in range(tC)]\n",
    "        for i in range(int(C*N)):\n",
    "          x = support_labels.index(query_labels[i])\n",
    "          mean_correct_class[x].append('4')\n",
    "          if(mean_pred_index[i] == x) :\n",
    "            mean_correct_pred[x].append('4')\n",
    "        for i in range(tC) :\n",
    "           z = len(mean_correct_pred[i])/len(mean_correct_class[i])\n",
    "           classwise_mean_acc[i].append(z)  \n",
    "        #std calculation\n",
    "        std = 0\n",
    "        for i in range(int(C*N)) :\n",
    "           x = support_labels.index(query_labels[i])\n",
    "           p_i = np.array([p[i,:] for p in mc_predictions])\n",
    "           std_i = tf.math.reduce_std(p_i,axis=0) \n",
    "           std_i_true = std_i[x]\n",
    "           std += std_i_true                                                    # adding std of each class\n",
    "        # print('std',std)\n",
    "        loss += MC_LOSS_WEIGHT*std \n",
    "        y = np.zeros((int(C*N),C))                                            # (150,10)\n",
    "        for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])                           # creation of 1-hot for the true labels\n",
    "            y[i][x] = 1                                                               \n",
    "        return loss, mc_predictions, mean_accuracy, classwise_mean_acc, y\n",
    "\n",
    "\n",
    "        def save(self, model_path):\n",
    "            self.encoder.save_weights(model_path)\n",
    "\n",
    "        def load(self, model_path):\n",
    "            self.encoder(tf.zeros([1, self.w, self.h, self.c]))\n",
    "            self.encoder.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainingEpisode(patches:list, labels:list, K:int, C:int, N:int ):\n",
    "    \"\"\"\n",
    "    createTrainingEpisode creates a training episode for the N-way K-shot learning task.\n",
    "    \n",
    "    :param patches: list of all patches classified into different classes.\n",
    "    :param labels: list of classes from which the traning episode is to be created.\n",
    "    :param K: number of patches per class in the support set.\n",
    "    :param C: number of classes in the training episode.\n",
    "    :param N: number of patches per class in the query set.\n",
    "    :return queryPatches, queryLabels, supportPatches, supportLabels: training episode\n",
    "    \n",
    "    Algorithm:\n",
    "    - Select N classes from the list of labels. They should be unique.\n",
    "    - For each class, select K+Q patches. They should be unique.\n",
    "        - First K patches are support patches.\n",
    "        - Last Q patches are query patches.\n",
    "        - Append the support patches to supportPatches.\n",
    "        - Append the query patches to queryPatches.\n",
    "        - Append the class label to queryLabels Q times.\n",
    "    - Shuffle the queryPatches and queryLabels in the same order.\n",
    "    - Convert the queryPatches and supportPatches to tensors.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    selectedLabels = random.sample(labels, C)\n",
    "    supportPatches = []\n",
    "    supportLabels = list(selectedLabels)\n",
    "    queryPatches = []\n",
    "    queryLabels = []\n",
    "    \n",
    "    for n in selectedLabels:\n",
    "        sran_indices = np.random.choice(len(patches[n-1]),K,replace=False)  # for class no X-1: select K samples \n",
    "        supportPatches.extend( patches[n-1][sran_indices,:,:,:,:])\n",
    "        qran_indices = np.random.choice(len(patches[n-1]),N,replace=False)  # N Samples for Query\n",
    "        queryPatches.extend(patches[n-1][qran_indices,:,:,:,:])\n",
    "        queryLabels.extend([n]*N)\n",
    "    \n",
    "    shuffled = list(zip(queryPatches, queryLabels))\n",
    "    random.shuffle(shuffled)\n",
    "    queryPatches, queryLabels = zip(*shuffled)\n",
    "    \n",
    "    queryPatches = tf.convert_to_tensor(np.reshape(np.asarray(queryPatches),(C*N,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    supportPatches = tf.convert_to_tensor(np.reshape(np.asarray(supportPatches),(C*K,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    \n",
    "    return queryPatches, queryLabels, supportPatches, supportLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(support, query, support_labels, query_labels, K, C, N):\n",
    "    # Forward & update gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N,N_TIMES,training=True)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    # A gradient simply measures the change in all weights with regard to the change in error. You can also think of a gradient as the slope of a function. The higher the gradient, the steeper the slope and the faster a model can learn. But if the slope is zero, the model stops learning\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Log loss and accuracy for step\n",
    "    train_loss(loss)\n",
    "    train_acc(mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeIt\n",
    "def trainingEpochs(patches, labels, n_epochs, n_episodes):\n",
    "    \"\"\"\n",
    "    trainingEpochs function trains the model for n_epochs and n_episodes.\n",
    "    \n",
    "    :param patches: image patches to be trained\n",
    "    :param labels: corresponding labels to be used\n",
    "    :param n_epochs: number of epochs\n",
    "    :param n_episodes: number of episodes\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    template = 'Epoch {}/{}, Episode {}/{}, Train Loss: {:.2f}, Train Accuracy: {:.2f}'\n",
    "    \n",
    "    l=0\n",
    "    a=0\n",
    "    # for epoch in tqdm(range(n_epochs), desc='Epochs'):\n",
    "    #     train_loss.reset_states()\n",
    "    #     train_acc.reset_states()\n",
    "    #     for episode in tqdm(range(n_episodes), desc=f'Episodes (Loss: {l:.2f}, Acc: {a:.2f})'):\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss.reset_states()\n",
    "        train_acc.reset_states()\n",
    "        for episode in range(n_episodes):\n",
    "            queryPatches, queryLabels, supportPatches, supportLabels = createTrainingEpisode(patches, labels, TRAIN_K, TRAIN_C, TRAIN_N)\n",
    "            train_step(supportPatches, queryPatches,supportLabels,  queryLabels, TRAIN_K, TRAIN_C, TRAIN_N)\n",
    "            # clear_output(wait=True)\n",
    "            l = train_loss.result()*100\n",
    "            a = train_acc.result()*100\n",
    "            if(VERBOSE):\n",
    "                print(template.format(epoch+1, n_epochs, episode+1, n_episodes, train_loss.result()*100, train_acc.result()*100))\n",
    "                trainingData.append([train_loss.result(),  train_acc.result()*100])\n",
    "                plotData(trainingData)\n",
    "        if(epoch and epoch % 5 == 0):\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix_train)    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTunningEpisodes(patches:list, labels:list, K:int, C:int, N:int):\n",
    "    \"\"\"\n",
    "    createTuningEpisodes creates a tuning episode for the N-way K-shot learning task.\n",
    "    \n",
    "    :param patches: list of all patches classified into different classes.\n",
    "    :param labels: list of classes from which the tuning episode is to be created.\n",
    "    :param K: number of patches per class in the support set.\n",
    "    :param C: number of classes in the tuning episode.\n",
    "    :param N: number of patches per class in the query set.\n",
    "    :return queryPatches, queryLabels, supportPatches, supportLabels: tuning episode\n",
    "    \n",
    "    Algorithm:\n",
    "    - Select C classes from the list of labels. They should be unique.\n",
    "    - For each selected class.\n",
    "        - Shuffle the patches of that class.\n",
    "        - First K patches are support patches.\n",
    "        - Next N patches are query patches. \n",
    "        - Append the support patches to supportPatches.\n",
    "        - Append the query patches to queryPatches.\n",
    "        - Append the class label to queryLabels N times.\n",
    "    - Shuffle the queryPatches and queryLabels in the same order.\n",
    "    - Convert the queryPatches and supportPatches to tensors.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    selected_classes = np.random.choice(labels,C,replace=False)\n",
    "    supportLabels  = list(selected_classes)\n",
    "    queryLabels = []\n",
    "    supportPatches = []\n",
    "    queryPatches = []\n",
    "    \n",
    "    for x in selected_classes :\n",
    "        y = labels.index(x)\n",
    "        np.random.shuffle(patches[y])    \n",
    "        supportPatches.extend(patches[y][:K,:,:,:,:])  # 1st K patches for support set\n",
    "        queryPatches.extend(patches[y][K:K+N,:,:,:,:])   # next N patches for query set\n",
    "        queryLabels.extend([x]*N)            \n",
    "          # next 5 labels for query set\n",
    "    \n",
    "    shuffled = list(zip(queryPatches, queryLabels))\n",
    "    random.shuffle(shuffled)\n",
    "    queryPatches, queryLabels = zip(*shuffled)\n",
    "    \n",
    "    queryPatches = tf.convert_to_tensor(np.reshape(np.asarray(queryPatches),(C*N,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    supportPatches = tf.convert_to_tensor(np.reshape(np.asarray(supportPatches),(C*K,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    \n",
    "    return queryPatches, queryLabels, supportPatches, supportLabels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_step(support, query, support_labels, query_labels, K, C, N):\n",
    "    # Forward & update gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N,N_TIMES,training=True)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Log loss and accuracy for step\n",
    "    tune_loss(loss)\n",
    "    tune_acc(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeIt\n",
    "def tunningEpochs(patches, labels, n_epochs, n_episodes):\n",
    "    \"\"\"\n",
    "    trainingEpochs function trains the model for n_epochs and n_episodes.\n",
    "    \n",
    "    :param patches: image patches to be trained\n",
    "    :param labels: corresponding labels to be used\n",
    "    :param n_epochs: number of epochs\n",
    "    :param n_episodes: number of episodes\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    template = 'Epoch {}/{}, Tune Loss: {:.2f}, Tune Accuracy: {:.2f}'\n",
    "    l=0\n",
    "    a=0\n",
    "    for epoch in tqdm(range(n_epochs), desc=f'Epochs (Loss: {l:.2f}, Acc: {a:.2f})'): \n",
    "        tune_loss.reset_states()  \n",
    "        tune_acc.reset_states()    \n",
    "        for epi in tqdm(range(n_episodes), desc='Episodes'):  \n",
    "            queryPatches, queryLabels, supportPatches, supportLabels = createTunningEpisodes(patches, labels, TUNE_K, TUNE_C, TUNE_N)    \n",
    "            tune_step(supportPatches, queryPatches,supportLabels, queryLabels, TUNE_K, TUNE_C, TUNE_N)   \n",
    "            # clear_output(wait=True)   \n",
    "        a = tune_acc.result()*100\n",
    "        l = tune_loss.result()\n",
    "        if(VERBOSE):\n",
    "            print(template.format(epoch+1, n_epochs,tune_loss.result(),tune_acc.result()*100))\n",
    "            tunningData.append([tune_loss.result(),  tune_acc.result()*100])\n",
    "            plotData(tunningData)\n",
    "        if (epoch+1)%5 == 0 :\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix_tune) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTestingEpisode(patches, labels, K, C, i, f):\n",
    "    selected_classes = labels[i:f]   # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    support_labels = list(selected_classes)\n",
    "    query_labels = []\n",
    "    support_patches = []\n",
    "    query_patches = []\n",
    "    for x in selected_classes :\n",
    "        y = labels.index(x)\n",
    "        support_imgs = patches[y][:K,:,:,:,:]\n",
    "        query_imgs = patches[y][K:,:,:,:,:]\n",
    "        support_patches.extend(support_imgs)\n",
    "        query_patches.extend(query_imgs)\n",
    "        for i in range(query_imgs.shape[0]) :\n",
    "            query_labels.append(x)\n",
    "    print('query_labels', query_labels)\n",
    "    temp1 = list(zip(query_patches, query_labels)) \n",
    "    random.shuffle(temp1) \n",
    "    query_patches, query_labels = zip(*temp1)\n",
    "    x = len(query_labels)\n",
    "    query_patches = tf.convert_to_tensor(np.reshape(np.asarray(query_patches),(x,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    support_patches = tf.convert_to_tensor(np.reshape(np.asarray(support_patches),(C*K,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    return query_patches, support_patches, query_labels, support_labels,x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(support, query, support_labels, query_labels, K, C, y):\n",
    "    loss, mc_predictions, mean_accuracy, classwise_mean_acc, y = ProtoModel(support, query, support_labels, query_labels, K, C, y,N_TIMES,training=False)\n",
    "    return loss, mc_predictions, mean_accuracy, classwise_mean_acc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeIt\n",
    "def testingEpochs(patches, labels, n_epochs):\n",
    "    \"\"\"\n",
    "    testingEpochs function tests the model for n_epochs.\n",
    "    \n",
    "    :param patches: image patches to be trained\n",
    "    :param labels: corresponding labels to be used\n",
    "    :param n_epochs: number of epochs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    oa1=0\n",
    "    oa2=0\n",
    "    for epoch in tqdm(range(n_epochs), desc=f'Epochs (OA1: {oa1:.2f}, OA2: {oa2:.2f})'):\n",
    "        test_loss.reset_states()  \n",
    "        test_acc.reset_states()     \n",
    "        \n",
    "        tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1 = createTestingEpisode(patches,labels,TEST_K,TEST_C,0,3)    \n",
    "        loss1, mc_predictions1, mean_accuracy1, classwise_mean_acc1, y1 = test_step(tsupport_patches1, tquery_patches1,support_labels1, query_labels1, TEST_K, TEST_C, y=x1/3) \n",
    "        tquery_patches2, tsupport_patches2, query_labels2, support_labels2, x2 = createTestingEpisode(patches,labels,TEST_K,TEST_C,3,6)    \n",
    "        loss2, mc_predictions2, mean_accuracy2, classwise_mean_acc2, y2 = test_step(tsupport_patches2, tquery_patches2,support_labels2, query_labels2, 5, 3, x2/3)\n",
    "        \n",
    "        oa1 = mean_accuracy1\n",
    "        oa2 = mean_accuracy2\n",
    "        if(VERBOSE):\n",
    "            print(\"=========================================\")\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "            print(\"-----------------------------------------\")\n",
    "            print(f\"Overall Accuracy 1 (OA1): {mean_accuracy1}\")\n",
    "            # Class Wise Accuracy\n",
    "            for i in range(TEST_C):\n",
    "                print(f\"Class {i+1} Accuracy: {classwise_mean_acc1[i]}\")\n",
    "            print(f\"Loss: {loss1.numpy():.3f}\")\n",
    "            print(\"-----------------------------------------\")\n",
    "            print(f\"Overall Accuracy 2 (OA2): {mean_accuracy2}\")\n",
    "            # Class Wise Accuracy\n",
    "            for i in range(TEST_C):\n",
    "                print(f\"Class {i+1+TEST_C} Accuracy: {classwise_mean_acc2[i]}\")\n",
    "            print(f\"Loss: {loss2.numpy():.3f}\")\n",
    "            print(\"=========================================\")\n",
    "            \n",
    "            testingData.append([mean_accuracy1*100, mean_accuracy2*100, loss1.numpy(), loss2.numpy()])\n",
    "            plotData(testingData, testing=True)\n",
    "        # else:\n",
    "            # clear_output(wait=True)\n",
    "            # print(\"-----------------------------------------\\n\" + f\"Epoch {epoch+1}/{n_epochs}\\n\" + \"-----------------------------------------\\n\"\n",
    "            # + f\"Overall Accuracy 1 (OA1): {mean_accuracy1}\\n\" + f\"Overall Accuracy 2 (OA2): {mean_accuracy2}\")\n",
    "\n",
    "        \n",
    "    return mc_predictions1, mc_predictions2, y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian_pines\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "data = Data(DATASET, PCA_COMPONENTS, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, patches = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES, TRAINING_CLASSES, TRAINING_LABELS, TUNNING_LABELS, TESTING_CLASSES, TESTING_LABELS, TRAINING_PATCHES,TUNNING_PATCHES, TESTING_PATCHES = data.load_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 11, 11, 30,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 11, 11, 30,   512         ['input_1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " spatial_dropout3d (SpatialDrop  (None, 11, 11, 30,   0          ['conv3d[0][0]']                 \n",
      " out3D)                         8)                                                                \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 11, 11, 30,   5776        ['spatial_dropout3d[0][0]']      \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " spatial_dropout3d_1 (SpatialDr  (None, 11, 11, 30,   0          ['conv3d_1[0][0]']               \n",
      " opout3D)                       16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 9, 9, 28, 32  13856       ['spatial_dropout3d_1[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 9, 9, 896)    0           ['conv3d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 7, 7, 64)     516160      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 7, 7, 64)     0           ['conv2d[0][0]',                 \n",
      "                                                                  'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 7, 7, 64)     0           ['attention[0][0]']              \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 7, 7, 64)     1           ['softmax[0][0]',                \n",
      "                                                                  'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 7, 7, 64)    128         ['attention_1[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3136)         0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 3136)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          803072      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,372,401\n",
      "Trainable params: 1,372,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create instance of the model\n",
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the Prototypical Network\n",
    "ProtoModel = Prototypical(model, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH, IMAGE_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the Checkpoint\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, ProtoModel = ProtoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_labels [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "296\n"
     ]
    }
   ],
   "source": [
    "tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1 = createTestingEpisode(TESTING_PATCHES, TESTING_LABELS, TEST_K,TEST_C,0,3) \n",
    "\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supp (25, 11, 11, 30, 1)\n",
      "que (75, 11, 11, 30, 1)\n",
      "C K N\n",
      "5 5 15\n",
      "cat (100, 11, 11, 30, 1)\n",
      "z (100, 128)\n",
      "z_p (5, 5, 128)\n",
      "z_p mean (5, 128)\n",
      "z_q (75, 128)\n",
      "dist (75, 5)\n",
      "log softmax (75, 5)\n",
      "pred softmax (75, 5)\n",
      "all pred (1, 75, 5)\n",
      "all std pred (75, 5)\n",
      "std () tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "MEAN (75, 5)\n",
      "MEAN eq (75,) tf.Tensor(\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0.], shape=(75,), dtype=float32)\n",
      "MEAN acc () tf.Tensor(0.22666667, shape=(), dtype=float32)\n",
      "MEAN preds (75, 5) tf.Tensor(\n",
      "[[0.17865865 0.22912592 0.17941977 0.20333011 0.20946552]\n",
      " [0.20230205 0.1968834  0.18601921 0.2015391  0.21325625]\n",
      " [0.19877985 0.19241264 0.19219927 0.2146082  0.20200007]\n",
      " [0.16858739 0.2201357  0.20168291 0.2085933  0.20100075]\n",
      " [0.1856264  0.22867882 0.1959179  0.2065782  0.18319872]\n",
      " [0.22029643 0.18088785 0.17235488 0.21408102 0.2123798 ]\n",
      " [0.20111112 0.21119407 0.18992311 0.19360246 0.20416929]\n",
      " [0.18692689 0.19277146 0.18693222 0.20646685 0.22690259]\n",
      " [0.21416904 0.19309565 0.17806682 0.20552358 0.20914488]\n",
      " [0.17861453 0.22339    0.1884619  0.21105406 0.19847952]\n",
      " [0.20435809 0.19127466 0.22902058 0.17353766 0.20180899]\n",
      " [0.16561344 0.24365325 0.1884355  0.2022013  0.20009647]\n",
      " [0.17216414 0.19605611 0.22181405 0.21023162 0.19973415]\n",
      " [0.19597481 0.2007253  0.22068432 0.19276787 0.18984771]\n",
      " [0.19661617 0.20582084 0.18171875 0.21348281 0.20236148]\n",
      " [0.19149013 0.19629808 0.2118525  0.21942888 0.18093039]\n",
      " [0.20764102 0.1949523  0.18788548 0.22115064 0.18837054]\n",
      " [0.20327054 0.18709123 0.19242194 0.21991059 0.19730571]\n",
      " [0.17070197 0.23720327 0.19743827 0.2066986  0.18795793]\n",
      " [0.1948798  0.20705032 0.19011287 0.22000079 0.1879562 ]\n",
      " [0.2022214  0.18655823 0.16840534 0.22578086 0.21703424]\n",
      " [0.22126831 0.21017398 0.20226127 0.18213618 0.18416025]\n",
      " [0.18903708 0.21349637 0.19429545 0.202747   0.20042406]\n",
      " [0.17574093 0.23353763 0.20183693 0.20312282 0.18576166]\n",
      " [0.1941528  0.20685789 0.18944514 0.21634686 0.19319727]\n",
      " [0.15596558 0.21359536 0.22469682 0.20933695 0.19640523]\n",
      " [0.1919436  0.2061001  0.19406691 0.20511693 0.20277244]\n",
      " [0.19732055 0.19655539 0.22610009 0.1952988  0.18472515]\n",
      " [0.20736237 0.1938183  0.20579486 0.19600913 0.1970154 ]\n",
      " [0.1885436  0.20418468 0.18290587 0.20538929 0.21897656]\n",
      " [0.22298203 0.16609265 0.18960719 0.21489196 0.20642616]\n",
      " [0.20149623 0.1737845  0.19989164 0.21676254 0.20806508]\n",
      " [0.1972019  0.20144038 0.19683672 0.20273815 0.2017828 ]\n",
      " [0.1998552  0.19192034 0.19065288 0.21022049 0.20735106]\n",
      " [0.23311391 0.2054898  0.17103605 0.19690295 0.19345732]\n",
      " [0.19202581 0.21949458 0.19342674 0.20191982 0.19313303]\n",
      " [0.18325579 0.18825372 0.19876519 0.23995489 0.1897704 ]\n",
      " [0.19407558 0.20198168 0.19134845 0.20432791 0.20826645]\n",
      " [0.19859216 0.21230365 0.19446768 0.19629535 0.19834119]\n",
      " [0.17826957 0.20093814 0.21961312 0.19757564 0.2036035 ]\n",
      " [0.17739919 0.22278081 0.21342021 0.18939638 0.1970034 ]\n",
      " [0.20450741 0.17744902 0.1952629  0.20815884 0.21462184]\n",
      " [0.21177137 0.19965439 0.17607361 0.19474697 0.21775362]\n",
      " [0.1763791  0.21177602 0.20598522 0.20195806 0.20390156]\n",
      " [0.21937363 0.21206932 0.17087285 0.2027484  0.1949358 ]\n",
      " [0.18517424 0.20961723 0.20735376 0.1960867  0.20176804]\n",
      " [0.19538411 0.21305326 0.16787155 0.21600981 0.20768124]\n",
      " [0.18200026 0.21384154 0.21832082 0.19108458 0.19475274]\n",
      " [0.19158357 0.19241185 0.18882762 0.23679858 0.19037834]\n",
      " [0.20981002 0.18895046 0.18962783 0.21069063 0.20092103]\n",
      " [0.20519938 0.20283552 0.18775748 0.20348679 0.20072094]\n",
      " [0.20465106 0.18693198 0.18843327 0.2115306  0.20845309]\n",
      " [0.21807507 0.18496287 0.19834901 0.18511936 0.21349372]\n",
      " [0.20002104 0.2021262  0.18524571 0.2063139  0.20629314]\n",
      " [0.1957546  0.18027423 0.22785652 0.20730637 0.18880822]\n",
      " [0.20648316 0.20180464 0.19809733 0.20722106 0.18639381]\n",
      " [0.23706304 0.2166976  0.17143545 0.17296705 0.20183688]\n",
      " [0.19423793 0.19392498 0.21049528 0.20818251 0.19315931]\n",
      " [0.19409293 0.21536948 0.21613537 0.18141422 0.19298795]\n",
      " [0.216533   0.18190731 0.18852085 0.20966491 0.20337395]\n",
      " [0.18761474 0.1823694  0.20611793 0.21441191 0.20948601]\n",
      " [0.1855844  0.20621191 0.18205169 0.2133553  0.21279676]\n",
      " [0.17648739 0.19366942 0.21288751 0.20368467 0.21327105]\n",
      " [0.2084583  0.20425154 0.18133314 0.19799805 0.20795901]\n",
      " [0.18059914 0.2372214  0.2083883  0.18365605 0.19013518]\n",
      " [0.18332303 0.20402499 0.18624642 0.21887049 0.20753506]\n",
      " [0.18645866 0.190396   0.19428238 0.20066158 0.22820143]\n",
      " [0.21941313 0.19104016 0.19724631 0.20854844 0.18375193]\n",
      " [0.20146093 0.19574909 0.19501449 0.19230545 0.21546997]\n",
      " [0.19612372 0.20175469 0.19335292 0.2252762  0.18349253]\n",
      " [0.18957174 0.20913707 0.19420975 0.19960362 0.20747788]\n",
      " [0.20331694 0.19450508 0.22591276 0.19677244 0.17949276]\n",
      " [0.17446609 0.22515756 0.19136615 0.22079092 0.18821926]\n",
      " [0.18425858 0.20387438 0.19485499 0.20728867 0.20972338]\n",
      " [0.2006014  0.19710912 0.17855057 0.2412784  0.18246058]], shape=(75, 5), dtype=float32)\n",
      "Function 'trainingEpochs' executed in 0.2984s\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainingEpochs(patches, TRAINING_LABELS, TRAINING_EPOCH, TRAINING_EPISODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/41, Tune Loss: 0.11, Tune Accuracy: 100.00\n",
      "Function 'tunningEpochs' executed in 457.1728s\n"
     ]
    }
   ],
   "source": [
    "tunningEpochs(TUNNING_PATCHES, TESTING_LABELS, TUNNING_EPOCH, TUNNING_EPISODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Epoch 1000/1000\n",
      "-----------------------------------------\n",
      "Overall Accuracy 1 (OA1): 0.9459459185600281\n",
      "Overall Accuracy 2 (OA2): 0.9405940771102905\n",
      "Function 'testingEpochs' executed in 1439.1789s\n"
     ]
    }
   ],
   "source": [
    "mc_predictions1, mc_predictions2, y1, y2 =  testingEpochs(TESTING_PATCHES, TESTING_LABELS, TESTING_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lib.Stats import Stats\n",
    "stats = Stats(mc_predictions1, mc_predictions2, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.21102068290294 Kappa accuracy (%)\n",
      "\n",
      "\n",
      "94.32387312186978 Overall accuracy (%)\n",
      "\n",
      "\n",
      "97.35057471264366 Average accuracy (%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      0.93      0.96       232\n",
      "           2       0.59      1.00      0.74        23\n",
      "           3       0.45      1.00      0.62        15\n",
      "           4       1.00      0.91      0.95       200\n",
      "           5       1.00      1.00      1.00        88\n",
      "\n",
      "    accuracy                           0.94       599\n",
      "   macro avg       0.84      0.97      0.88       599\n",
      "weighted avg       0.97      0.94      0.95       599\n",
      "\n",
      "\n",
      "\n",
      "[[ 41   0   0   0   0   0]\n",
      " [  0 216  16   0   0   0]\n",
      " [  0   0  23   0   0   0]\n",
      " [  0   0   0  15   0   0]\n",
      " [  0   0   0  18 182   0]\n",
      " [  0   0   0   0   0  88]]\n"
     ]
    }
   ],
   "source": [
    "stats.printReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(SAVE_REPORT):\n",
    "    stats.saveReport(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(SAVE_MODEL):\n",
    "    ProtoModel.save(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
