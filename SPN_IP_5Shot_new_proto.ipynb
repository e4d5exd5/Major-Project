{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aditya Sawant's Version of SPN_IP_5Shot.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Used\n",
    "\n",
    "- tensorflow\n",
    "- sklearn\n",
    "- numpy\n",
    "- matplotlib\n",
    "- pandas\n",
    "- scipy\n",
    "- tensorflow_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn numpy matplotlib scipy tensorflow_probability pandas plotly \n",
    "# tensorflow[and-cuda]==2.10 [cuDNN 8.1.1 CUDA 11.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def timeIt(func):\n",
    "    \"\"\"\n",
    "    timeIt is a decorator function to time the execution of a function.\n",
    "    \n",
    "    :param func: function to be timed\n",
    "    :return: wrapper function\n",
    "    \"\"\"\n",
    "    def wrap_func(*args, **kwargs):\n",
    "        t1 = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        t2 = time()\n",
    "        print(f'Function {func.__name__!r} executed in {(t2-t1):.4f}s')\n",
    "        return result\n",
    "    return wrap_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingData = pd.DataFrame(columns=['Loss', 'Accuracy'])\n",
    "def plotData(data, testing=False):\n",
    "    \n",
    "    if testing:\n",
    "        accuracy1_values = [item[0] for item in data]\n",
    "        accuracy2_values = [item[1] for item in data]\n",
    "        loss1_values = [item[2] for item in data]\n",
    "        loss2_values = [item[3] for item in data]\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss1_values, color='red', label='Loss')\n",
    "        plt.plot(accuracy1_values, color='blue', label='Accuracy')\n",
    "        plt.xlabel('Epoch/Episode')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Loss and Overall Accuracy 1')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss2_values, color='red', label='Loss')\n",
    "        plt.plot(accuracy2_values, color='blue', label='Accuracy')\n",
    "        plt.xlabel('Epoch/Episode')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Loss and Overall Accuracy 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        loss_values = [item[0] for item in data]\n",
    "        accuracy_values = [item[1] for item in data]\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_values, color='red', label='Loss')\n",
    "        plt.plot(accuracy_values, color='blue', label='Accuracy')\n",
    "        plt.xlabel('Epoch/Episode')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Loss and Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.10.0-rc3-6-g359c3cdfc5f 2.10.0\n",
      "True\n",
      "Number of GPUs Available:  1\n",
      "Number of Devices Available:  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import statistics\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "  \n",
    "from operator import truediv\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version.GIT_VERSION, tf.version.VERSION)\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(\"Number of GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Number of Devices Available: \", len(tf.config.experimental.list_physical_devices()))\n",
    "# import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.compat.v1.distributions import Bernoulli\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "from datetime import date, datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from lib.Data import Data\n",
    "from lib.Stats import Stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test each code block individually\n",
    "TEST_BLOCKS: bool = False\n",
    "CWD: str = os.getcwd()\n",
    "VERBOSE: bool = False\n",
    "\n",
    "SAVE_REPORT: bool = True\n",
    "SAVE_MODEL: bool = False\n",
    "# Data Loading and Preprocessing\n",
    "\n",
    "\n",
    "# Dataset Used : Indian Pines\n",
    "DATASET: str = 'IP' # IP (indian_pines) PU (pavia_university) SA (salinas) HU (houston) \n",
    "PATH_TO_DATASET: str = CWD + '\\\\Datasets\\\\'\n",
    "\n",
    "# PCA\n",
    "PCA_COMPONENTS: int = 30 # Number of components to keep after PCA reduction\n",
    "\n",
    "# Window size for forming image cubes\n",
    "WINDOW_SIZE: int = 11\n",
    "\n",
    "# Image dimensions after forming image cubes\n",
    "IMAGE_WIDTH: int\n",
    "IMAGE_HEIGHT: int\n",
    "IMAGE_DEPTH: int\n",
    "IMAGE_CHANNEL: int \n",
    "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH, IMAGE_CHANNEL = 11, 11, 30, 1\n",
    "\n",
    "# Model Parameters\n",
    "\n",
    "N_TIMES = 1 # Number of times to run the model. Internally, the model is runs each episode N_TIMES times\n",
    "\n",
    "# Learning Rate\n",
    "LEARNING_RATE: float = 0.00001\n",
    "\n",
    "# Temprature Scaling\n",
    "TAU: float = 1.8\n",
    "\n",
    "# C (No. of Classes) K (No. of Samples per Class) N (No. of Patches per Class)\n",
    "TRAIN_C: int = 5 # Number of classes to be used for training\n",
    "TRAIN_K: int = 5 # Number of patches per class to be used for support during training\n",
    "TRAIN_N: int = 15 # Number of patches per class to be used for query during training\n",
    "\n",
    "TUNE_C: int = 3 # Number of classes to be used for testing\n",
    "TUNE_K: int = 1 # Number of patches per class to be used for support during testing\n",
    "TUNE_N: int = 4 # Number of patches per class to be used for query during testing\n",
    "\n",
    "TEST_C: int = 3 # Number of classes to be used for testing\n",
    "TEST_K: int = 5 # Number of patches per class to be used for support during testing\n",
    "TEST_N: int = 5 # Number of patches per class to be used for query during testing\n",
    "\n",
    "# ===================================\n",
    "# DO NOT REMOVE THIS.\n",
    "tC = 3   # classes in a test episode \n",
    "# Don't know this yet, probably used in the model to calculate loss\n",
    "MC_LOSS_WEIGHT: int = 5 \n",
    "# DIRECTLY USED IN PROTOTYPICAL NETWORK CLASS IN TESTING CASE\n",
    "# ===================================\n",
    "\n",
    "# Training Epochs\n",
    "TRAINING_EPOCH: int = 3  # 50\n",
    "\n",
    "# Training Episode\n",
    "TRAINING_EPISODE: int = 5 # 100\n",
    "\n",
    "# Tunning Epochs\n",
    "TUNNING_EPOCH: int = 3\n",
    "\n",
    "# Tunning Episode\n",
    "TUNNING_EPISODE: int = 5\n",
    "\n",
    "# Testing Epochs\n",
    "TESTING_EPOCH: int = 10\n",
    "\n",
    "# Metrics to be used for evaluation\n",
    "train_loss = tf.metrics.Mean(name='train_loss')\n",
    "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
    "tune_loss = tf.metrics.Mean(name='tune_loss')\n",
    "tune_acc = tf.metrics.Mean(name='tune_accuracy')\n",
    "test_loss = tf.metrics.Mean(name='test_loss')\n",
    "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
    "\n",
    "trainingData = []\n",
    "tunningData = []\n",
    "testingData = []\n",
    "\n",
    "run_folder =  f'{date.today()}' + '-' + f'{datetime.now().hour}_5_1' + '\\\\' \n",
    "\n",
    "checkpoint_dir = CWD + '\\\\saves\\\\' + run_folder + DATASET + '\\\\' + f'{TRAIN_K}_shot_way' + '\\\\Train'\n",
    "checkpoint_prefix_train = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint_dir1 = CWD + '\\\\saves\\\\' + run_folder + DATASET + '\\\\' + f'{TRAIN_K}_shot_way' + '\\\\Train\\\\Tune'\n",
    "checkpoint_prefix_tune = os.path.join(checkpoint_dir1, \"ckpt\")\n",
    "\n",
    "report_path = CWD + f'\\\\Reports\\\\Report_{date.today()}_{str(datetime.now()).split(\".\")[0].split()[1].replace(\":\", \"-\")}.txt'\n",
    "model_save_path = CWD + '\\\\saves\\\\' + run_folder + DATASET + '\\\\' + f'{TRAIN_K}_shot_way' + '\\\\Train\\\\encoder.h5'\n",
    "\n",
    "\n",
    "checkpoint = None  # To be used for loading checkpoints. Declared in the Main Block\n",
    "ProtoModel = None  # Prototypical Network Object. Declared in the Main Block\n",
    "model = None  # Model Object. Declared in the Main Block\n",
    "optimizer = None  # Optimizer Object. Declared in the Main Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    \"\"\"\n",
    "    createModel() function creates the model architecture for the 3D CNN model.\n",
    "    :return: model \n",
    "    \n",
    "    The model architecture is as follows:\n",
    "    1. Input layer\n",
    "    2. 3D Convolution layer with 8 filters, kernel size (3,3,7), activation function 'relu' and padding 'same'\n",
    "    3. Spatial Dropout layer with dropout rate 0.3\n",
    "    4. 3D Convolution layer with 16 filters, kernel size (3,3,5), activation function 'relu' and padding 'same'\n",
    "    5. Spatial Dropout layer with dropout rate 0.3\n",
    "    6. 3D Convolution layer with 32 filters, kernel size (3,3,3), activation function 'relu'\n",
    "    7. Reshape layer to reshape the output of 3D Convolution layer to 2D\n",
    "    8. 2D Convolution layer with 64 filters, kernel size (3,3), activation function 'relu'\n",
    "    9. Flatten layer to flatten the output of 2D Convolution layer\n",
    "    10. Dropout layer with dropout rate 0.4\n",
    "    11. Dense layer with 256 neurons and activation function 'relu'\n",
    "    12. Dropout layer with dropout rate 0.4\n",
    "    13. Dense layer with 128 neurons and activation function 'relu'\n",
    "    14. Output layer with 128 neurons and activation function 'relu'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # input_layer = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL))\n",
    "    \n",
    "    # output_layer_1_conv = layers.Conv3D(filters=8, kernel_size=(3,3,7), activation='relu',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL),padding='same')(input_layer)\n",
    "    \n",
    "    # output_layer_1_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_1_conv,training=True)\n",
    "    \n",
    "    # output_layer_2_conv = layers.Conv3D(filters=16, kernel_size=(3,3,5), activation='relu',padding='same')(output_layer_1_drop3d)\n",
    "    \n",
    "    # output_layer_2_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_2_conv,training=True)\n",
    "    \n",
    "    # output_layer_3_conv = layers.Conv3D(filters=32, kernel_size=(3,3,3), activation= 'relu')(output_layer_2_drop3d)\n",
    "    \n",
    "    # output_layer_3_reshaped = layers.Reshape((output_layer_3_conv.shape[1], output_layer_3_conv.shape[2], output_layer_3_conv.shape[3]*output_layer_3_conv.shape[4]))(output_layer_3_conv)\n",
    "    \n",
    "    # output_layer_4_conv = layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(output_layer_3_reshaped)\n",
    "    \n",
    "    # output_layer_4_flatten = layers.Flatten()(output_layer_4_conv)\n",
    "    \n",
    "    # output_layer_4_drop = layers.Dropout(rate=0.4)(output_layer_4_flatten,training=True)\n",
    "    \n",
    "    # output_layer_4_dense = layers.Dense(256, activation='relu')(output_layer_4_drop)\n",
    "    \n",
    "    # output_layer_5_conv = layers.Dropout(0.4)(output_layer_4_dense,training=True)\n",
    "    \n",
    "    # output_layer_5_dense = layers.Dense(128, activation='relu')(output_layer_5_conv)\n",
    "    \n",
    "    # model = Model(inputs=input_layer, outputs=output_layer_5_dense)\n",
    "\n",
    "    \n",
    "    input_layer = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL))\n",
    "\n",
    "    output_layer_1_conv = layers.Conv3D(filters=8, kernel_size=(3,3,7), activation='relu',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, IMAGE_CHANNEL),padding='same')(input_layer)\n",
    "\n",
    "    output_layer_1_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_1_conv,training=True)\n",
    "\n",
    "    output_layer_2_conv = layers.Conv3D(filters=16, kernel_size=(3,3,5), activation='relu',padding='same')(output_layer_1_drop3d)\n",
    "\n",
    "    output_layer_2_drop3d = layers.SpatialDropout3D(rate=0.3, data_format='channels_last')(output_layer_2_conv,training=True)\n",
    "\n",
    "    output_layer_3_conv = layers.Conv3D(filters=32, kernel_size=(3,3,3), activation= 'relu')(output_layer_2_drop3d)\n",
    "\n",
    "    output_layer_3_reshaped = layers.Reshape((output_layer_3_conv.shape[1], output_layer_3_conv.shape[2], output_layer_3_conv.shape[3]*output_layer_3_conv.shape[4]))(output_layer_3_conv)\n",
    "\n",
    "    output_layer_4_conv = layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(output_layer_3_reshaped)\n",
    "\n",
    "    output_layer_5_SA_dot = layers.Attention()([output_layer_4_conv, output_layer_4_conv])\n",
    "\n",
    "    output_layer_5_softmax = layers.Softmax()(output_layer_5_SA_dot)\n",
    "\n",
    "    output_layer_5_SA_concat = layers.Attention(score_mode='concat')([output_layer_5_softmax, output_layer_4_conv])\n",
    "\n",
    "    output_layer_5_normalization = layers.LayerNormalization()(output_layer_5_SA_concat)\n",
    "\n",
    "    output_layer_6_flatten = layers.Flatten()(output_layer_5_normalization)\n",
    "\n",
    "    output_layer_6_drop = layers.Dropout(rate=0.4)(output_layer_6_flatten,training=True)\n",
    "\n",
    "    output_layer_6_dense = layers.Dense(256, activation='relu')(output_layer_6_drop)\n",
    "\n",
    "    output_layer_7_conv = layers.Dropout(0.4)(output_layer_6_dense,training=True)\n",
    "\n",
    "    output_layer_7_dense = layers.Dense(128, activation='relu')(output_layer_7_conv)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer_7_dense)\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model\n",
    "    \n",
    "    \n",
    "if(TEST_BLOCKS):\n",
    "    model = createModel()\n",
    "    print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_euclidian_dists(x, y):\n",
    "    \"\"\"\n",
    "    calc_euclidian_dists: Calculates the euclidian distance between two tensors\n",
    "    :param x: Tensor of shape (n, d)\n",
    "    :param y: Tensor of shape (m, d)\n",
    "    :return: Tensor of shape (n, m) with euclidian distances\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    m = y.shape[0]\n",
    "    x = tf.tile(tf.expand_dims(x, 1), [1, m, 1])\n",
    "    y = tf.tile(tf.expand_dims(y, 0), [n, 1, 1])\n",
    "    return tf.reduce_mean(tf.math.pow(x - y, 2), 2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prototypical(Model):\n",
    "    def __init__(self, model, w, h, d, c):\n",
    "        '''\n",
    "        model: encoder model\n",
    "        w: width of input image\n",
    "        h: height of input image\n",
    "        d: depth of input image\n",
    "        c: number of channels of input image\n",
    "        '''\n",
    "        super(Prototypical, self).__init__()\n",
    "        self.w, self.h, self.d, self.c = w, h, d, c\n",
    "        self.encoder = model\n",
    "\n",
    "    def call(self, support, query, support_labels, query_labels, K, C, N,n_times,training=True):\n",
    "        '''\n",
    "        support: support images (25, 11, 11, 30, 1)\n",
    "        query: query images (75, 11, 11, 30, 1)\n",
    "        supppor_labels: support labels (25, 5)\n",
    "        query_labels: query labels (75, 5)\n",
    "        K: number of support images per class\n",
    "        C: number of classes\n",
    "        N: number of query images per class\n",
    "        n_times: number of times to pass the query images for variance calculation\n",
    "        training: True if training, False if testing\n",
    "        '''\n",
    "        cat = tf.concat([support,query], axis=0)\n",
    "        loss = 0\n",
    "        all_predictions = []\n",
    "        y = np.zeros((int(C*N),C))\n",
    "        for i in range(int(C*N)) :\n",
    "            x = support_labels.index(query_labels[i])\n",
    "            y[i][x] = 1\n",
    "\n",
    "            \n",
    "        for i in range(n_times) :\n",
    "            # Pass through encoder to get embeddings.\n",
    "            z = self.encoder(cat)\n",
    "\n",
    "            # Reshape embeddings to separate support and query embeddings.\n",
    "            # For prototypes, we reshape C x K embeddings to C x K x D, ie. each class has K examples, each of D dimensions.\n",
    "            z_support = tf.reshape(z[:C * K],[C, K, z.shape[-1]])\n",
    "            # For query, we simply take the remaining embeddings.\n",
    "            z_query = z[C * K:]\n",
    "\n",
    "            # The prototypes are simply the mean of the support embeddings.\n",
    "            z_prototypes = tf.math.reduce_mean(z_support, axis=1)\n",
    "\n",
    "            # Take the euclidian distance between the query embeddings and the prototypes.\n",
    "            distances = calc_euclidian_dists(z_query, z_prototypes)\n",
    "\n",
    "            # Calculate the log softmax of the distances. These are the preictions for the current pass.\n",
    "            predictions = tf.nn.log_softmax(-distances, axis=-1)\n",
    "\n",
    "            # Calcyulate the loss for the current pass and add it to the total loss.\n",
    "            loss += - tf.reduce_mean((tf.reduce_sum(tf.multiply(y, predictions), axis=-1)))\n",
    "\n",
    "            # Append the predictions for the current pass to the list of predictions.\n",
    "            all_predictions.append(predictions)\n",
    "        \n",
    "        \n",
    "        if training:\n",
    "            # Convert the list of predictions to a tensor.\n",
    "            predictions = tf.convert_to_tensor(np.reshape(np.asarray(all_predictions),(n_times,int(C*N),C)))\n",
    "\n",
    "            # Calculate the standard deviation of the predictions.\n",
    "            std_predictions = tf.math.reduce_std(predictions,axis=0)\n",
    "\n",
    "            # Calculate the standard deviation of the true labels.\n",
    "            std = tf.reduce_sum(tf.reduce_sum(tf.multiply(std_predictions,y),axis=1))\n",
    "\n",
    "            # Add the standard deviation to the loss.\n",
    "            loss += MC_LOSS_WEIGHT*std\n",
    "\n",
    "            # Calculate the mean prediction.\n",
    "            mean_predictions = tf.reduce_mean(predictions,axis=0)\n",
    "\n",
    "            # Calculate the accuracy for each query patch.\n",
    "            # Check if the index of max probability is equal to the true class index.\n",
    "            mean_eq = tf.cast(tf.equal( tf.cast(tf.argmax(mean_predictions, axis=-1), tf.int32), tf.cast(tf.argmax(y,axis=-1), tf.int32)), tf.float32)\n",
    "            \n",
    "            # Calculate the mean accuracy.\n",
    "            mean_accuracy = tf.reduce_mean(mean_eq)\n",
    "            \n",
    "            return loss, mean_accuracy, mean_predictions\n",
    "\n",
    "        else:\n",
    "            # Calculate the mean predictions.\n",
    "            mean_predictions = tf.reduce_mean(all_predictions,axis=0)\n",
    "            \n",
    "            # Get the index of the max probability for each query patch.\n",
    "            mean_predictions_indices = tf.argmax(mean_predictions,axis=1)\n",
    "            \n",
    "            # Calculate the accuracy for each query patch.\n",
    "            # Check if the index of max probability is equal to the true class index.\n",
    "            mean_eq = tf.cast(tf.equal(tf.cast(mean_predictions_indices, tf.int32), tf.cast(tf.argmax(y, axis=-1), tf.int32)), tf.float32)\n",
    "            \n",
    "            # Calculate the mean accuracy.\n",
    "            mean_accuracy = tf.reduce_mean(mean_eq)\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            Explaination for classwise_mean_acc:\n",
    "            \n",
    "            What we need to get?\n",
    "                We need to get the mean accuracy for each class.\n",
    "            \n",
    "            How to get it?\n",
    "                We loop over all the query patches.\n",
    "                x is the index of the true class of the current query patch.\n",
    "                We check if the index of max probability is equal to the true class index.\n",
    "                if yes, we append 1 to the list of correct predictions for the current class.\n",
    "                if no, we append 0 to the list of correct predictions for the current class.\n",
    "                \n",
    "                After the loop, we calculate the mean accuracy for each class.\n",
    "                To do this, we simply divide the number of correct predictions for each class by the total number of predictions for each class.\n",
    "                    where sum(acc_list) represents the number of correct predictions for the current class.\n",
    "                    and len(acc_list) represents the total number of predictions for the current class.\n",
    "            \n",
    "            And done we have the mean accuracy for each class.\n",
    "            '''\n",
    "            classwise_mean_acc = [[] for _ in range(tC)]\n",
    "            std = 0\n",
    "            for i in range(int(C * N)):\n",
    "                #  Classwise mean accuracy\n",
    "                x = support_labels.index(query_labels[i])\n",
    "                \n",
    "                is_correct = (mean_predictions_indices[i] == x)\n",
    "                classwise_mean_acc[x].append(int(is_correct))\n",
    "                \n",
    "                #  ----------------------\n",
    "                # Standard deviation\n",
    "                \n",
    "                # Get all the predictions for the current query patch from all the n_times.\n",
    "                p_i = np.array([p[i,:] for p in all_predictions])\n",
    "                \n",
    "                # Get the standard deviation of the predictions for the current query patch.\n",
    "                std += tf.math.reduce_std(p_i, axis=0)[x]\n",
    "\n",
    "            # Calculate the mean accuracy for each class\n",
    "            classwise_mean_acc = [sum(acc_list) / len(acc_list)\n",
    "                                if acc_list else 0 for acc_list in classwise_mean_acc]\n",
    "            \n",
    "            loss += MC_LOSS_WEIGHT*std\n",
    "            \n",
    "            return loss, all_predictions, mean_accuracy, classwise_mean_acc, y\n",
    "\n",
    "\n",
    "        def save(self, model_path):\n",
    "            self.encoder.save_weights(model_path)\n",
    "\n",
    "        def load(self, model_path):\n",
    "            self.encoder(tf.zeros([1, self.w, self.h, self.c]))\n",
    "            self.encoder.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainingEpisode(patches:list, labels:list, K:int, C:int, N:int ):\n",
    "    \"\"\"\n",
    "    createTrainingEpisode creates a training episode for the N-way K-shot learning task.\n",
    "    \n",
    "    :param patches: list of all patches classified into different classes.\n",
    "    :param labels: list of classes from which the traning episode is to be created.\n",
    "    :param K: number of patches per class in the support set.\n",
    "    :param C: number of classes in the training episode.\n",
    "    :param N: number of patches per class in the query set.\n",
    "    :return queryPatches, queryLabels, supportPatches, supportLabels: training episode\n",
    "    \n",
    "    Algorithm:\n",
    "    - Select N classes from the list of labels. They should be unique.\n",
    "    - For each class, select K+Q patches. They should be unique.\n",
    "        - First K patches are support patches.\n",
    "        - Last Q patches are query patches.\n",
    "        - Append the support patches to supportPatches.\n",
    "        - Append the query patches to queryPatches.\n",
    "        - Append the class label to queryLabels Q times.\n",
    "    - Shuffle the queryPatches and queryLabels in the same order.\n",
    "    - Convert the queryPatches and supportPatches to tensors.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    selectedLabels = random.sample(labels, C)\n",
    "    supportPatches = []\n",
    "    supportLabels = list(selectedLabels)\n",
    "    queryPatches = []\n",
    "    queryLabels = []\n",
    "    \n",
    "    for n in selectedLabels:\n",
    "        sran_indices = np.random.choice(len(patches[n-1]),K,replace=False)  # for class no X-1: select K samples \n",
    "        supportPatches.extend( patches[n-1][sran_indices,:,:,:,:])\n",
    "        qran_indices = np.random.choice(len(patches[n-1]),N,replace=False)  # N Samples for Query\n",
    "        queryPatches.extend(patches[n-1][qran_indices,:,:,:,:])\n",
    "        queryLabels.extend([n]*N)\n",
    "    \n",
    "    shuffled = list(zip(queryPatches, queryLabels))\n",
    "    random.shuffle(shuffled)\n",
    "    queryPatches, queryLabels = zip(*shuffled)\n",
    "    \n",
    "    queryPatches = tf.convert_to_tensor(np.reshape(np.asarray(queryPatches),(C*N,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    supportPatches = tf.convert_to_tensor(np.reshape(np.asarray(supportPatches),(C*K,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    \n",
    "    return queryPatches, queryLabels, supportPatches, supportLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(support, query, support_labels, query_labels, K, C, N):\n",
    "    # Forward & update gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N,N_TIMES,training=True)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    # A gradient simply measures the change in all weights with regard to the change in error. You can also think of a gradient as the slope of a function. The higher the gradient, the steeper the slope and the faster a model can learn. But if the slope is zero, the model stops learning\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Log loss and accuracy for step\n",
    "    train_loss(loss)\n",
    "    train_acc(mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeIt\n",
    "def trainingEpochs(patches, labels, n_epochs, n_episodes):\n",
    "    \"\"\"\n",
    "    trainingEpochs function trains the model for n_epochs and n_episodes.\n",
    "    \n",
    "    :param patches: image patches to be trained\n",
    "    :param labels: corresponding labels to be used\n",
    "    :param n_epochs: number of epochs\n",
    "    :param n_episodes: number of episodes\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    template = 'Epoch {}/{}, Episode {}/{}, Train Loss: {:.2f}, Train Accuracy: {:.2f}'\n",
    "    # for epoch in tqdm(range(n_epochs), desc='Epochs'):\n",
    "    #     train_loss.reset_states()\n",
    "    #     train_acc.reset_states()\n",
    "    #     for episode in tqdm(range(n_episodes), desc=f'Episodes (Loss: {l:.2f}, Acc: {a:.2f})'):\n",
    "    \n",
    "    trainObj = tqdm(total=n_episodes * n_epochs, desc=f'Epoch 1/{n_epochs}, Episode 1/{n_episodes}')\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss.reset_states()\n",
    "        train_acc.reset_states()\n",
    "        for episode in range(n_episodes):\n",
    "            queryPatches, queryLabels, supportPatches, supportLabels = createTrainingEpisode(patches, labels, TRAIN_K, TRAIN_C, TRAIN_N)\n",
    "            train_step(supportPatches, queryPatches,supportLabels,  queryLabels, TRAIN_K, TRAIN_C, TRAIN_N)\n",
    "            # clear_output(wait=True)\n",
    "            trainObj.set_description(\n",
    "                f'Epoch {epoch+1}/{n_epochs}, Episode {episode+1}/{n_episodes} (Loss: {train_loss.result().numpy()*100:.2f}, Acc: {train_acc.result().numpy()*100:.2f})')\n",
    "            trainObj.update(1)\n",
    "            if(VERBOSE):\n",
    "                print(template.format(epoch+1, n_epochs, episode+1, n_episodes, train_loss.result()*100, train_acc.result()*100))\n",
    "                trainingData.append([train_loss.result(),  train_acc.result()*100])\n",
    "                plotData(trainingData)\n",
    "        \n",
    "        if(epoch and epoch % 5 == 0):\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix_train)    \n",
    "    trainObj.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTunningEpisodes(patches:list, labels:list, K:int, C:int, N:int):\n",
    "    \"\"\"\n",
    "    createTuningEpisodes creates a tuning episode for the N-way K-shot learning task.\n",
    "    \n",
    "    :param patches: list of all patches classified into different classes.\n",
    "    :param labels: list of classes from which the tuning episode is to be created.\n",
    "    :param K: number of patches per class in the support set.\n",
    "    :param C: number of classes in the tuning episode.\n",
    "    :param N: number of patches per class in the query set.\n",
    "    :return queryPatches, queryLabels, supportPatches, supportLabels: tuning episode\n",
    "    \n",
    "    Algorithm:\n",
    "    - Select C classes from the list of labels. They should be unique.\n",
    "    - For each selected class.\n",
    "        - Shuffle the patches of that class.\n",
    "        - First K patches are support patches.\n",
    "        - Next N patches are query patches. \n",
    "        - Append the support patches to supportPatches.\n",
    "        - Append the query patches to queryPatches.\n",
    "        - Append the class label to queryLabels N times.\n",
    "    - Shuffle the queryPatches and queryLabels in the same order.\n",
    "    - Convert the queryPatches and supportPatches to tensors.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    selected_classes = np.random.choice(labels,C,replace=False)\n",
    "    supportLabels  = list(selected_classes)\n",
    "    queryLabels = []\n",
    "    supportPatches = []\n",
    "    queryPatches = []\n",
    "    \n",
    "    for x in selected_classes :\n",
    "        y = labels.index(x)\n",
    "        np.random.shuffle(patches[y])    \n",
    "        supportPatches.extend(patches[y][:K,:,:,:,:])  # 1st K patches for support set\n",
    "        queryPatches.extend(patches[y][K:K+N,:,:,:,:])   # next N patches for query set\n",
    "        queryLabels.extend([x]*N)            \n",
    "          # next 5 labels for query set\n",
    "    \n",
    "    shuffled = list(zip(queryPatches, queryLabels))\n",
    "    random.shuffle(shuffled)\n",
    "    queryPatches, queryLabels = zip(*shuffled)\n",
    "    \n",
    "    queryPatches = tf.convert_to_tensor(np.reshape(np.asarray(queryPatches),(C*N,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    supportPatches = tf.convert_to_tensor(np.reshape(np.asarray(supportPatches),(C*K,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    \n",
    "    return queryPatches, queryLabels, supportPatches, supportLabels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_step(support, query, support_labels, query_labels, K, C, N):\n",
    "    # Forward & update gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N,N_TIMES,training=True)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Log loss and accuracy for step\n",
    "    tune_loss(loss)\n",
    "    tune_acc(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeIt\n",
    "def tunningEpochs(patches, labels, n_epochs, n_episodes):\n",
    "    \"\"\"\n",
    "    trainingEpochs function trains the model for n_epochs and n_episodes.\n",
    "    \n",
    "    :param patches: image patches to be trained\n",
    "    :param labels: corresponding labels to be used\n",
    "    :param n_epochs: number of epochs\n",
    "    :param n_episodes: number of episodes\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    template = 'Epoch {}/{}, Tune Loss: {:.2f}, Tune Accuracy: {:.2f}'\n",
    "\n",
    "    epochObj = tqdm(range(n_epochs), desc='Epochs')\n",
    "    for epoch in epochObj: \n",
    "        tune_loss.reset_states()  \n",
    "        tune_acc.reset_states()    \n",
    "        for epi in range(n_episodes):  \n",
    "            queryPatches, queryLabels, supportPatches, supportLabels = createTunningEpisodes(patches, labels, TUNE_K, TUNE_C, TUNE_N)    \n",
    "            tune_step(supportPatches, queryPatches,supportLabels, queryLabels, TUNE_K, TUNE_C, TUNE_N)   \n",
    "            # clear_output(wait=True)   \n",
    "        epochObj.set_postfix(\n",
    "            {'Loss': tune_acc.result().numpy()*100, 'Acc': tune_loss.result().numpy()}, refresh=True)\n",
    "        if(VERBOSE):\n",
    "            print(template.format(epoch+1, n_epochs,tune_loss.result(),tune_acc.result()*100))\n",
    "            tunningData.append([tune_loss.result(),  tune_acc.result()*100])\n",
    "            plotData(tunningData)\n",
    "        if (epoch+1)%5 == 0 :\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix_tune) \n",
    "    epochObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTestingEpisode(patches, labels, K, C, i, f):\n",
    "    selected_classes = labels[i:f]   # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    support_labels = list(selected_classes)\n",
    "    query_labels = []\n",
    "    support_patches = []\n",
    "    query_patches = []\n",
    "    for x in selected_classes :\n",
    "        y = labels.index(x)\n",
    "        \n",
    "        support_imgs = patches[y][:K,:,:,:,:]\n",
    "        query_imgs = patches[y][K:,:,:,:,:]\n",
    "        support_patches.extend(support_imgs)\n",
    "        query_patches.extend(query_imgs)\n",
    "        for i in range(query_imgs.shape[0]) :\n",
    "            query_labels.append(x)\n",
    "    temp1 = list(zip(query_patches, query_labels)) \n",
    "    random.shuffle(temp1) \n",
    "    query_patches, query_labels = zip(*temp1)\n",
    "    x = len(query_labels)\n",
    "    query_patches = tf.convert_to_tensor(np.reshape(np.asarray(query_patches),(x,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    support_patches = tf.convert_to_tensor(np.reshape(np.asarray(support_patches),(C*K,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH,IMAGE_CHANNEL)),dtype=tf.float32)\n",
    "    return query_patches, support_patches, query_labels, support_labels,x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(support, query, support_labels, query_labels, K, C, y):\n",
    "    loss, mc_predictions, mean_accuracy, classwise_mean_acc, y = ProtoModel(support, query, support_labels, query_labels, K, C, y,N_TIMES,training=False)\n",
    "    return loss, mc_predictions, mean_accuracy, classwise_mean_acc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeIt\n",
    "def testingEpochs(patches, labels, n_epochs):\n",
    "    \"\"\"\n",
    "    testingEpochs function tests the model for n_epochs.\n",
    "    \n",
    "    :param patches: image patches to be trained\n",
    "    :param labels: corresponding labels to be used\n",
    "    :param n_epochs: number of epochs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    epochObj = tqdm(range(n_epochs), desc=f'Epochs')\n",
    "    \n",
    "    for epoch in epochObj:\n",
    "        test_loss.reset_states()  \n",
    "        test_acc.reset_states()     \n",
    "        \n",
    "        tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1 = createTestingEpisode(patches,labels,TEST_K,TEST_C,0,3)    \n",
    "        loss1, mc_predictions1, mean_accuracy1, classwise_mean_acc1, y1 = test_step(tsupport_patches1, tquery_patches1,support_labels1, query_labels1, TEST_K, TEST_C, y=x1/3) \n",
    "        tquery_patches2, tsupport_patches2, query_labels2, support_labels2, x2 = createTestingEpisode(patches,labels,TEST_K,TEST_C,3,6)    \n",
    "        loss2, mc_predictions2, mean_accuracy2, classwise_mean_acc2, y2 = test_step(tsupport_patches2, tquery_patches2,support_labels2, query_labels2, 5, 3, x2/3)\n",
    "        \n",
    "        oa1 = mean_accuracy1\n",
    "        oa2 = mean_accuracy2\n",
    "        epochObj.set_postfix(\n",
    "            {'OA1': oa1.numpy(), 'OA2': oa2.numpy()}, refresh=True)\n",
    "        if(VERBOSE):\n",
    "            print(\"=========================================\")\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "            print(\"-----------------------------------------\")\n",
    "            print(f\"Overall Accuracy 1 (OA1): {mean_accuracy1}\")\n",
    "            # Class Wise Accuracy\n",
    "            for i in range(TEST_C):\n",
    "                print(f\"Class {i+1} Accuracy: {classwise_mean_acc1[i]}\")\n",
    "            print(f\"Loss: {loss1.numpy():.3f}\")\n",
    "            print(\"-----------------------------------------\")\n",
    "            print(f\"Overall Accuracy 2 (OA2): {mean_accuracy2}\")\n",
    "            # Class Wise Accuracy\n",
    "            for i in range(TEST_C):\n",
    "                print(f\"Class {i+1+TEST_C} Accuracy: {classwise_mean_acc2[i]}\")\n",
    "            print(f\"Loss: {loss2.numpy():.3f}\")\n",
    "            print(\"=========================================\")\n",
    "            \n",
    "            testingData.append([mean_accuracy1*100, mean_accuracy2*100, loss1.numpy(), loss2.numpy()])\n",
    "            plotData(testingData, testing=True)\n",
    "        # else:\n",
    "            # clear_output(wait=True)\n",
    "            # print(\"-----------------------------------------\\n\" + f\"Epoch {epoch+1}/{n_epochs}\\n\" + \"-----------------------------------------\\n\"\n",
    "            # + f\"Overall Accuracy 1 (OA1): {mean_accuracy1}\\n\" + f\"Overall Accuracy 2 (OA2): {mean_accuracy2}\")\n",
    "\n",
    "    epochObj.close()\n",
    "    return mc_predictions1, mc_predictions2, y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian_pines\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "data = Data(DATASET, PCA_COMPONENTS, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, patches = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES, TRAINING_CLASSES, TRAINING_LABELS, TUNNING_LABELS, TESTING_CLASSES, TESTING_LABELS, TRAINING_PATCHES,TUNNING_PATCHES, TESTING_PATCHES = data.load_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 11, 11, 30,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " conv3d_24 (Conv3D)             (None, 11, 11, 30,   512         ['input_9[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " spatial_dropout3d_16 (SpatialD  (None, 11, 11, 30,   0          ['conv3d_24[0][0]']              \n",
      " ropout3D)                      8)                                                                \n",
      "                                                                                                  \n",
      " conv3d_25 (Conv3D)             (None, 11, 11, 30,   5776        ['spatial_dropout3d_16[0][0]']   \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " spatial_dropout3d_17 (SpatialD  (None, 11, 11, 30,   0          ['conv3d_25[0][0]']              \n",
      " ropout3D)                      16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_26 (Conv3D)             (None, 9, 9, 28, 32  13856       ['spatial_dropout3d_17[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 9, 9, 896)    0           ['conv3d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 7, 7, 64)     516160      ['reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " attention_16 (Attention)       (None, 7, 7, 64)     0           ['conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " softmax_8 (Softmax)            (None, 7, 7, 64)     0           ['attention_16[0][0]']           \n",
      "                                                                                                  \n",
      " attention_17 (Attention)       (None, 7, 7, 64)     1           ['softmax_8[0][0]',              \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 7, 7, 64)    128         ['attention_17[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 3136)         0           ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 3136)         0           ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 256)          803072      ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 256)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          32896       ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,372,401\n",
      "Trainable params: 1,372,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create instance of the model\n",
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the Prototypical Network\n",
    "ProtoModel = Prototypical(model, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH, IMAGE_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the Checkpoint\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, ProtoModel = ProtoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Episode 5/5 (Loss: 159.98, Acc: 22.67): 100%|██████████| 15/15 [00:02<00:00,  7.13it/s, Loss=0, Acc=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'trainingEpochs' executed in 2.1115s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainingEpochs(patches, TRAINING_LABELS, TRAINING_EPOCH, TRAINING_EPISODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 3/3 [00:01<00:00,  2.37it/s, Loss=38.3, Acc=1.08]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'tunningEpochs' executed in 1.2705s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tunningEpochs(TUNNING_PATCHES, TESTING_LABELS, TUNNING_EPOCH, TUNNING_EPISODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [00:17<00:00,  1.75s/it, OA1=0.223, OA2=0.399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'testingEpochs' executed in 17.4637s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mc_predictions1, mc_predictions2, y1, y2 =  testingEpochs(TESTING_PATCHES, TESTING_LABELS, TESTING_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lib.Stats import Stats\n",
    "stats = Stats(mc_predictions1, mc_predictions2, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.00025933105554 Kappa accuracy (%)\n",
      "\n",
      "\n",
      "31.21869782971619 Overall accuracy (%)\n",
      "\n",
      "\n",
      "39.56349541415545 Average accuracy (%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.44      0.22        41\n",
      "           1       0.80      0.17      0.28       232\n",
      "           2       0.06      0.35      0.11        23\n",
      "           3       0.09      0.60      0.16        15\n",
      "           4       0.71      0.36      0.48       200\n",
      "           5       0.39      0.45      0.42        88\n",
      "\n",
      "    accuracy                           0.31       599\n",
      "   macro avg       0.37      0.40      0.28       599\n",
      "weighted avg       0.62      0.31      0.35       599\n",
      "\n",
      "\n",
      "\n",
      "[[18  4 19  0  0  0]\n",
      " [95 40 97  0  0  0]\n",
      " [ 9  6  8  0  0  0]\n",
      " [ 0  0  0  9  4  2]\n",
      " [ 0  0  0 68 72 60]\n",
      " [ 0  0  0 22 26 40]]\n"
     ]
    }
   ],
   "source": [
    "stats.printReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(SAVE_REPORT):\n",
    "    stats.saveReport(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(SAVE_MODEL):\n",
    "    ProtoModel.save(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
